[{"path":"https://vincentarelbundock.github.io/marginaleffects/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://vincentarelbundock.github.io/marginaleffects/LICENSE.html","id":"0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/LICENSE.html","id":"1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/LICENSE.html","id":"2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/LICENSE.html","id":"3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/LICENSE.html","id":"4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/LICENSE.html","id":"5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/LICENSE.html","id":"6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/LICENSE.html","id":"7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/LICENSE.html","id":"8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/LICENSE.html","id":"9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/LICENSE.html","id":"10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/LICENSE.html","id":"11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/LICENSE.html","id":"12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/LICENSE.html","id":"13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/LICENSE.html","id":"14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/LICENSE.html","id":"15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/LICENSE.html","id":"16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/LICENSE.html","id":"17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/alternative_software.html","id":"emmeans","dir":"Articles","previous_headings":"","what":"emmeans","title":"Comparisons to alternative software","text":"emmeans package developed Russell V. Lenth colleagues. emmeans truly incredible piece software, trailblazer R ecosystem. extremely powerful package whose functionality overlaps marginaleffects significant degree: marginal means, contrasts, slopes. Even two packages can compute many quantities, emmeans marginaleffects pretty different philosophies respect user interface computation. emmeans analysis typically starts computing “marginal means” holding numeric covariates means, averaging across balanced grid categorical predictors. , users can use contrast() function estimate difference marginal means. marginaleffects package supplies marginalmeans function can also compute marginal means. However, typical analysis squarely centered predicted/fitted values. useful starting point , many cases, analysts find easy intuitive express scientific queries terms changes predicted values. example, average predicted probability survival differ treatment control group? difference predicted wage college high school graduates? Let’s say estimate linear regression model two continuous regressors multiplicative interaction: \\[y = \\beta_0 + \\beta_1 x + \\beta_2 z + \\beta_3 x \\cdot z + \\varepsilon\\] model, effect \\(x\\) \\(y\\) depend value covariate \\(z\\). Let’s say user wants estimate happens predicted value \\(y\\) \\(x\\) increases 1 unit, \\(z \\\\{-1, 0, 1\\}\\). , use comparisons() function. variables argument determines scientific query interest, newdata argument determines grid covariate values want evaluate query: vignettes show, marginaleffects can also compute contrasts marginal means. can also compute various quantities interest like raw fitted values, slopes (partial derivatives), contrasts marginal means. also offers flexible mechanism run (non-)linear hypothesis tests using delta method, offers fully customizable strategy compute quantities like odds ratios (completely arbitrary functions predicted outcome). Thus, (Vincent’s) biased opinion, main benefits marginaleffects emmeans : Support model types. Simpler, intuitive, highly consistent user interface. Easier compute average marginal effects unit-level marginal effects whole datasets. Easier compute marginal effects (slopes) custom grids continuous regressors. Easier implement causal inference strategies like parametric g-formula regression adjustement experiments (see vignettes). Allows computation arbitrary quantities interest via user-supplied functions automatic delta method inference. Common plots easy plot_cap(), plot_cco(), plot_cme() functions. fair, many marginaleffects advantages listed come subjective preferences user interface. Readers thus encouraged try packages see interface prefer. AFAICT, main advantages emmeans marginaleffects : Omnibus tests. Equivalence noninferiority tests. Multiplicity adjustments. Please let know find features emmeans can add list. Marginal Means Vignette includes side--side comparisons emmeans marginaleffects compute marginal means. rest section compares syntax contrasts marginaleffects.","code":"model <- lm(y ~ x * z, data)  comparisons(   model,   variables = list(x = 1), # what is the effect of 1-unit change in x?   newdata = datagrid(z = -1:1) # when z is held at values -1, 0, or 1 )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/alternative_software.html","id":"contrasts","dir":"Articles","previous_headings":"emmeans","what":"Contrasts","title":"Comparisons to alternative software","text":"far can tell, emmeans provide easy way compute unit-level contrasts every row dataset used fit model. Therefore, side--side syntax shown always include newdata=datagrid() specify want compute one contrast: mean values regressors. day--day practice marginaleffects(), however, extra argument necessary. Fit model: Link scale, pairwise contrasts: Response scale, reference groups:","code":"library(emmeans) library(marginaleffects)  mod <- glm(vs ~ hp + factor(cyl), data = mtcars, family = binomial) emm <- emmeans(mod, specs = \"cyl\") contrast(emm, method = \"revpairwise\", adjust = \"none\", df = Inf) #>  contrast    estimate      SE  df z.ratio p.value #>  cyl6 - cyl4   -0.905    1.63 Inf  -0.555  0.5789 #>  cyl8 - cyl4  -19.542 4367.17 Inf  -0.004  0.9964 #>  cyl8 - cyl6  -18.637 4367.16 Inf  -0.004  0.9966 #>  #> Degrees-of-freedom method: user-specified  #> Results are given on the log odds ratio (not the response) scale.  comparisons(mod,             type = \"link\",             newdata = \"mean\",             variables = list(cyl = \"pairwise\")) #>   rowid type term contrast  comparison   std.error    statistic   p.value #> 1     1 link  cyl    6 - 4  -0.9048741    1.630231 -0.555058785 0.5788545 #> 2     1 link  cyl    8 - 4 -19.5417566 4367.165924 -0.004474700 0.9964297 #> 3     1 link  cyl    8 - 6 -18.6368825 4367.165407 -0.004267501 0.9965950 #>       conf.low  conf.high predicted predicted_hi predicted_lo     vs       hp #> 1    -4.100068    2.29032 -19.15839   -0.5215048    0.3833693 0.4375 146.6875 #> 2 -8579.029682 8539.94617 -19.15839  -19.1583873    0.3833693 0.4375 146.6875 #> 3 -8578.123795 8540.85003 -19.15839  -19.1583873   -0.5215048 0.4375 146.6875 #>   cyl #> 1   8 #> 2   8 #> 3   8 emm <- emmeans(mod, specs = \"cyl\", regrid = \"response\") contrast(emm, method = \"trt.vs.ctrl1\", adjust = \"none\", df = Inf, ratios = FALSE) #>  contrast    estimate    SE  df z.ratio p.value #>  cyl6 - cyl4   -0.222 0.394 Inf  -0.564  0.5727 #>  cyl8 - cyl4   -0.595 0.511 Inf  -1.163  0.2447 #>  #> Degrees-of-freedom method: user-specified  comparisons(mod, newdata = \"mean\") #>   rowid     type term contrast    comparison    std.error   statistic   p.value #> 1     1 response   hp       +1 -1.557824e-10 6.803615e-07 -0.00022897 0.9998173 #> 2     1 response  cyl    6 - 4 -2.221851e-01 3.916435e-01 -0.56731461 0.5705005 #> 3     1 response  cyl    8 - 4 -5.946855e-01 5.097420e-01 -1.16664014 0.2433557 #>        conf.low    conf.high    predicted predicted_hi predicted_lo     vs #> 1 -1.333640e-06 1.333328e-06 4.782094e-09 4.704837e-09 4.860620e-09 0.4375 #> 2 -9.897921e-01 5.454220e-01 4.782094e-09 3.725004e-01 5.946855e-01 0.4375 #> 3 -1.593761e+00 4.043905e-01 4.782094e-09 4.782094e-09 5.946855e-01 0.4375 #>         hp cyl    eps #> 1 146.6875   8 0.0283 #> 2 146.6875   8     NA #> 3 146.6875   8     NA"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/alternative_software.html","id":"contrasts-by-group","dir":"Articles","previous_headings":"emmeans","what":"Contrasts by group","title":"Comparisons to alternative software","text":"slightly complicated example contrasts estimated subgroup lme4 mixed effects model. First estimate model compute pairwise contrasts subgroup using emmeans: emmeans obtain results? Roughly speaking: Create prediction grid one cell combination categorical predictors model, numeric variables held means. Make adjusted predictions cell prediction grid. Take average predictions (marginal means) combination btype (focal variable) resp (group variable). Compute pairwise differences (contrasts) marginal means across different levels focal variable btype. short, emmeans computes pairwise contrasts marginal means, averages adjusted predictions. different default types contrasts produced comparisons(), reports contrasts adjusted predictions, without averaging across pre-specified grid predictors. comparisons() instead? Let newdata data frame supplied user (original data frame used fit model), : Create new data frame called newdata2, identical newdata except focal variable incremented one level. predict(model, newdata = newdata2) - predict(model, newdata = newdata) Although idiomatic, can use still use comparisons() emulate emmeans results. First, create prediction grid one cell combination categorical predictor model: grid 18 rows, one combination levels resp (3), situ (2), btype (3) variables (3 * 2 * 3 = 18). compute pairwise contrasts grid: 3 pairwise contrasts, corresponding 3 pairwise comparisons possible 3 levels focal variable btype: scold-curse, shout-scold, shout-curse. comparisons() function estimates 3 contrasts row newdata, get \\(18 \\times 3 = 54\\) rows. Finally, wanted contrasts averaged subgroup resp variable, can use argument: results identical produced emmeans (except \\(t\\) vs. \\(z\\)).","code":"library(dplyr) library(lme4) library(emmeans)  dat <- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/lme4/VerbAgg.csv\") dat$woman <- as.numeric(dat$Gender == \"F\")  mod <- glmer(     woman ~ btype * resp + situ + (1 + Anger | item),     family = binomial,     data = dat)  emmeans(mod, specs = \"btype\", by = \"resp\") |>     contrast(method = \"revpairwise\", adjust = \"none\") #> resp = no: #>  contrast      estimate     SE  df z.ratio p.value #>  scold - curse  -0.0152 0.1097 Inf  -0.139  0.8898 #>  shout - curse  -0.2533 0.1022 Inf  -2.479  0.0132 #>  shout - scold  -0.2381 0.0886 Inf  -2.686  0.0072 #>  #> resp = perhaps: #>  contrast      estimate     SE  df z.ratio p.value #>  scold - curse  -0.2393 0.1178 Inf  -2.031  0.0422 #>  shout - curse  -0.0834 0.1330 Inf  -0.627  0.5309 #>  shout - scold   0.1559 0.1358 Inf   1.148  0.2510 #>  #> resp = yes: #>  contrast      estimate     SE  df z.ratio p.value #>  scold - curse   0.0391 0.1292 Inf   0.302  0.7624 #>  shout - curse   0.5802 0.1784 Inf   3.252  0.0011 #>  shout - scold   0.5411 0.1888 Inf   2.866  0.0042 #>  #> Results are averaged over the levels of: situ  #> Results are given on the log odds ratio (not the response) scale. nd <- datagrid(     model = mod,     resp = dat$resp,     situ = dat$situ,     btype = dat$btype) nrow(nd) #> [1] 18 cmp <- comparisons(mod,     variables = list(\"btype\" = \"pairwise\"),     newdata = nd,     type = \"link\") nrow(cmp) #> [1] 54 comparisons(mod,     by = \"resp\",     variables = list(\"btype\" = \"pairwise\"),     newdata = nd,     type = \"link\") |>     summary() #>    Term                  Contrast    resp   Effect Std. Error z value  Pr(>|z|) #> 1 btype mean(scold) - mean(curse)      no -0.01520    0.10965 -0.1386 0.8897581 #> 2 btype mean(scold) - mean(curse) perhaps -0.23928    0.11779 -2.0314 0.0422130 #> 3 btype mean(scold) - mean(curse)     yes  0.03907    0.12922  0.3023 0.7623876 #> 4 btype mean(shout) - mean(curse)      no -0.25330    0.10219 -2.4786 0.0131889 #> 5 btype mean(shout) - mean(curse) perhaps -0.08336    0.13303 -0.6266 0.5309040 #> 6 btype mean(shout) - mean(curse)     yes  0.58018    0.17842  3.2518 0.0011468 #> 7 btype mean(shout) - mean(scold)      no -0.23810    0.08864 -2.6860 0.0072316 #> 8 btype mean(shout) - mean(scold) perhaps  0.15592    0.13583  1.1479 0.2510250 #> 9 btype mean(shout) - mean(scold)     yes  0.54111    0.18881  2.8660 0.0041574 #>     2.5 %    97.5 % #> 1 -0.2301  0.199715 #> 2 -0.4701 -0.008416 #> 3 -0.2142  0.292344 #> 4 -0.4536 -0.053004 #> 5 -0.3441  0.177372 #> 6  0.2305  0.929873 #> 7 -0.4118 -0.064358 #> 8 -0.1103  0.422149 #> 9  0.1711  0.911161 #>  #> Model type:  glmerMod  #> Prediction type:  link"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/alternative_software.html","id":"marginal-effects","dir":"Articles","previous_headings":"emmeans","what":"Marginal Effects","title":"Comparisons to alternative software","text":"far can tell, emmeans::emtrends makes easier compute marginal effects user-specified values large grids full original dataset. Response scale, user-specified values: Link scale, user-specified values:","code":"mod <- glm(vs ~ hp + factor(cyl), data = mtcars, family = binomial)  emtrends(mod, ~hp, \"hp\", regrid = \"response\", at = list(cyl = 4)) #>   hp hp.trend    SE  df asymp.LCL asymp.UCL #>  147 -0.00786 0.011 Inf   -0.0294    0.0137 #>  #> Confidence level used: 0.95  marginaleffects(mod, newdata = datagrid(cyl = 4)) #>   rowid     type term contrast         dydx  std.error  statistic   p.value #> 1     1 response   hp    dY/dX -0.007852329 0.01110851 -0.7068751 0.4796441 #> 2     1 response  cyl    6 - 4 -0.222185055 0.39164346 -0.5673146 0.5705005 #> 3     1 response  cyl    8 - 4 -0.594685481 0.50974200 -1.1666401 0.2433557 #>      conf.low  conf.high predicted predicted_hi predicted_lo     vs       hp #> 1 -0.02962461 0.01391995 0.5946855 5.944633e-01    0.5946855 0.4375 146.6875 #> 2 -0.98979213 0.54542202 0.5946855 3.725004e-01    0.5946855 0.4375 146.6875 #> 3 -1.59376144 0.40439048 0.5946855 4.782094e-09    0.5946855 0.4375 146.6875 #>   cyl    eps #> 1   4 0.0283 #> 2   4     NA #> 3   4     NA emtrends(mod, ~hp, \"hp\", at = list(cyl = 4)) #>   hp hp.trend     SE  df asymp.LCL asymp.UCL #>  147  -0.0326 0.0339 Inf    -0.099    0.0338 #>  #> Confidence level used: 0.95  marginaleffects(mod, type = \"link\", newdata = datagrid(cyl = 4)) #>   rowid type term contrast         dydx    std.error  statistic   p.value #> 1     1 link   hp    dY/dX  -0.03257475 3.388105e-02 -0.9614446 0.3363287 #> 2     1 link  cyl    6 - 4  -0.90487411 1.630231e+00 -0.5550588 0.5788545 #> 3     1 link  cyl    8 - 4 -19.54175662 4.367166e+03 -0.0044747 0.9964297 #>        conf.low    conf.high predicted predicted_hi predicted_lo     vs #> 1 -9.898038e-02 3.383088e-02 0.3833693    0.3824475    0.3833693 0.4375 #> 2 -4.100068e+00 2.290320e+00 0.3833693   -0.5215048    0.3833693 0.4375 #> 3 -8.579030e+03 8.539946e+03 0.3833693  -19.1583873    0.3833693 0.4375 #>         hp cyl    eps #> 1 146.6875   4 0.0283 #> 2 146.6875   4     NA #> 3 146.6875   4     NA"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/alternative_software.html","id":"more-examples","dir":"Articles","previous_headings":"emmeans","what":"More examples","title":"Comparisons to alternative software","text":"emmeans vs. marginaleffects comparisons:","code":"# Example of examining a continuous x categorical interaction using emmeans and marginaleffects # Authors: Cameron Patrick and Vincent Arel-Bundock  library(tidyverse) library(emmeans) library(marginaleffects)  # use the mtcars data, set up am as a factor data(mtcars) mc <- mtcars %>% mutate(am = factor(am))  # fit a linear model to mpg with wt x am interaction m <- lm(mpg ~ wt*am, data = mc) summary(m)  # 1. means for each level of am at mean wt. emmeans(m, \"am\") marginalmeans(m, variables = \"am\") predictions(m, newdata = datagrid(am = 0:1))  # 2. means for each level of am at wt = 2.5, 3, 3.5. emmeans(m, c(\"am\", \"wt\"), at = list(wt = c(2.5, 3, 3.5))) predictions(m, newdata = datagrid(am = 0:1, wt = c(2.5, 3, 3.5))  # 3. means for wt = 2.5, 3, 3.5, averaged over levels of am (implicitly!). emmeans(m, \"wt\", at = list(wt = c(2.5, 3, 3.5)))  # same thing, but the averaging is more explicit, using the `by` argument predictions(   m,   newdata = datagrid(am = 0:1, wt = c(2.5, 3, 3.5)),   by = \"wt\")  # 4. graphical version of 2. emmip(m, am ~ wt, at = list(wt = c(2.5, 3, 3.5)), CIs = TRUE) plot_cap(m, condition = c(\"wt\", \"am\"))  # 5. compare levels of am at specific values of wt. # this is a bit ugly because the emmeans defaults for pairs() are silly. # infer = TRUE: enable confidence intervals. # adjust = \"none\": begone, Tukey. # reverse = TRUE: contrasts as (later level) - (earlier level) pairs(emmeans(m, \"am\", by = \"wt\", at = list(wt = c(2.5, 3, 3.5))),       infer = TRUE, adjust = \"none\", reverse = TRUE)  comparisons(   m,   variables = \"am\",   newdata = datagrid(wt = c(2.5, 3, 3.5)))  # 6. plot of pairswise comparisons plot(pairs(emmeans(m, \"am\", by = \"wt\", at = list(wt = c(2.5, 3, 3.5))),       infer = TRUE, adjust = \"none\", reverse = TRUE))  # Since `wt` is numeric, the default is to plot it as a continuous variable on # the x-axis.  But not that this is the **exact same info** as in the emmeans plot. plot_cco(m, effect = \"am\", condition = \"wt\")  # You of course customize everything, set draw=FALSE, and feed the raw data to feed to ggplot2 p <- plot_cco(   m,   effect = \"am\",   condition = list(wt = c(2.5, 3, 3.5)),   draw = FALSE)  ggplot(p, aes(y = condition1, x = comparison, xmin = conf.low, xmax = conf.high)) +   geom_pointrange()  # 7. slope of wt for each level of am emtrends(m, \"am\", \"wt\") marginaleffects(m, newdata = datagrid(am = 0:1))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/alternative_software.html","id":"margins-and-prediction","dir":"Articles","previous_headings":"","what":"margins and prediction","title":"Comparisons to alternative software","text":"margins prediction packages R designed Thomas Leeper emulate behavior margins command Stata. packages trailblazers strongly influenced development marginaleffects. main benefits marginaleffects packages : Support model types Faster Memory efficient Plots using ggplot2 instead Base R extensive test suite Active development syntax two packages similar.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/alternative_software.html","id":"average-marginal-effects","dir":"Articles","previous_headings":"margins and prediction","what":"Average Marginal Effects","title":"Comparisons to alternative software","text":"","code":"library(margins) library(marginaleffects)  mod <- lm(mpg ~ cyl + hp + wt, data = mtcars)  mar <- margins(mod) summary(mar) #>  factor     AME     SE       z      p   lower   upper #>     cyl -0.9416 0.5509 -1.7092 0.0874 -2.0214  0.1382 #>      hp -0.0180 0.0119 -1.5188 0.1288 -0.0413  0.0052 #>      wt -3.1670 0.7406 -4.2764 0.0000 -4.6185 -1.7155  mfx <- marginaleffects(mod) summary(mfx) #>   Term   Effect Std. Error z value   Pr(>|z|)    2.5 %    97.5 % #> 1  cyl -0.94162    0.55092  -1.709   0.087417 -2.02139  0.138159 #> 2   hp -0.01804    0.01188  -1.519   0.128803 -0.04132  0.005239 #> 3   wt -3.16697    0.74058  -4.276 1.8997e-05 -4.61848 -1.715471 #>  #> Model type:  lm  #> Prediction type:  response"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/alternative_software.html","id":"individual-level-marginal-effects","dir":"Articles","previous_headings":"margins and prediction","what":"Individual-Level Marginal Effects","title":"Comparisons to alternative software","text":"Marginal effects user-specified data frame:","code":"head(data.frame(mar)) #>    mpg cyl disp  hp drat    wt  qsec vs am gear carb   fitted se.fitted #> 1 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4 22.82043 0.6876212 #> 2 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4 22.01285 0.6056817 #> 3 22.8   4  108  93 3.85 2.320 18.61  1  1    4    1 25.96040 0.7349593 #> 4 21.4   6  258 110 3.08 3.215 19.44  1  0    3    1 20.93608 0.5800910 #> 5 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2 17.16780 0.8322986 #> 6 18.1   6  225 105 2.76 3.460 20.22  1  0    3    1 20.25036 0.6638322 #>     dydx_cyl    dydx_hp   dydx_wt Var_dydx_cyl  Var_dydx_hp Var_dydx_wt #> 1 -0.9416168 -0.0180381 -3.166973    0.3035104 0.0001410451   0.5484521 #> 2 -0.9416168 -0.0180381 -3.166973    0.3035104 0.0001410451   0.5484521 #> 3 -0.9416168 -0.0180381 -3.166973    0.3035104 0.0001410451   0.5484521 #> 4 -0.9416168 -0.0180381 -3.166973    0.3035104 0.0001410451   0.5484521 #> 5 -0.9416168 -0.0180381 -3.166973    0.3035104 0.0001410451   0.5484521 #> 6 -0.9416168 -0.0180381 -3.166973    0.3035104 0.0001410451   0.5484521 #>   X_weights X_at_number #> 1        NA           1 #> 2        NA           1 #> 3        NA           1 #> 4        NA           1 #> 5        NA           1 #> 6        NA           1  head(mfx) #>   rowid     type term       dydx std.error statistic    p.value  conf.low #> 1     1 response  cyl -0.9416168 0.5509163 -1.709183 0.08741706 -2.021393 #> 2     2 response  cyl -0.9416168 0.5509163 -1.709183 0.08741706 -2.021393 #> 3     3 response  cyl -0.9416168 0.5509164 -1.709183 0.08741712 -2.021393 #> 4     4 response  cyl -0.9416168 0.5509163 -1.709183 0.08741706 -2.021393 #> 5     5 response  cyl -0.9416168 0.5509164 -1.709183 0.08741710 -2.021393 #> 6     6 response  cyl -0.9416168 0.5509163 -1.709183 0.08741706 -2.021393 #>   conf.high predicted predicted_hi predicted_lo  mpg cyl  hp    wt   eps #> 1 0.1381594  22.82043     22.82005     22.82043 21.0   6 110 2.620 4e-04 #> 2 0.1381594  22.01285     22.01247     22.01285 21.0   6 110 2.875 4e-04 #> 3 0.1381595  25.96040     25.96002     25.96040 22.8   4  93 2.320 4e-04 #> 4 0.1381594  20.93608     20.93570     20.93608 21.4   6 110 3.215 4e-04 #> 5 0.1381595  17.16780     17.16742     17.16780 18.7   8 175 3.440 4e-04 #> 6 0.1381594  20.25036     20.24998     20.25036 18.1   6 105 3.460 4e-04 nd <- data.frame(cyl = 4, hp = 110, wt = 3)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/alternative_software.html","id":"marginal-effects-at-the-mean","dir":"Articles","previous_headings":"margins and prediction","what":"Marginal Effects at the Mean","title":"Comparisons to alternative software","text":"","code":"mar <- margins(mod, data = data.frame(mean_or_mode(mtcars)), unit_ses = TRUE) data.frame(mar) #>        mpg    cyl     disp       hp     drat      wt     qsec     vs      am #> 1 20.09062 6.1875 230.7219 146.6875 3.596563 3.21725 17.84875 0.4375 0.40625 #>     gear   carb   fitted se.fitted   dydx_cyl    dydx_hp   dydx_wt Var_dydx_cyl #> 1 3.6875 2.8125 20.09062 0.4439832 -0.9416168 -0.0180381 -3.166973    0.3035013 #>    Var_dydx_hp Var_dydx_wt SE_dydx_cyl SE_dydx_hp SE_dydx_wt X_weights #> 1 0.0001410453     0.54846   0.5509096 0.01187625  0.7405808        NA #>   X_at_number #> 1           1  marginaleffects(mod, newdata = \"mean\") #>   rowid     type term       dydx  std.error statistic      p.value    conf.low #> 1     1 response  cyl -0.9416168 0.55091633 -1.709183 8.741706e-02 -2.02139298 #> 2     1 response   hp -0.0180381 0.01187625 -1.518838 1.288032e-01 -0.04131512 #> 3     1 response   wt -3.1669731 0.74057579 -4.276366 1.899688e-05 -4.61847499 #>     conf.high predicted predicted_hi predicted_lo      mpg    cyl       hp #> 1  0.13815935  20.09062     20.09025     20.09062 20.09062 6.1875 146.6875 #> 2  0.00523892  20.09062     20.09011     20.09062 20.09062 6.1875 146.6875 #> 3 -1.71547124  20.09062     20.08939     20.09062 20.09062 6.1875 146.6875 #>        wt       eps #> 1 3.21725 0.0004000 #> 2 3.21725 0.0283000 #> 3 3.21725 0.0003911"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/alternative_software.html","id":"counterfactual-average-marginal-effects","dir":"Articles","previous_headings":"margins and prediction","what":"Counterfactual Average Marginal Effects","title":"Comparisons to alternative software","text":"argument margins package emulates Stata fixing values variables user-specified values, replicating full dataset several times combination supplied values (see Stata section ). example, dataset includes 32 rows user calls =list(cyl=c(4, 6)), margins compute 64 unit-level marginal effects estimates:","code":"dat <- mtcars dat$cyl <- factor(dat$cyl) mod <- lm(mpg ~ cyl * hp + wt, data = mtcars)  mar <- margins(mod, at = list(cyl = c(4, 6, 8))) summary(mar) #>  factor    cyl     AME     SE       z      p   lower   upper #>     cyl 4.0000  0.0381 0.6000  0.0636 0.9493 -1.1378  1.2141 #>     cyl 6.0000  0.0381 0.5999  0.0636 0.9493 -1.1376  1.2139 #>     cyl 8.0000  0.0381 0.5999  0.0636 0.9493 -1.1376  1.2139 #>      hp 4.0000 -0.0878 0.0267 -3.2937 0.0010 -0.1400 -0.0355 #>      hp 6.0000 -0.0499 0.0154 -3.2397 0.0012 -0.0800 -0.0197 #>      hp 8.0000 -0.0120 0.0108 -1.1065 0.2685 -0.0332  0.0092 #>      wt 4.0000 -3.1198 0.6613 -4.7175 0.0000 -4.4160 -1.8236 #>      wt 6.0000 -3.1198 0.6613 -4.7175 0.0000 -4.4160 -1.8236 #>      wt 8.0000 -3.1198 0.6613 -4.7175 0.0000 -4.4160 -1.8236  mfx <- marginaleffects(     mod,     by = \"cyl\",     newdata = datagridcf(cyl = c(4, 6, 8))) summary(mfx) #>   Term    Contrast cyl   Effect Std. Error  z value   Pr(>|z|)    2.5 % #> 1  cyl mean(dY/dX)   4  0.03814    0.59989  0.06357 0.94930949 -1.13762 #> 2  cyl mean(dY/dX)   6  0.03814    0.59989  0.06357 0.94930949 -1.13762 #> 3  cyl mean(dY/dX)   8  0.03814    0.59989  0.06357 0.94930949 -1.13762 #> 4   hp mean(dY/dX)   4 -0.08778    0.02665 -3.29366 0.00098892 -0.14002 #> 5   hp mean(dY/dX)   6 -0.04987    0.01539 -3.23974 0.00119639 -0.08004 #> 6   hp mean(dY/dX)   8 -0.01197    0.01081 -1.10649 0.26851517 -0.03316 #> 7   wt mean(dY/dX)   4 -3.11981    0.66132 -4.71754 2.3871e-06 -4.41598 #> 8   wt mean(dY/dX)   6 -3.11981    0.66132 -4.71754 2.3871e-06 -4.41598 #> 9   wt mean(dY/dX)   8 -3.11981    0.66132 -4.71754 2.3871e-06 -4.41598 #>      97.5 % #> 1  1.213899 #> 2  1.213899 #> 3  1.213899 #> 4 -0.035545 #> 5 -0.019701 #> 6  0.009229 #> 7 -1.823648 #> 8 -1.823648 #> 9 -1.823648 #>  #> Model type:  lm  #> Prediction type:  response"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/alternative_software.html","id":"adjusted-predictions","dir":"Articles","previous_headings":"margins and prediction","what":"Adjusted Predictions","title":"Comparisons to alternative software","text":"syntax compute adjusted predictions using predictions package marginaleffects similar:","code":"prediction::prediction(mod) |> head() #>    mpg cyl disp  hp drat    wt  qsec vs am gear carb   fitted se.fitted #> 1 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4 21.90488 0.6927034 #> 2 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4 21.10933 0.6266557 #> 3 22.8   4  108  93 3.85 2.320 18.61  1  1    4    1 25.64753 0.6652076 #> 4 21.4   6  258 110 3.08 3.215 19.44  1  0    3    1 20.04859 0.6041400 #> 5 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2 17.25445 0.7436172 #> 6 18.1   6  225 105 2.76 3.460 20.22  1  0    3    1 19.53360 0.6436862  marginaleffects::predictions(mod) |> head() #>   rowid     type predicted std.error statistic       p.value conf.low conf.high #> 1     1 response  21.90488 0.6927034  31.62231 1.822647e-219 20.48357  23.32619 #> 2     2 response  21.10933 0.6266557  33.68569 9.366966e-249 19.82354  22.39512 #> 3     3 response  25.64753 0.6652076  38.55568  0.000000e+00 24.28264  27.01242 #> 4     4 response  20.04859 0.6041400  33.18534 1.751939e-241 18.80900  21.28819 #> 5     5 response  17.25445 0.7436172  23.20340 4.207206e-119 15.72867  18.78022 #> 6     6 response  19.53360 0.6436862  30.34646 2.797513e-202 18.21286  20.85434 #>    mpg cyl  hp    wt #> 1 21.0   6 110 2.620 #> 2 21.0   6 110 2.875 #> 3 22.8   4  93 2.320 #> 4 21.4   6 110 3.215 #> 5 18.7   8 175 3.440 #> 6 18.1   6 105 3.460"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/alternative_software.html","id":"stata","dir":"Articles","previous_headings":"","what":"Stata","title":"Comparisons to alternative software","text":"Stata good expensive software package statistical analysis. published StataCorp LLC. section compares Stata’s margins command marginaleffects. results produced marginaleffects extensively tested Stata. See test suite list dozens models compared estimates standard errors.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/alternative_software.html","id":"average-marginal-effect-ames","dir":"Articles","previous_headings":"Stata","what":"Average Marginal Effect (AMEs)","title":"Comparisons to alternative software","text":"Marginal effects unit-level quantities. compute “average marginal effects”, first calculate marginal effects observation dataset. , take mean unit-level marginal effects.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/alternative_software.html","id":"stata-1","dir":"Articles","previous_headings":"Stata > Average Marginal Effect (AMEs)","what":"Stata","title":"Comparisons to alternative software","text":"Stata’s margins command marginaleffects function can calculate average marginal effects (AMEs). example showing estimate AMEs Stata:","code":"quietly reg mpg cyl hp wt margins, dydx(*)  Average marginal effects                        Number of obs     =         32 Model VCE    : OLS   Expression   : Linear prediction, predict() dy/dx w.r.t. : cyl hp wt   ------------------------------------------------------------------------------     |            Delta-method     |      dy/dx   Std. Err.      t    P>|t|     [95% Conf. Interval] ------------------------------------------------------------------------------ cyl |  -.9416168   .5509164    -1.71   0.098    -2.070118    .1868842  hp |  -.0180381   .0118762    -1.52   0.140    -.0423655    .0062893  wt |  -3.166973   .7405759    -4.28   0.000    -4.683974   -1.649972 ------------------------------------------------------------------------------"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/alternative_software.html","id":"marginaleffects","dir":"Articles","previous_headings":"Stata > Average Marginal Effect (AMEs)","what":"marginaleffects","title":"Comparisons to alternative software","text":"results can obtained marginaleffects() summary() like : Note Stata reports t statistics marginaleffects reports Z. produces slightly different p-values model low degrees freedom: mtcars 32 rows","code":"library(\"marginaleffects\") mod <- lm(mpg ~ cyl + hp + wt, data = mtcars) mfx <- marginaleffects(mod) summary(mfx) #>   Term   Effect Std. Error z value   Pr(>|z|)    2.5 %    97.5 % #> 1  cyl -0.94162    0.55092  -1.709   0.087417 -2.02139  0.138159 #> 2   hp -0.01804    0.01188  -1.519   0.128803 -0.04132  0.005239 #> 3   wt -3.16697    0.74058  -4.276 1.8997e-05 -4.61848 -1.715471 #>  #> Model type:  lm  #> Prediction type:  response"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/alternative_software.html","id":"counterfactual-marginal-effects","dir":"Articles","previous_headings":"Stata","what":"Counterfactual Marginal Effects","title":"Comparisons to alternative software","text":"“counterfactual marginal effect” special quantity obtained replicating dataset fixing regressor user-defined values. Concretely, Stata computes counterfactual marginal effects 3 steps: Duplicate whole dataset 3 times sets values cyl three specified values subsets. Calculate marginal effects observation large grid. Take average marginal effects value variable interest.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/alternative_software.html","id":"stata-2","dir":"Articles","previous_headings":"Stata > Counterfactual Marginal Effects","what":"Stata","title":"Comparisons to alternative software","text":"argument, Stata’s margins command estimates average counterfactual marginal effects. example:","code":"quietly reg mpg i.cyl##c.hp wt margins, dydx(hp) at(cyl = (4 6 8))  Average marginal effects                        Number of obs     =         32 Model VCE    : OLS  Expression   : Linear prediction, predict() dy/dx w.r.t. : hp  1._at        : cyl             =           4  2._at        : cyl             =           6  3._at        : cyl             =           8  ------------------------------------------------------------------------------              |            Delta-method              |      dy/dx   Std. Err.      t    P>|t|     [95% Conf. Interval] -------------+---------------------------------------------------------------- hp           |          _at |           1  |   -.099466   .0348665    -2.85   0.009    -.1712749   -.0276571           2  |  -.0213768    .038822    -0.55   0.587    -.1013323    .0585787           3  |   -.013441   .0125138    -1.07   0.293    -.0392137    .0123317 ------------------------------------------------------------------------------"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/alternative_software.html","id":"marginaleffects-1","dir":"Articles","previous_headings":"Stata > Counterfactual Marginal Effects","what":"marginaleffects","title":"Comparisons to alternative software","text":"can estimate average counterfactual marginal effects marginaleffects() using datagridcf() create counterfactual dataset full original dataset replicated potential value cyl variable. , tell argument average within groups: equivalent taking group-wise mean observation-level marginal effects: Note following Stata, standard errors group-averaged marginal effects computed taking “Jacobian mean:”","code":"mod <- lm(mpg ~ as.factor(cyl) * hp + wt, data = mtcars)  mfx <- marginaleffects(     mod,     variables = \"hp\",     by = \"cyl\",     newdata = datagridcf(cyl = c(4, 6, 8))) summary(mfx) #>   Term    Contrast cyl   Effect Std. Error z value Pr(>|z|)    2.5 %   97.5 % #> 1   hp mean(dY/dX)   4 -0.09947    0.03487 -2.8528 0.004334 -0.16780 -0.03113 #> 2   hp mean(dY/dX)   6 -0.02138    0.03882 -0.5506 0.581884 -0.09747  0.05471 #> 3   hp mean(dY/dX)   8 -0.01344    0.01251 -1.0741 0.282780 -0.03797  0.01109 #>  #> Model type:  lm  #> Prediction type:  response aggregate(dydx ~ term + cyl, data = mfx, FUN = mean) #>   term cyl        dydx #> 1   hp   4 -0.09946598 #> 2   hp   6 -0.02137679 #> 3   hp   8 -0.01344103 J <- attr(mfx, \"jacobian\") J_mean <- aggregate(J, by = list(mfx$cyl), FUN = mean) J_mean <- as.matrix(J_mean[, 2:ncol(J_mean)]) sqrt(diag(J_mean %*% vcov(mod) %*% t(J_mean))) #> [1] 0.03486650 0.03882203 0.01251382"},{"path":[]},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/alternative_software.html","id":"stata-3","dir":"Articles","previous_headings":"Stata > Average Counterfactual Adjusted Predictions","what":"Stata","title":"Comparisons to alternative software","text":"Just like Stata’s margins command computes average counterfactual marginal effects, can also estimate average counterfactual adjusted predictions. example: , Stata background: duplicates whole dataset 3 times sets values cyl three specified values subsets. calculates predictions large grid. takes average prediction value cyl. words, average counterfactual adjusted predictions implemented Stata hybrid predictions observed values (default marginaleffects::predictions) predictions representative values.","code":"quietly reg mpg i.cyl##c.hp wt margins, at(cyl = (4 6 8))  Predictive margins                              Number of obs     =         32 Model VCE    : OLS  Expression   : Linear prediction, predict()  1._at        : cyl             =           4  2._at        : cyl             =           6  3._at        : cyl             =           8  ------------------------------------------------------------------------------              |            Delta-method              |     Margin   Std. Err.      t    P>|t|     [95% Conf. Interval] -------------+----------------------------------------------------------------          _at |           1  |   17.44233   2.372914     7.35   0.000     12.55522    22.32944           2  |    18.9149   1.291483    14.65   0.000     16.25505    21.57476           3  |   18.33318   1.123874    16.31   0.000     16.01852    20.64785 ------------------------------------------------------------------------------"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/alternative_software.html","id":"marginaleffects-2","dir":"Articles","previous_headings":"Stata > Average Counterfactual Adjusted Predictions","what":"marginaleffects","title":"Comparisons to alternative software","text":"can estimate average counterfactual adjusted predictions predictions() , first, setting grid_type argument datagrid() \"counterfactual\" , second, averaging predictions using argument summary(), manual function like dplyr::summarise().","code":"mod <- lm(mpg ~ as.factor(cyl) * hp + wt, data = mtcars)  pred <- predictions(     mod,     by = \"cyl\",     newdata = datagridcf(cyl = c(4, 6, 8))) summary(pred) #>   cyl Predicted Std. Error z value   Pr(>|z|) CI low CI high #> 1   4     17.44      2.373   7.351 1.9733e-13  12.79   22.09 #> 2   6     18.91      1.291  14.646 < 2.22e-16  16.38   21.45 #> 3   8     18.33      1.124  16.312 < 2.22e-16  16.13   20.54 #>  #> Model type:  lm  #> Prediction type:  response  pred %>%     group_by(cyl) %>%     summarize(AAP = mean(predicted)) #> # A tibble: 3 × 2 #>   cyl     AAP #>   <fct> <dbl> #> 1 4      17.4 #> 2 6      18.9 #> 3 8      18.3"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/alternative_software.html","id":"brmsmargins","dir":"Articles","previous_headings":"","what":"brmsmargins","title":"Comparisons to alternative software","text":"brmsmargins package developed Joshua Wiley: package functions calculate marginal effects brms models ( http://paul-buerkner.github.io/brms/ ). central motivator calculate average marginal effects (AMEs) continuous discrete predictors fixed effects mixed effects regression models including location scale models. main advantage brmsmargins marginaleffects ability compute “Marginal Coefficients” following method described Hedeker et al (2012). main advantages marginaleffects brmsmargins : Support 60+ model types, rather just brms package. Simpler user interface (subjective). time writing (2022-05-25) brmsmargins support certain brms models multivariate multinomial outcomes. also support custom outcome transformations. rest section presents side--side replications analyses brmsmargins vignettes order show highlight parallels differences syntax.","code":""},{"path":[]},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/alternative_software.html","id":"ames-for-logistic-regression","dir":"Articles","previous_headings":"brmsmargins > Marginal Effects for Fixed Effects Models","what":"AMEs for Logistic Regression","title":"Comparisons to alternative software","text":"Estimate logistic regression model brms: Compute AMEs manually: Compute AMEs brmsmargins: Compute AMEs using marginaleffects: mpg element Effect column marginaleffects matches M column output brmsmargins.","code":"library(brms) library(brmsmargins) library(marginaleffects) library(data.table) library(withr) h <- 1e-4  void <- capture.output(     bayes.logistic <- brm(       vs ~ am + mpg, data = mtcars,       family = \"bernoulli\", seed = 1234,       silent = 2, refresh = 0,       chains = 4L, cores = 4L) ) d1 <- d2 <- mtcars d2$mpg <- d2$mpg + h p1 <- posterior_epred(bayes.logistic, newdata = d1) p2 <- posterior_epred(bayes.logistic, newdata = d2) m <- (p2 - p1) / h quantile(rowMeans(m), c(.5, .025, .975)) #>        50%       2.5%      97.5%  #> 0.07014014 0.05437810 0.09159280 bm <- brmsmargins(   bayes.logistic,   add = data.frame(mpg = c(0, 0 + h)),   contrasts = cbind(\"AME MPG\" = c(-1 / h, 1 / h)),   CI = 0.95,   CIType = \"ETI\") data.frame(bm$ContrastSummary) #>            M        Mdn        LL        UL PercentROPE PercentMID   CI CIType #> 1 0.07118446 0.07014014 0.0543781 0.0915928          NA         NA 0.95    ETI #>   ROPE  MID   Label #> 1 <NA> <NA> AME MPG mfx <- marginaleffects(bayes.logistic)  summary(mfx) #>   Term   Effect    2.5 %   97.5 % #> 1   am -0.31810 -0.52182 -0.07808 #> 2  mpg  0.07015  0.05439  0.09158 #>  #> Model type:  brmsfit  #> Prediction type:  response"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/alternative_software.html","id":"marginal-effects-for-mixed-effects-models","dir":"Articles","previous_headings":"brmsmargins","what":"Marginal Effects for Mixed Effects Models","title":"Comparisons to alternative software","text":"Estimate mixed effects logistic regression model brms:","code":"d <- withr::with_seed(   seed = 12345, code = {     nGroups <- 100     nObs <- 20     theta.location <- matrix(rnorm(nGroups * 2), nrow = nGroups, ncol = 2)     theta.location[, 1] <- theta.location[, 1] - mean(theta.location[, 1])     theta.location[, 2] <- theta.location[, 2] - mean(theta.location[, 2])     theta.location[, 1] <- theta.location[, 1] / sd(theta.location[, 1])     theta.location[, 2] <- theta.location[, 2] / sd(theta.location[, 2])     theta.location <- theta.location %*% chol(matrix(c(1.5, -.25, -.25, .5^2), 2))     theta.location[, 1] <- theta.location[, 1] - 2.5     theta.location[, 2] <- theta.location[, 2] + 1     d <- data.table(       x = rep(rep(0:1, each = nObs / 2), times = nGroups))     d[, ID := rep(seq_len(nGroups), each = nObs)]      for (i in seq_len(nGroups)) {       d[ID == i, y := rbinom(         n = nObs,         size = 1,         prob = plogis(theta.location[i, 1] + theta.location[i, 2] * x))         ]     }     copy(d)   })  void <- capture.output(     mlogit <- brms::brm(       y ~ 1 + x + (1 + x | ID), family = \"bernoulli\",       data = d, seed = 1234,       silent = 2, refresh = 0,       chains = 4L, cores = 4L) ) #> Warning: There were 61 divergent transitions after warmup. See #> https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup #> to find out why this is a problem and how to eliminate them. #> Warning: Examine the pairs() plot to diagnose sampling problems #> Warning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#bulk-ess #> Warning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable. #> Running the chains for more iterations may help. See #> https://mc-stan.org/misc/warnings.html#tail-ess"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/alternative_software.html","id":"ame-including-random-effects","dir":"Articles","previous_headings":"brmsmargins > Marginal Effects for Mixed Effects Models","what":"AME: Including Random Effects","title":"Comparisons to alternative software","text":"","code":"bm <- brmsmargins(   mlogit,   add = data.frame(x = c(0, h)),   contrasts = cbind(\"AME x\" = c(-1 / h, 1 / h)),   effects = \"includeRE\",   CI = .95,   CIType = \"ETI\") data.frame(bm$ContrastSummary) #>           M       Mdn         LL        UL PercentROPE PercentMID   CI CIType #> 1 0.1113512 0.1114643 0.08037199 0.1419889          NA         NA 0.95    ETI #>   ROPE  MID Label #> 1 <NA> <NA> AME x  mfx <- marginaleffects(mlogit) summary(mfx) #>   Term Effect   2.5 % 97.5 % #> 1    x 0.1115 0.08037  0.142 #>  #> Model type:  brmsfit  #> Prediction type:  response"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/alternative_software.html","id":"ame-fixed-effects-only-grand-mean","dir":"Articles","previous_headings":"brmsmargins > Marginal Effects for Mixed Effects Models","what":"AME: Fixed Effects Only (Grand Mean)","title":"Comparisons to alternative software","text":"","code":"bm <- brmsmargins(   mlogit,   add = data.frame(x = c(0, h)),   contrasts = cbind(\"AME x\" = c(-1 / h, 1 / h)),   effects = \"fixedonly\",   CI = .95,   CIType = \"ETI\") data.frame(bm$ContrastSummary) #>           M       Mdn         LL        UL PercentROPE PercentMID   CI CIType #> 1 0.1038071 0.1032705 0.06328158 0.1485747          NA         NA 0.95    ETI #>   ROPE  MID Label #> 1 <NA> <NA> AME x  mfx <- marginaleffects(mlogit, re_formula = NA) summary(mfx) #>   Term Effect   2.5 % 97.5 % #> 1    x 0.1033 0.06328 0.1486 #>  #> Model type:  brmsfit  #> Prediction type:  response"},{"path":[]},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/alternative_software.html","id":"ames-for-fixed-effects-location-scale-models","dir":"Articles","previous_headings":"brmsmargins > Marginal Effects for Location Scale Models","what":"AMEs for Fixed Effects Location Scale Models","title":"Comparisons to alternative software","text":"Estimate fixed effects location scale model brms:","code":"d <- withr::with_seed(   seed = 12345, code = {     nObs <- 1000L     d <- data.table(       grp = rep(0:1, each = nObs / 2L),       x = rnorm(nObs, mean = 0, sd = 0.25))     d[, y := rnorm(nObs,                    mean = x + grp,                    sd = exp(1 + x + grp))]     copy(d)   })  void <- capture.output(     ls.fe <- brm(bf(       y ~ 1 + x + grp,       sigma ~ 1 + x + grp),       family = \"gaussian\",       data = d, seed = 1234,       silent = 2, refresh = 0,       chains = 4L, cores = 4L) )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/alternative_software.html","id":"fixed-effects-only","dir":"Articles","previous_headings":"brmsmargins > Marginal Effects for Location Scale Models","what":"Fixed effects only","title":"Comparisons to alternative software","text":"","code":"bm <- brmsmargins(   ls.fe,   add = data.frame(x = c(0, h)),   contrasts = cbind(\"AME x\" = c(-1 / h, 1 / h)),   CI = 0.95, CIType = \"ETI\",   effects = \"fixedonly\") data.frame(bm$ContrastSummary) #>          M     Mdn        LL       UL PercentROPE PercentMID   CI CIType ROPE #> 1 1.625042 1.63264 0.7558805 2.497346          NA         NA 0.95    ETI <NA> #>    MID Label #> 1 <NA> AME x  mfx <- marginaleffects(ls.fe, re_formula = NA) summary(mfx) #>   Term Effect  2.5 % 97.5 % #> 1  grp  1.012 0.3482  1.678 #> 2    x  1.633 0.7559  2.497 #>  #> Model type:  brmsfit  #> Prediction type:  response"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/alternative_software.html","id":"discrete-change-and-distributional-parameter-dpar","dir":"Articles","previous_headings":"brmsmargins > Marginal Effects for Location Scale Models","what":"Discrete change and distributional parameter (dpar)","title":"Comparisons to alternative software","text":"Compute contrast adjusted predictions sigma parameter, grp=0 grp=1: marginaleffects use comparisons() function variables argument:","code":"bm <- brmsmargins(   ls.fe,   at = data.frame(grp = c(0, 1)),   contrasts = cbind(\"AME grp\" = c(-1, 1)),   CI = 0.95, CIType = \"ETI\", dpar = \"sigma\",   effects = \"fixedonly\") data.frame(bm$ContrastSummary) #>          M      Mdn       LL       UL PercentROPE PercentMID   CI CIType ROPE #> 1 4.901384 4.895236 4.404996 5.417512          NA         NA 0.95    ETI <NA> #>    MID   Label #> 1 <NA> AME grp cmp <- comparisons(   ls.fe,   variables = list(grp = 0:1),   dpar = \"sigma\") summary(cmp) #>   Term Contrast Effect 2.5 % 97.5 % #> 1  grp    1 - 0  4.895 4.405  5.418 #>  #> Model type:  brmsfit  #> Prediction type:  response"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/alternative_software.html","id":"marginal-effect-continuous-on-sigma","dir":"Articles","previous_headings":"brmsmargins > Marginal Effects for Location Scale Models","what":"Marginal effect (continuous) on sigma","title":"Comparisons to alternative software","text":"","code":"bm <- brmsmargins(   ls.fe,   add = data.frame(x = c(0, h)),   contrasts = cbind(\"AME x\" = c(-1 / h, 1 / h)),   CI = 0.95, CIType = \"ETI\", dpar = \"sigma\",   effects = \"fixedonly\") data.frame(bm$ContrastSummary) #>          M      Mdn       LL       UL PercentROPE PercentMID   CI CIType ROPE #> 1 4.455297 4.443977 3.500513 5.449401          NA         NA 0.95    ETI <NA> #>    MID Label #> 1 <NA> AME x  mfx <- marginaleffects(ls.fe, dpar = \"sigma\", re_formula = NA) summary(mfx) #>   Term Effect 2.5 % 97.5 % #> 1  grp  5.287 4.694  5.926 #> 2    x  4.444 3.501  5.450 #>  #> Model type:  brmsfit  #> Prediction type:  response"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/alternative_software.html","id":"effects","dir":"Articles","previous_headings":"","what":"effects","title":"Comparisons to alternative software","text":"effects package created John Fox colleagues. marginaleffects supports 30+ model types effects. effects focuses computation “adjusted predictions.” plots produces roughly equivalent ones produced plot_cap predictions functions marginaleffects. effects appear support marginal effects (slopes), marginal means, contrasts effects uses Base graphics whereas marginaleffects uses ggplot2 effects includes lot powerful options customize plots. contrast, marginaleffects produces objects can customized chaining ggplot2 functions. Users can also call plot_cap(model, draw=FALSE) create prediction grid, work raw data directly create plot need effects offers several options currently available marginaleffects, including: Partial residuals plots Many types ways plot adjusted predictions: package vignette","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/alternative_software.html","id":"modelbased","dir":"Articles","previous_headings":"","what":"modelbased","title":"Comparisons to alternative software","text":"modelbased package developed easystats team. section incomplete; contributions welcome. Wrapper around emmeans compute marginal means marginal effects. Powerful functions create beautiful plots.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/alternative_software.html","id":"ggeffects","dir":"Articles","previous_headings":"","what":"ggeffects","title":"Comparisons to alternative software","text":"ggeffects package developed Daniel Lüdecke. section incomplete; contributions welcome. Wrapper around emmeans compute marginal means.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/brms.html","id":"logistic-regression-with-multiplicative-interactions","dir":"Articles","previous_headings":"","what":"Logistic regression with multiplicative interactions","title":"Bayesian analysis with brms","text":"Load libraries download data passengers Titanic Rdatasets archive: Fit logit model multiplicative interaction:","code":"library(marginaleffects) library(brms) library(ggplot2) library(ggdist) library(magrittr)  dat <- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/carData/TitanicSurvival.csv\") dat$survived <- ifelse(dat$survived == \"yes\", 1, 0) dat$woman <- ifelse(dat$sex == \"female\", 1, 0) mod <- brm(survived ~ woman * age + passengerClass,            family = bernoulli(link = \"logit\"),            data = dat)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/brms.html","id":"adjusted-predictions","dir":"Articles","previous_headings":"Logistic regression with multiplicative interactions","what":"Adjusted predictions","title":"Bayesian analysis with brms","text":"can compute adjusted predicted values outcome variable (.e., probability survival aboard Titanic) using predictions function. default, function calculates predictions row dataset: visualize relationship outcome one regressors, can plot conditional adjusted predictions plot_cap function:  Compute adjusted predictions user-specified values regressors, using newdata argument datagrid function: posteriordraws function samples posterior distribution model, produces data frame drawid draw columns. “long” format makes easy plots results:","code":"pred <- predictions(mod) head(pred) #>   rowid     type predicted  conf.low conf.high survived woman     age #> 1     1 response 0.9366604 0.9069674 0.9590097        1     1 29.0000 #> 2     2 response 0.8493050 0.7453010 0.9186720        1     0  0.9167 #> 3     3 response 0.9433293 0.8948592 0.9704210        0     1  2.0000 #> 4     4 response 0.5131011 0.4302430 0.5999582        0     0 30.0000 #> 5     5 response 0.9374937 0.9080051 0.9600572        0     1 25.0000 #> 6     6 response 0.2730542 0.2028999 0.3517513        1     0 48.0000 #>   passengerClass #> 1            1st #> 2            1st #> 3            1st #> 4            1st #> 5            1st #> 6            1st plot_cap(mod, condition = \"age\") pred <- predictions(mod,                     newdata = datagrid(woman = 0:1,                                        passengerClass = c(\"1st\", \"2nd\", \"3rd\"))) pred #>   rowid     type  predicted   conf.low conf.high  survived      age woman #> 1     1 response 0.51492993 0.43192231 0.6018749 0.4082218 29.88113     0 #> 2     2 response 0.20128833 0.15362308 0.2613351 0.4082218 29.88113     0 #> 3     3 response 0.08750369 0.06555724 0.1141134 0.4082218 29.88113     0 #> 4     4 response 0.93641346 0.90660921 0.9587589 0.4082218 29.88113     1 #> 5     5 response 0.77829290 0.70896643 0.8346419 0.4082218 29.88113     1 #> 6     6 response 0.57010265 0.49377997 0.6441967 0.4082218 29.88113     1 #>   passengerClass #> 1            1st #> 2            2nd #> 3            3rd #> 4            1st #> 5            2nd #> 6            3rd pred <- posteriordraws(pred) head(pred) #>   drawid       draw rowid     type  predicted   conf.low conf.high  survived #> 1      1 0.46566713     1 response 0.51492993 0.43192231 0.6018749 0.4082218 #> 2      1 0.16658900     2 response 0.20128833 0.15362308 0.2613351 0.4082218 #> 3      1 0.08750961     3 response 0.08750369 0.06555724 0.1141134 0.4082218 #> 4      1 0.93735755     4 response 0.93641346 0.90660921 0.9587589 0.4082218 #> 5      1 0.77437334     5 response 0.77829290 0.70896643 0.8346419 0.4082218 #> 6      1 0.62216334     6 response 0.57010265 0.49377997 0.6441967 0.4082218 #>        age woman passengerClass #> 1 29.88113     0            1st #> 2 29.88113     0            2nd #> 3 29.88113     0            3rd #> 4 29.88113     1            1st #> 5 29.88113     1            2nd #> 6 29.88113     1            3rd ggplot(pred, aes(x = draw, fill = factor(woman))) +     geom_density() +     facet_grid(~ passengerClass, labeller = label_both) +     labs(x = \"Predicted probability of survival\", y = \"\", fill = \"Woman\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/brms.html","id":"marginal-effects","dir":"Articles","previous_headings":"Logistic regression with multiplicative interactions","what":"Marginal effects","title":"Bayesian analysis with brms","text":"Use marginaleffects() compute marginal effects (slopes regression equation) row dataset, use summary() compute “Average Marginal Effects”, , average observation-level marginal effects: Compute marginal effects regressors fixed user-specified values, regressors held means: Compute plot conditional marginal effects:  posteriordraws produces dataset drawid draw columns: can use dataset plot results. example, plot posterior density marginal effect age woman variable equal 0 1:","code":"mfx <- marginaleffects(mod) summary(mfx) #>             Term  Contrast    Effect     2.5 %    97.5 % #> 1            age     dY/dX -0.005265 -0.007104 -0.003462 #> 2 passengerClass 2nd - 1st -0.237269 -0.309664 -0.164460 #> 3 passengerClass 3rd - 1st -0.389119 -0.454761 -0.322277 #> 4          woman     dY/dX  0.366252  0.336326  0.392362 #>  #> Model type:  brmsfit  #> Prediction type:  response marginaleffects(mod,                 newdata = datagrid(woman = 1,                                    passengerClass = \"1st\")) #>   rowid     type           term  contrast          dydx     conf.low #> 1     1 response          woman     dY/dX  0.1562784430  0.111359140 #> 2     1 response            age     dY/dX -0.0002383118 -0.001355295 #> 3     1 response passengerClass 2nd - 1st -0.1574415687 -0.223274987 #> 4     1 response passengerClass 3rd - 1st -0.3653763624 -0.438319255 #>       conf.high predicted predicted_hi predicted_lo  survived      age woman #> 1  0.2087557243 0.9364135    0.9364295    0.9364135 0.4082218 29.88113     1 #> 2  0.0008710313 0.9364135    0.9364102    0.9364135 0.4082218 29.88113     1 #> 3 -0.1028896556 0.9364135    0.7782929    0.9364135 0.4082218 29.88113     1 #> 4 -0.2947694986 0.9364135    0.5701027    0.9364135 0.4082218 29.88113     1 #>   passengerClass        eps #> 1            1st 0.00010000 #> 2            1st 0.00798333 #> 3            1st         NA #> 4            1st         NA plot_cme(mod, effect = \"woman\", condition = \"age\") draws <- posteriordraws(mfx)  dim(draws) #> [1] 16736000       17  head(draws) #>   drawid      draw rowid     type  term contrast       dydx   conf.low #> 1      1 0.1633609     1 response woman    dY/dX 0.15298096 0.10883007 #> 2      1 0.1359009     2 response woman    dY/dX 0.13546458 0.03607654 #> 3      1 0.0615405     3 response woman    dY/dX 0.05878909 0.02875607 #> 4      1 0.7088821     4 response woman    dY/dX 0.65453708 0.56699300 #> 5      1 0.1473759     5 response woman    dY/dX 0.13828737 0.09722433 #> 6      1 0.6635099     6 response woman    dY/dX 0.70740470 0.58935737 #>   conf.high predicted predicted_hi predicted_lo survived woman     age #> 1 0.2051898 0.9366604    0.9366751    0.9366604        1     1 29.0000 #> 2 0.2970409 0.8493050    0.8493174    0.8493050        1     0  0.9167 #> 3 0.1009453 0.9433293    0.9433358    0.9433293        0     1  2.0000 #> 4 0.7442501 0.5131011    0.5131652    0.5131011        0     0 30.0000 #> 5 0.1863969 0.9374937    0.9375085    0.9374937        0     1 25.0000 #> 6 0.8406470 0.2730542    0.2731252    0.2730542        1     0 48.0000 #>   passengerClass   eps #> 1            1st 1e-04 #> 2            1st 1e-04 #> 3            1st 1e-04 #> 4            1st 1e-04 #> 5            1st 1e-04 #> 6            1st 1e-04 mfx <- marginaleffects(mod,                        variables = \"age\",                        newdata = datagrid(woman = 0:1)) |>        posteriordraws()  ggplot(mfx, aes(x = draw, fill = factor(woman))) +     stat_halfeye(slab_alpha = .5) +     labs(x = \"Marginal Effect of Age on Survival\",          y = \"Posterior density\",          fill = \"Woman\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/brms.html","id":"random-effects-model","dir":"Articles","previous_headings":"","what":"Random effects model","title":"Bayesian analysis with brms","text":"section replicates analyses random effects model published Andrew Heiss’ blog post: “guide correctly calculating posterior predictions average marginal effects multilevel Bayesian models.” objective mainly illustrate use marginaleffects. Please refer original post detailed discussion quantities computed . Load libraries download data: Fit basic model:","code":"library(brms) library(ggdist) library(patchwork) library(marginaleffects)  vdem_2015 <- read.csv(\"https://github.com/vincentarelbundock/marginaleffects/raw/main/data-raw/vdem_2015.csv\")  head(vdem_2015) #>   country_name country_text_id year                           region #> 1       Mexico             MEX 2015  Latin America and the Caribbean #> 2     Suriname             SUR 2015  Latin America and the Caribbean #> 3       Sweden             SWE 2015 Western Europe and North America #> 4  Switzerland             CHE 2015 Western Europe and North America #> 5        Ghana             GHA 2015               Sub-Saharan Africa #> 6 South Africa             ZAF 2015               Sub-Saharan Africa #>   media_index party_autonomy_ord polyarchy civil_liberties party_autonomy #> 1       0.837                  3     0.631           0.704           TRUE #> 2       0.883                  4     0.777           0.887           TRUE #> 3       0.956                  4     0.915           0.968           TRUE #> 4       0.939                  4     0.901           0.960           TRUE #> 5       0.858                  4     0.724           0.921           TRUE #> 6       0.898                  4     0.752           0.869           TRUE mod <- brm(   bf(media_index ~ party_autonomy + civil_liberties + (1 | region),      phi ~ (1 | region)),   data = vdem_2015,   family = Beta(),   control = list(adapt_delta = 0.9))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/brms.html","id":"posterior-predictions","dir":"Articles","previous_headings":"Random effects model","what":"Posterior predictions","title":"Bayesian analysis with brms","text":"compute posterior predictions specific values regressors, use newdata argument datagrid function. also use type argument compute two types predictions: accounting residual (observation-level) residual variance (prediction) ignoring (response). Extract posterior draws plot :","code":"nd = datagrid(model = mod,               party_autonomy = c(TRUE, FALSE),               civil_liberties = .5,               region = \"Middle East and North Africa\") p1 <- predictions(mod, type = \"response\", newdata = nd) %>%     posteriordraws() p2 <- predictions(mod, type = \"prediction\", newdata = nd) %>%     posteriordraws() pred <- rbind(p1, p2) ggplot(pred, aes(x = draw, fill = party_autonomy)) +     stat_halfeye(alpha = .5) +     facet_wrap(~ type) +     labs(x = \"Media index (predicted)\",           y = \"Posterior density\",          fill = \"Party autonomy\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/brms.html","id":"marginal-effects-and-contrasts","dir":"Articles","previous_headings":"Random effects model","what":"Marginal effects and contrasts","title":"Bayesian analysis with brms","text":"noted Marginal Effects vignette, one distinct marginal effect combination regressor values. , consider one combination regressor values, region “Middle East North Africa”, civil_liberties 0.5. , calculate mean posterior distribution marginal effects: Use posteriordraws() extract draws posterior distribution marginal effects, plot :  Plot marginal effects, conditional regressor:","code":"mfx <- marginaleffects(mod,                        newdata = datagrid(civil_liberties = .5,                                           region = \"Middle East and North Africa\")) mfx #>   rowid     type            term     contrast      dydx  conf.low conf.high #> 1     1 response  party_autonomy TRUE - FALSE 0.2517104 0.1663314 0.3355927 #> 2     1 response civil_liberties        dY/dX 0.8160498 0.6213970 1.0066362 #>   predicted predicted_hi predicted_lo media_index party_autonomy #> 1 0.6213442    0.6213442    0.3684876   0.6723184           TRUE #> 2 0.6213442    0.6214182    0.6213442   0.6723184           TRUE #>   civil_liberties                       region      eps #> 1             0.5 Middle East and North Africa       NA #> 2             0.5 Middle East and North Africa 9.56e-05 mfx <- posteriordraws(mfx)  ggplot(mfx, aes(x = draw, y = term)) +   stat_halfeye() +   labs(x = \"Marginal effect\", y = \"\") plot_cme(mod,          effect = \"civil_liberties\",          condition = \"party_autonomy\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/brms.html","id":"continuous-predictors","dir":"Articles","previous_headings":"Random effects model","what":"Continuous predictors","title":"Bayesian analysis with brms","text":"slope line different values civil liberties can obtained : plotted:  marginaleffects function can use ellipsis (...) push argument forward posterior_predict function. can alter types predictions returned. example, re_formula=NA argument posterior_predict.brmsfit method compute marginaleffects without including group-level effects:","code":"pred <- predictions(mod,                     newdata = datagrid(party_autonomy = FALSE,                                        region = \"Middle East and North Africa\",                                        civil_liberties = seq(0, 1, by = 0.05))) |>         posteriordraws()  ggplot(pred, aes(x = civil_liberties, y = draw)) +     stat_lineribbon() +     scale_fill_brewer(palette = \"Reds\") +     labs(x = \"Civil liberties\",          y = \"Media index (predicted)\",          fill = \"\") mfx <- marginaleffects(mod,                        newdata = datagrid(civil_liberties = c(.2, .5, .8),                                           party_autonomy = FALSE,                                           region = \"Middle East and North Africa\"),                        variables = \"civil_liberties\") mfx #>   rowid     type            term      dydx  conf.low conf.high predicted #> 1     1 response civil_liberties 0.4900170 0.3609330 0.6388463 0.1700110 #> 2     2 response civil_liberties 0.8071389 0.6121827 0.9926679 0.3684876 #> 3     3 response civil_liberties 0.8069026 0.6744996 0.9336997 0.6244447 #>   predicted_hi predicted_lo media_index civil_liberties party_autonomy #> 1    0.1700591    0.1700110   0.6723184             0.2          FALSE #> 2    0.3685630    0.3684876   0.6723184             0.5          FALSE #> 3    0.6245229    0.6244447   0.6723184             0.8          FALSE #>                         region      eps #> 1 Middle East and North Africa 9.56e-05 #> 2 Middle East and North Africa 9.56e-05 #> 3 Middle East and North Africa 9.56e-05 mfx <- posteriordraws(mfx)  ggplot(mfx, aes(x = draw, fill = factor(civil_liberties))) +     stat_halfeye(slab_alpha = .5) +     labs(x = \"Marginal effect of Civil Liberties on Media Index\",          y = \"Posterior density\",          fill = \"Civil liberties\") mfx <- marginaleffects(mod,                        newdata = datagrid(civil_liberties = c(.2, .5, .8),                                           party_autonomy = FALSE,                                           region = \"Middle East and North Africa\"),                        variables = \"civil_liberties\",                        re_formula = NA) |>        posteriordraws()  ggplot(mfx, aes(x = draw, fill = factor(civil_liberties))) +     stat_halfeye(slab_alpha = .5) +     labs(x = \"Marginal effect of Civil Liberties on Media Index\",          y = \"Posterior density\",          fill = \"Civil liberties\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/brms.html","id":"global-grand-mean","dir":"Articles","previous_headings":"Random effects model","what":"Global grand mean","title":"Bayesian analysis with brms","text":"","code":"pred <- predictions(mod,                     re_formula = NA,                     newdata = datagrid(party_autonomy = c(TRUE, FALSE))) |>         posteriordraws()  mfx <- marginaleffects(mod,                        re_formula = NA,                        variables = \"party_autonomy\") |>        posteriordraws()  plot1 <- ggplot(pred, aes(x = draw, fill = party_autonomy)) +          stat_halfeye(slab_alpha = .5) +          labs(x = \"Media index (Predicted)\",               y = \"Posterior density\",               fill = \"Party autonomy\")  plot2 <- ggplot(mfx, aes(x = draw)) +          stat_halfeye(slab_alpha = .5)  +          labs(x = \"Contrast: Party autonomy TRUE - FALSE\",               y = \"\",               fill = \"Party autonomy\")  # combine plots using the `patchwork` package plot1 + plot2"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/brms.html","id":"region-specific-predictions-and-contrasts","dir":"Articles","previous_headings":"Random effects model","what":"Region-specific predictions and contrasts","title":"Bayesian analysis with brms","text":"Predicted media index region level civil liberties:  Predicted media index region level civil liberties:  Predicted media index region party autonomy:  TRUE/FALSE contrasts (marginal effects) party autonomy region:","code":"pred <- predictions(mod,                     newdata = datagrid(region = vdem_2015$region,                                        party_autonomy = FALSE,                                         civil_liberties = seq(0, 1, length.out = 100))) |>          posteriordraws()  ggplot(pred, aes(x = civil_liberties, y = draw)) +     stat_lineribbon() +     scale_fill_brewer(palette = \"Reds\") +     facet_wrap(~ region) +     labs(x = \"Civil liberties\",          y = \"Media index (predicted)\",          fill = \"\") pred <- predictions(mod,                     newdata = datagrid(region = vdem_2015$region,                                        civil_liberties = c(.2, .8),                                       party_autonomy = FALSE)) |>         posteriordraws()  ggplot(pred, aes(x = draw, fill = factor(civil_liberties))) +     stat_halfeye(slab_alpha = .5) +     facet_wrap(~ region) +     labs(x = \"Media index (predicted)\",          y = \"Posterior density\",          fill = \"Civil liberties\") pred <- predictions(mod,                     newdata = datagrid(region = vdem_2015$region,                                        party_autonomy = c(TRUE, FALSE),                                        civil_liberties = .5)) |>         posteriordraws()  ggplot(pred, aes(x = draw, y = region , fill = party_autonomy)) +     stat_halfeye(slab_alpha = .5) +     labs(x = \"Media index (predicted)\",          y = \"\",          fill = \"Party autonomy\") mfx <- marginaleffects(mod,                        variables = \"party_autonomy\",                        newdata = datagrid(region = vdem_2015$region,                                           civil_liberties = .5)) |>         posteriordraws()  ggplot(mfx, aes(x = draw, y = region , fill = party_autonomy)) +     stat_halfeye(slab_alpha = .5) +     labs(x = \"Media index (predicted)\",          y = \"\",          fill = \"Party autonomy\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/brms.html","id":"hypothetical-groups","dir":"Articles","previous_headings":"Random effects model","what":"Hypothetical groups","title":"Bayesian analysis with brms","text":"can also obtain predictions marginal effects hypothetical group instead one observed regions. achieve , create dataset NA region column. call marginaleffects predictions functions allow_new_levels argument. argument pushed via ellipsis (...) posterior_epred function brms package:","code":"dat <- data.frame(civil_liberties = .5,                   party_autonomy = FALSE,                   region = \"New Region\")  mfx <- marginaleffects(     mod,     variables = \"party_autonomy\",     allow_new_levels = TRUE,     newdata = dat)  draws <- posteriordraws(mfx)  ggplot(draws, aes(x = draw)) +      stat_halfeye() +      labs(x = \"Marginal effect of party autonomy in a generic world region\", y = \"\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/brms.html","id":"averaging-marginalizing-integrating-random-effects","dir":"Articles","previous_headings":"Random effects model","what":"Averaging, marginalizing, integrating random effects","title":"Bayesian analysis with brms","text":"Consider logistic regression model random effects: can compute adjusted predictions given value x firm (random effects) follows: can average/marginalize/integrate across random effects tidy function argument: can also draw (assumed gaussian) population distribution random effects, asking predictions() make predictions new “levels” random effects. take average predictions using tidy() , “integrated random effects”, described brmsmargins package vignette. code , make predictions 100 firm identifiers original dataset. also ask predictions() push forward allow_new_levels sample_new_levels arguments brms::posterior_epred function: can “integrate ” random effects marginaleffects functions . instance, nearly equivalent brmsmargins command output (slight variations due different random seeds): See alternative software vignette information brmsmargins.","code":"dat <- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/plm/EmplUK.csv\") dat$x <- as.numeric(dat$output > median(dat$output)) dat$y <- as.numeric(dat$emp > median(dat$emp)) mod <- brm(y ~ x + (1 | firm), data = dat, backend = \"cmdstanr\", family = \"bernoulli\") p <- predictions(mod, newdata = datagrid(x = 0, firm = unique)) head(p) #>   rowid     type    predicted     conf.low   conf.high        y x firm #> 1     1 response 9.999974e-01 9.012039e-01 1.000000000 0.499515 0    1 #> 2     2 response 9.999976e-01 8.946581e-01 1.000000000 0.499515 0    2 #> 3     3 response 9.999968e-01 9.120847e-01 1.000000000 0.499515 0    3 #> 4     4 response 9.999948e-01 7.971402e-01 1.000000000 0.499515 0    4 #> 5     5 response 9.999984e-01 9.089520e-01 1.000000000 0.499515 0    5 #> 6     6 response 4.899093e-08 8.417651e-21 0.001898002 0.499515 0    6 predictions(mod, newdata = datagrid(x = 0, firm = unique)) |> tidy() #>        type  estimate  conf.low conf.high #> 1: response 0.4538567 0.4395532 0.4683439  predictions(mod, newdata = datagrid(x = 0:1, firm = unique), by = \"x\") #>       type x predicted  conf.low conf.high #> 1 response 0 0.4538567 0.4395532 0.4683439 #> 2 response 1 0.5571714 0.5456459 0.5696210 predictions(     mod,     newdata = datagrid(x = 0:1, firm = -1:-100),     allow_new_levels = TRUE,     sample_new_levels = \"gaussian\",     by = \"x\") #>       type x predicted  conf.low conf.high #> 1 response 0 0.4515202 0.3416259 0.5659155 #> 2 response 1 0.5510228 0.4361979 0.6635158 comparisons(     mod,     newdata = datagrid(firm = -1:-100),     allow_new_levels = TRUE,     sample_new_levels = \"gaussian\") |>     summary() #>   Term Contrast  Effect   2.5 % 97.5 % #> 1    x    1 - 0 0.09665 0.04753 0.1626 #>  #> Model type:  brmsfit  #> Prediction type:  response library(brmsmargins) bm <- brmsmargins(   k = 100,   object = mod,   at = data.frame(x = c(0, 1)),   CI = .95,   CIType = \"ETI\",   contrasts = cbind(\"AME x\" = c(-1, 1)),   effects = \"integrateoutRE\") bm$ContrastSummary |> data.frame() #>            M        Mdn         LL        UL PercentROPE PercentMID   CI CIType #> 1 0.09849443 0.09657406 0.04810063 0.1602947          NA         NA 0.95    ETI #>   ROPE  MID Label #> 1 <NA> <NA> AME x"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/brms.html","id":"multinomial-logit","dir":"Articles","previous_headings":"","what":"Multinomial logit","title":"Bayesian analysis with brms","text":"Fit model categorical outcome (heating system choice California houses) logit link:","code":"dat <- \"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Heating.csv\" dat <- read.csv(dat) mod <- brm(depvar ~ ic.gc + oc.gc,            data = dat,            family = categorical(link = \"logit\"))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/brms.html","id":"adjusted-predictions-1","dir":"Articles","previous_headings":"Multinomial logit","what":"Adjusted predictions","title":"Bayesian analysis with brms","text":"Compute predicted probabilities level outcome variable: Extract posterior draws plot :  Use plot_cap function plot conditional adjusted predictions level outcome variable gear, conditional value mpg regressor:","code":"pred <- predictions(mod)  head(pred) #>   rowid     type group  predicted   conf.low  conf.high depvar  ic.gc  oc.gc #> 1     1 response    ec 0.06626689 0.04471591 0.09304536     gc 866.00 199.69 #> 2     2 response    ec 0.07681658 0.05896082 0.09740047     gc 727.93 168.66 #> 3     3 response    ec 0.10300017 0.06181137 0.15849874     gc 599.48 165.58 #> 4     4 response    ec 0.06335247 0.04590258 0.08378809     er 835.17 180.88 #> 5     5 response    ec 0.07452660 0.05739728 0.09467869     er 755.59 174.91 #> 6     6 response    ec 0.07086098 0.04545918 0.10359585     gc 666.11 135.67 draws <- posteriordraws(pred)  ggplot(draws, aes(x = draw, fill = group)) +     geom_density(alpha = .2, color = \"white\") +     labs(x = \"Predicted probability\",          y = \"Density\",          fill = \"Heating system\") plot_cap(mod, condition = \"oc.gc\") +     facet_wrap(~ group) +     labs(y = \"Predicted probability\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/brms.html","id":"marginal-effects-1","dir":"Articles","previous_headings":"Multinomial logit","what":"Marginal effects","title":"Bayesian analysis with brms","text":"","code":"mfx <- marginaleffects(mod) summary(mfx) #>   Group  Term   Effect   2.5 %   97.5 % #> 1    ec ic.gc   4.3839   4.007   4.7376 #> 2    ec oc.gc  19.3866  17.717  20.9493 #> 3    er ic.gc   0.0928  -0.270   0.4149 #> 4    er oc.gc   0.4105  -1.194   1.8349 #> 5    gc ic.gc  -7.9963  -8.498  -7.4477 #> 6    gc oc.gc -35.3623 -37.581 -32.9363 #>  #> Model type:  brmsfit  #> Prediction type:  response"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/brms.html","id":"hurdle-models","dir":"Articles","previous_headings":"","what":"Hurdle models","title":"Bayesian analysis with brms","text":"section replicates analyses yet another amazing blog post Andrew Heiss. begin, estimate hurdle model brms random effects, using data gapminder package:","code":"library(gapminder) library(brms) library(dplyr) library(ggplot2) library(ggdist) library(cmdstanr) library(patchwork) library(marginaleffects)  set.seed(1024)  CHAINS <- 4 ITER <- 2000 WARMUP <- 1000 BAYES_SEED <- 1234  gapminder <- gapminder::gapminder |>    filter(continent != \"Oceania\") |>    # Make a bunch of GDP values 0   mutate(prob_zero = ifelse(lifeExp < 50, 0.3, 0.02),          will_be_zero = rbinom(n(), 1, prob = prob_zero),          gdpPercap = ifelse(will_be_zero, 0, gdpPercap)) |>    select(-prob_zero, -will_be_zero) |>    # Make a logged version of GDP per capita   mutate(log_gdpPercap = log1p(gdpPercap)) |>    mutate(is_zero = gdpPercap == 0)  mod <- brm(   bf(gdpPercap ~ lifeExp + year + (1 + lifeExp + year | continent),      hu ~ lifeExp),   data = gapminder,   backend = \"cmdstanr\",   family = hurdle_lognormal(),   cores = 2,   chains = CHAINS, iter = ITER, warmup = WARMUP, seed = BAYES_SEED,   silent = 2)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/brms.html","id":"adjusted-predictions-2","dir":"Articles","previous_headings":"Hurdle models","what":"Adjusted predictions","title":"Bayesian analysis with brms","text":"Adjusted predictions every observation original data: Adjusted predictions hu parameter: Predictions different scale: Plot adjusted predictions function lifeExp:  Predictions one condition re_formula argument brms:","code":"predictions(mod) %>% head() #>   rowid     type predicted conf.low conf.high gdpPercap lifeExp year continent #> 1     1 response  142.5456 103.1327  218.8240  779.4453  28.801 1952      Asia #> 2     2 response  168.2657 124.8506  255.8359  820.8530  30.332 1957      Asia #> 3     3 response  201.7414 152.9039  303.6894  853.1007  31.997 1962      Asia #> 4     4 response  251.4996 196.5698  372.8495  836.1971  34.020 1967      Asia #> 5     5 response  312.2482 249.5193  454.2419    0.0000  36.088 1972      Asia #> 6     6 response  397.5390 324.5934  566.6799  786.1134  38.438 1977      Asia predictions(mod, dpar = \"hu\") %>% head() #>   rowid     type predicted  conf.low conf.high gdpPercap lifeExp year continent #> 1     1 response 0.5739495 0.4746831 0.6515670  779.4453  28.801 1952      Asia #> 2     2 response 0.5365013 0.4416000 0.6112908  820.8530  30.332 1957      Asia #> 3     3 response 0.4955596 0.4069162 0.5664250  853.1007  31.997 1962      Asia #> 4     4 response 0.4455042 0.3656259 0.5106086  836.1971  34.020 1967      Asia #> 5     5 response 0.3957129 0.3251678 0.4537019    0.0000  36.088 1972      Asia #> 6     6 response 0.3413458 0.2823879 0.3907218  786.1134  38.438 1977      Asia predictions(mod, type = \"link\", dpar = \"hu\") %>% head() #>   rowid type   predicted   conf.low   conf.high gdpPercap lifeExp year #> 1     1 link  0.29798370 -0.1013542  0.62593415  779.4453  28.801 1952 #> 2     2 link  0.14626541 -0.2346709  0.45274118  820.8530  30.332 1957 #> 3     3 link -0.01776198 -0.3767284  0.26727993  853.1007  31.997 1962 #> 4     4 link -0.21885246 -0.5510282  0.04244063  836.1971  34.020 1967 #> 5     5 link -0.42336036 -0.7301227 -0.18572429    0.0000  36.088 1972 #> 6     6 link -0.65730248 -0.9326474 -0.44427921  786.1134  38.438 1977 #>   continent #> 1      Asia #> 2      Asia #> 3      Asia #> 4      Asia #> 5      Asia #> 6      Asia plot_cap(     mod,     condition = \"lifeExp\") +     labs(y = \"mu\") + plot_cap(     mod,     dpar = \"hu\",     condition = \"lifeExp\") +     labs(y = \"hu\") plot_cap(     mod,     re_formula = NULL,     condition = c(\"lifeExp\", \"continent\"))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/brms.html","id":"extract-draws-with-posteriordraws","dir":"Articles","previous_headings":"Hurdle models","what":"Extract draws with posteriordraws()","title":"Bayesian analysis with brms","text":"posteriordraws() function extract raw samples posterior objects produced marginaleffects. allows us use richer geoms summaries, ggdist package:","code":"predictions(     mod,     re_formula = NULL,     newdata = datagrid(model = mod,                        continent = gapminder$continent,                        year = c(1952, 2007),                        lifeExp = seq(30, 80, 1))) %>%     posteriordraws() %>%     ggplot(aes(lifeExp, draw, fill = continent, color = continent)) +     stat_lineribbon(alpha = .25) +     facet_grid(year ~ continent)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/brms.html","id":"average-contrasts","dir":"Articles","previous_headings":"Hurdle models","what":"Average Contrasts","title":"Bayesian analysis with brms","text":"happens gdpPercap lifeExp increases one? happens gdpPercap lifeExp increases one standard deviation? happens gdpPercap lifeExp increases 50 60 year simultaneously increases min max? Plot draws posterior distribution average contrasts (thing draws posterior distribution contrasts):","code":"comparisons(mod) %>% summary() #>      Term Contrast Effect  2.5 % 97.5 % #> 1 lifeExp       +1 718.87 515.58 811.96 #> 2    year       +1 -63.82 -84.44 -41.05 #>  #> Model type:  brmsfit  #> Prediction type:  response comparisons(mod, variables = list(lifeExp = \"sd\")) %>% summary() #>      Term                Contrast Effect 2.5 % 97.5 % #> 1 lifeExp (x + sd/2) - (x - sd/2)   4050  3718   4741 #>  #> Model type:  brmsfit  #> Prediction type:  response comparisons(     mod,     variables = list(lifeExp = c(50, 60), year = \"minmax\"),     cross = TRUE) %>%     summary() #>    Term contrast_lifeExp contrast_year Effect 2.5 % 97.5 % #> 1 cross          60 - 50     Max - Min  834.7 523.1   1404 #>  #> Model type:  brmsfit  #> Prediction type:  response comparisons(mod) %>%     summary() %>%     posteriordraws() %>%     ggplot(aes(estimate, term)) +     stat_dotsinterval() +     labs(x = \"Posterior distribution of average contrasts\", y = \"\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/brms.html","id":"marginal-effects-slopes","dir":"Articles","previous_headings":"Hurdle models","what":"Marginal effects (slopes)","title":"Bayesian analysis with brms","text":"Average Marginal Effect lifeExp different scales different parameters: Plot Conditional Marginal Effects  can call marginaleffects() comparisons() posteriordraws() function even control:","code":"marginaleffects(mod) |> summary() #>      Term Effect  2.5 % 97.5 % #> 1 lifeExp 718.71 515.56 811.70 #> 2    year -63.82 -84.44 -41.05 #>  #> Model type:  brmsfit  #> Prediction type:  response  marginaleffects(mod, type = \"link\") |> summary() #>      Term   Effect    2.5 %    97.5 % #> 1 lifeExp  0.08249  0.07419  0.088564 #> 2    year -0.00937 -0.01201 -0.006316 #>  #> Model type:  brmsfit  #> Prediction type:  link  marginaleffects(mod, dpar = \"hu\") |> summary() #>      Term    Effect     2.5 %    97.5 % #> 1 lifeExp -0.008171 -0.009367 -0.006687 #>  #> Model type:  brmsfit  #> Prediction type:  response  marginaleffects(mod, dpar = \"hu\", type = \"link\") |> summary() #>      Term   Effect   2.5 %   97.5 % #> 1 lifeExp -0.09934 -0.1132 -0.08382 #>  #> Model type:  brmsfit  #> Prediction type:  link plot_cme(     mod,     effect = \"lifeExp\",     condition = \"lifeExp\") +     labs(y = \"mu\") +  plot_cme(     mod,     dpar = \"hu\",     effect = \"lifeExp\",     condition = \"lifeExp\") +     labs(y = \"hu\") comparisons(     mod,     type = \"link\",     variables = \"lifeExp\",     newdata = datagrid(lifeExp = c(40, 70), continent = gapminder$continent)) %>%     posteriordraws() %>%     ggplot(aes(draw, continent, fill = continent)) +     stat_dotsinterval() +     facet_grid(lifeExp ~ .) +     labs(x = \"Effect of a 1 unit change in Life Expectancy\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/brms.html","id":"bayesian-estimates-and-credible-intervals","dir":"Articles","previous_headings":"","what":"Bayesian estimates and credible intervals","title":"Bayesian analysis with brms","text":"bayesian models like produced brms rstanarm packages, marginaleffects package functions report median posterior distribution main estimates. default credible intervals equal-tailed intervals (quantiles), default function identify center distribution median. Users can customize type intervals reported setting global options. Note reported estimate intervals change slightly:","code":"library(insight) library(marginaleffects)  mod <- insight::download_model(\"brms_1\")  options(marginaleffects_posterior_interval = \"hdi\") options(marginaleffects_posterior_center = mean) comparisons(mod) |> summary() #>   Term Contrast Effect  2.5 %  97.5 % #> 1  cyl       +1 -1.500 -2.385 -0.6771 #> 2   wt       +1 -3.206 -4.704 -1.5704 #>  #> Model type:  brmsfit  #> Prediction type:  response  options(marginaleffects_posterior_interval = \"eti\") options(marginaleffects_posterior_center = stats::median) comparisons(mod) |> summary() #>   Term Contrast Effect  2.5 %  97.5 % #> 1  cyl       +1 -1.494 -2.361 -0.6361 #> 2   wt       +1 -3.195 -4.792 -1.6450 #>  #> Model type:  brmsfit  #> Prediction type:  response"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/brms.html","id":"random-variables-posterior-and-ggdist","dir":"Articles","previous_headings":"","what":"Random variables: posterior and ggdist","title":"Bayesian analysis with brms","text":"Note: rest section requires version 0.8.1 marginaleffects, development version. Recent versions posterior, brms, ggdist packages make easy draw, summarize plot random variables. posteriordraws() can produce objects class rvar make easy use features returning data frame column type rvar:","code":"library(brms) library(ggdist) library(ggplot2) library(marginaleffects) mod <- brm(mpg ~ am, data = mtcars) p <- predictions(mod, by = \"am\") rvar <- posteriordraws(p, shape = \"rvar\")  rvar #>       type am predicted conf.low conf.high                rvar #> 1 response  0  17.13586 14.91663  19.28336 17.12590 ± 1.125765 #> 2 response  1  24.36238 21.54836  27.16601 24.36038 ± 1.427432  ggplot(rvar, aes(y = am, xdist = rvar)) +    stat_slabinterval()"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/brms.html","id":"non-linear-hypothesis-testing","dir":"Articles","previous_headings":"","what":"Non-linear hypothesis testing","title":"Bayesian analysis with brms","text":"Note: rest section requires version 0.8.1 marginaleffects, development version. begin estimating model: Notice can compute average contrasts two different ways, using tidy() function transform_pre argument: Now, use hypothesis argument compare first second rows comparisons() output: hypothesis function brms package can also perform non-linear hypothesis testing, generates convenient statistics summaries. function accepts D--P matrix draws posterior distribution, D number draws N number parameters. can obtain matrix using posteriordraws(x, shape = \"DxP\"), can simply add couple calls chain operations:","code":"mod <- brm(am ~ mpg + hp, data = mtcars, family = bernoulli(),            seed = 1024, silent = 2, chains = 4, iter = 1000) comparisons(mod) |> tidy() #>       type term contrast    estimate   conf.low   conf.high #> 1 response   hp       +1 0.005987268 0.00288400 0.008860451 #> 2 response  mpg       +1 0.135474011 0.07871312 0.174722602  comparisons(mod, transform_pre = \"differenceavg\") #>       type term contrast  comparison   conf.low   conf.high predicted #> 1 response  mpg mean(+1) 0.135474011 0.07871312 0.174722602 0.2029083 #> 2 response   hp mean(+1) 0.005987268 0.00288400 0.008860451 0.2029083 #>   predicted_hi predicted_lo #> 1    0.3718606   0.09989568 #> 2    0.2085257   0.19744730 comparisons(     mod,     transform_pre = \"differenceavg\",     hypothesis = \"b1 - b2 = 0.2\") #>       type      term  comparison   conf.low   conf.high #> 1 response b1-b2=0.2 -0.07020984 -0.1251562 -0.03339701 comparisons(mod) |>     tidy() |>     posteriordraws(shape = \"DxP\") |>     brms::hypothesis(\"b2 - b1 > .2\") #> Hypothesis Tests for class : #>         Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob #> 1 (b2-b1)-(.2) > 0    -0.07      0.02    -0.12    -0.04          0         0 #>   Star #> 1      #> --- #> 'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses. #> '*': For one-sided hypotheses, the posterior probability exceeds 95%; #> for two-sided hypotheses, the value tested against lies outside the 95%-CI. #> Posterior probabilities of point hypotheses assume equal prior probabilities."},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/contrasts.html","id":"simple-example-titanic","dir":"Articles","previous_headings":"","what":"Simple example: Titanic","title":"Contrasts","text":"Consider logistic regression model estimated using Titanic mortality data: question interests us : probability survival (outcome) change passenger travels 1st class vs. 3rd class? answer question straightforward , non-linear models interactions, effect change one variable depends values covariates model. Therefore, need refine question: probability survival (outcome) change 25 year old man travels 1st class vs. 3rd class? , estimand difference probabilities PClass=\"1st\" PClass=\"3rd\", estimand conditional values covariates Age=25 SexCode=1. comparisons() function, variables argument determines scientific query (estimand comparison), newdata argument determines estimate query (conditional covariate values). example: can compute contrast different “kinds” individuals, changing datagrid() call. function accepts functions vectors. , compute contrast probabilities survival 1st 3rd class oldest men women passengers: specify newdata argument, comparisons() calculate contrast every single combination covariate values original data. means obtain data frame results number rows original data. makes sense, non-linear models models interactions, individual can different contrast: big dataset contrasts like one can unwieldy. common strategy summarize unit-level contrasts taking average. can achieved using tidy() summary() functions: can also compute several average contrasts time: Note average contrasts often nice interpretation causal inference context, outcome parametric g-formula estimation. See vignette: https://vincentarelbundock.github.io/marginaleffects/articles/gformula.html rest vignette highlights features flexible powerful comparisons() function.","code":"library(marginaleffects)  dat <- \"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Titanic.csv\" dat <- read.csv(dat) mod <- glm(Survived ~ PClass * SexCode * Age, data = dat, family = binomial) comparisons(   mod,   variables = list(PClass = c(\"3rd\", \"1st\")),   newdata = datagrid(Age = 25, SexCode = 0)) #>   rowid     type   term  contrast comparison  std.error statistic    p.value #> 1     1 response PClass 1st - 3rd  0.3917678 0.07490717  5.230044 1.6947e-07 #>    conf.low conf.high predicted predicted_hi predicted_lo Survived PClass Age #> 1 0.2449524 0.5385831 0.1453863    0.5371541    0.1453863        0    3rd  25 #>   SexCode #> 1       0 comparisons(   mod,   variables = list(PClass = c(\"3rd\", \"1st\")),   newdata = datagrid(Age = range, SexCode = 0:1)) #>   rowid     type   term  contrast comparison  std.error statistic      p.value #> 1     1 response PClass 1st - 3rd 0.44260054 0.14817543  2.987004 0.0028172644 #> 2     2 response PClass 1st - 3rd 0.47017866 0.13297352  3.535882 0.0004064163 #> 3     3 response PClass 1st - 3rd 0.07106843 0.04532685  1.567910 0.1169020596 #> 4     4 response PClass 1st - 3rd 0.52411165 0.20599037  2.544350 0.0109481246 #>      conf.low conf.high  predicted predicted_hi predicted_lo Survived PClass #> 1  0.15218203 0.7330190 0.37434756   0.81694809   0.37434756        0    3rd #> 2  0.20955535 0.7308020 0.45484038   0.92501904   0.45484038        0    3rd #> 3 -0.01777056 0.1599074 0.01628383   0.08735226   0.01628383        0    3rd #> 4  0.12037794 0.9278454 0.44276383   0.96687548   0.44276383        0    3rd #>     Age SexCode #> 1  0.17       0 #> 2  0.17       1 #> 3 71.00       0 #> 4 71.00       1 cmp <- comparisons(   mod,   variables = list(PClass = c(\"3rd\", \"1st\")))  # number of contrast estimates nrow(cmp) #> [1] 756  # number of observations in the model nobs(mod) #> [1] 756 cmp <- comparisons(   mod,   variables = list(PClass = c(\"3rd\", \"1st\")))  summary(cmp) #>     Term  Contrast Effect Std. Error z value   Pr(>|z|)  2.5 % 97.5 % #> 1 PClass 1st - 3rd 0.3957    0.04253   9.303 < 2.22e-16 0.3123  0.479 #>  #> Model type:  glm  #> Prediction type:  response comparisons(mod) |> summary() #>      Term  Contrast    Effect Std. Error z value   Pr(>|z|)     2.5 %    97.5 % #> 1  PClass 2nd - 1st -0.224836   0.040523  -5.548 2.8839e-08 -0.304259 -0.145412 #> 2  PClass 3rd - 1st -0.395676   0.042530  -9.303 < 2.22e-16 -0.479034 -0.312318 #> 3 SexCode     1 - 0  0.497307   0.030171  16.483 < 2.22e-16  0.438172  0.556442 #> 4     Age        +1 -0.006096   0.001105  -5.515 3.4822e-08 -0.008262 -0.003929 #>  #> Model type:  glm  #> Prediction type:  response"},{"path":[]},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/contrasts.html","id":"logical-and-factor-predictors","dir":"Articles","previous_headings":"Predictor types","what":"Logical and factor predictors","title":"Contrasts","text":"Consider simple model logical factor variable: marginaleffects function automatically computes contrasts level categorical variables, relative baseline category (FALSE logicals, reference level factors), holding values mode mean: summary printed says moving reference category 4 level 6 cyl factor variable associated change -6.156 adjusted prediction. Similarly, contrast FALSE TRUE variable equal 2.560. can obtain different contrasts using comparisons() function. example: comparison, code produces results using emmeans package: Note commands also work types models, GLMs, different scales:","code":"library(marginaleffects) library(magrittr)  tmp <- mtcars tmp$am <- as.logical(tmp$am) mod <- lm(mpg ~ am + factor(cyl), tmp) mfx <- marginaleffects(mod) summary(mfx) #>   Term     Contrast  Effect Std. Error z value   Pr(>|z|)     2.5 % 97.5 % #> 1   am TRUE - FALSE   2.560      1.298   1.973    0.04851   0.01675  5.103 #> 2  cyl        6 - 4  -6.156      1.536  -4.009 6.1077e-05  -9.16608 -3.146 #> 3  cyl        8 - 4 -10.068      1.452  -6.933 4.1146e-12 -12.91359 -7.222 #>  #> Model type:  lm  #> Prediction type:  response comparisons(mod, variables = list(cyl = \"sequential\")) %>% tidy() #>       type term contrast  estimate std.error statistic      p.value  conf.low #> 1 response  cyl    6 - 4 -6.156118  1.535723 -4.008612 6.107658e-05 -9.166079 #> 2 response  cyl    8 - 6 -3.911442  1.470254 -2.660385 7.805144e-03 -6.793087 #>   conf.high #> 1 -3.146156 #> 2 -1.029797 comparisons(mod, variables = list(cyl = \"pairwise\")) %>% tidy() #>       type term contrast   estimate std.error statistic      p.value   conf.low #> 1 response  cyl    6 - 4  -6.156118  1.535723 -4.008612 6.107658e-05  -9.166079 #> 2 response  cyl    8 - 4 -10.067560  1.452082 -6.933187 4.114626e-12 -12.913589 #> 3 response  cyl    8 - 6  -3.911442  1.470254 -2.660385 7.805144e-03  -6.793087 #>   conf.high #> 1 -3.146156 #> 2 -7.221530 #> 3 -1.029797 comparisons(mod, variables = list(cyl = \"reference\")) %>% tidy() #>       type term contrast   estimate std.error statistic      p.value   conf.low #> 1 response  cyl    6 - 4  -6.156118  1.535723 -4.008612 6.107658e-05  -9.166079 #> 2 response  cyl    8 - 4 -10.067560  1.452082 -6.933187 4.114626e-12 -12.913589 #>   conf.high #> 1 -3.146156 #> 2 -7.221530 library(emmeans) emm <- emmeans(mod, specs = \"cyl\") contrast(emm, method = \"revpairwise\") #>  contrast    estimate   SE df t.ratio p.value #>  cyl6 - cyl4    -6.16 1.54 28  -4.009  0.0012 #>  cyl8 - cyl4   -10.07 1.45 28  -6.933  <.0001 #>  cyl8 - cyl6    -3.91 1.47 28  -2.660  0.0331 #>  #> Results are averaged over the levels of: am  #> P value adjustment: tukey method for comparing a family of 3 estimates  emm <- emmeans(mod, specs = \"am\") contrast(emm, method = \"revpairwise\") #>  contrast     estimate  SE df t.ratio p.value #>  TRUE - FALSE     2.56 1.3 28   1.973  0.0585 #>  #> Results are averaged over the levels of: cyl mod_logit <- glm(am ~ factor(gear), data = mtcars, family = binomial)  comparisons(mod_logit) %>% tidy() #>       type term contrast  estimate    std.error    statistic     p.value #> 1 response gear    4 - 3 0.6666667 1.360805e-01     4.899061 9.62957e-07 #> 2 response gear    5 - 3 1.0000000 1.071403e-05 93335.529594 0.00000e+00 #>    conf.low conf.high #> 1 0.3999538 0.9333795 #> 2 0.9999790 1.0000210  comparisons(mod_logit, type = \"link\") %>% tidy() #>   type term contrast estimate std.error   statistic   p.value   conf.low #> 1 link gear    4 - 3 21.25922  4577.962 0.004643817 0.9962948  -8951.381 #> 2 link gear    5 - 3 41.13214  9155.924 0.004492407 0.9964156 -17904.148 #>   conf.high #> 1   8993.90 #> 2  17986.41"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/contrasts.html","id":"character-predictors","dir":"Articles","previous_headings":"Predictor types","what":"Character predictors","title":"Contrasts","text":"functions marginaleffects package attempt treat character predictors factor predictors. However, using factors instead characters modeling strongly encouraged, much safer faster. factors hold useful information full list levels, makes easier track handle internally marginaleffects. Users strongly encouraged convert character variables factor fitting models using marginaleffects functions.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/contrasts.html","id":"numeric-predictors","dir":"Articles","previous_headings":"Predictor types","what":"Numeric predictors","title":"Contrasts","text":"can also compute contrasts differences numeric variables. example, can see happens adjusted predictions increment hp variable 1 unit (default) 5 units: Compare adjusted predictions change regressor two arbitrary values: Compare adjusted predictions regressor changes across interquartile range, across one two standard deviations mean, across full range:","code":"mod <- lm(mpg ~ hp, data = mtcars)  comparisons(mod) %>% tidy() #>       type term contrast    estimate std.error statistic      p.value #> 1 response   hp       +1 -0.06822828 0.0101193 -6.742389 1.558037e-11 #>      conf.low   conf.high #> 1 -0.08806175 -0.04839481  comparisons(     mod,     variables = list(hp = 5)) %>% tidy() #>       type term contrast   estimate  std.error statistic      p.value #> 1 response   hp       +5 -0.3411414 0.05059652 -6.742389 1.558038e-11 #>     conf.low conf.high #> 1 -0.4403087 -0.241974 comparisons(mod, variables = list(hp = c(90, 110))) %>% tidy() #>       type term contrast  estimate std.error statistic      p.value  conf.low #> 1 response   hp 110 - 90 -1.364566 0.2023861 -6.742389 1.558038e-11 -1.761235 #>    conf.high #> 1 -0.9678961 comparisons(mod, variables = list(hp = \"iqr\")) %>% tidy() #>       type term contrast  estimate std.error statistic      p.value  conf.low #> 1 response   hp  Q3 - Q1 -5.697061 0.8449619 -6.742389 1.558038e-11 -7.353156 #>   conf.high #> 1 -4.040966  comparisons(mod, variables = list(hp = \"sd\")) %>% tidy() #>       type term                contrast  estimate std.error statistic #> 1 response   hp (x + sd/2) - (x - sd/2) -4.677926 0.6938085 -6.742389 #>        p.value  conf.low conf.high #> 1 1.558038e-11 -6.037766 -3.318087  comparisons(mod, variables = list(hp = \"2sd\")) %>% tidy() #>       type term            contrast  estimate std.error statistic      p.value #> 1 response   hp (x - sd) - (x + sd) -9.355853  1.387617 -6.742389 1.558038e-11 #>    conf.low conf.high #> 1 -12.07553 -6.636174  comparisons(mod, variables = list(hp = \"minmax\")) %>% tidy() #>       type term  contrast estimate std.error statistic      p.value  conf.low #> 1 response   hp Max - Min -19.3086  2.863763 -6.742389 1.558038e-11 -24.92147 #>   conf.high #> 1 -13.69573"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/contrasts.html","id":"interactions","dir":"Articles","previous_headings":"","what":"Interactions","title":"Contrasts","text":"contexts like know happens two () predictors change time. marginaleffects package terminology, “interaction contrasts.” example, consider model two factor variables: happens increases 1 unit cyl changes baseline reference another level? variables argument used model formula includes interactions, “cross-contrasts” automatically displayed. can also force comparisons() setting interactions=TRUE using variables argument specify variables manipulated simultaneously.","code":"mod <- lm(mpg ~ am * factor(cyl), data = mtcars) cmp <- comparisons(mod, variables = c(\"cyl\", \"am\")) summary(cmp) #>   Term Contrast Effect Std. Error z value  Pr(>|z|)    2.5 % 97.5 % #> 1  cyl    6 - 4 -5.292      1.608  -3.290 0.0010004  -8.4437 -2.140 #> 2  cyl    8 - 4 -9.810      1.516  -6.470   9.8e-11 -12.7820 -6.838 #> 3   am    1 - 0  2.247      1.335   1.684 0.0921982  -0.3684  4.863 #>  #> Model type:  lm  #> Prediction type:  response"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/contrasts.html","id":"quantities-of-interest","dir":"Articles","previous_headings":"","what":"Quantities of interest","title":"Contrasts","text":"section compares 4 quantities: Unit-Level Contrasts Average Contrast Contrast Mean Contrast Marginal Means ideas discussed section focus contrasts, carry directly analogous types marginal effects.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/contrasts.html","id":"unit-level-contrasts","dir":"Articles","previous_headings":"Quantities of interest","what":"Unit-level contrasts","title":"Contrasts","text":"models interactions non-linear components (e.g., link function), value contrast marginal effect can depend value predictors model. result, contrasts marginal effects fundamentally unit-level quantities. effect 1 unit increase \\(X\\) can different Mary John. Every row dataset different contrast marginal effect. mtcars dataset 32 rows, comparisons() function produces 32 contrast estimates:","code":"library(marginaleffects) mod <- glm(vs ~ factor(gear) + mpg, family = binomial, data = mtcars) cmp <- comparisons(mod, variables = \"mpg\") nrow(cmp) #> [1] 32"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/contrasts.html","id":"average-contrasts","dir":"Articles","previous_headings":"Quantities of interest","what":"Average contrasts","title":"Contrasts","text":"default, marginaleffects() comparisons() functions compute marginal effects contrasts every row original dataset. unit-level estimates can great interest, discussed another vignette. Nevertheless, one may want focus one-number summaries: summary() function computes “Average Marginal Effect” “Average Contrast,” taking mean unit-level estimates. equivalent : also show full distribution contrasts across dataset histogram:  graph display effect change 1 unit mpg variable, individual observed data.","code":"summary(cmp) #>   Term Contrast  Effect Std. Error z value   Pr(>|z|)   2.5 %  97.5 % #> 1  mpg       +1 0.06081    0.01284   4.737 2.1714e-06 0.03565 0.08597 #>  #> Model type:  glm  #> Prediction type:  response mean(cmp$comparison) #> [1] 0.06080995 library(ggplot2)  cmp <- comparisons(mod, variables = \"gear\")  ggplot(cmp, aes(comparison)) +     geom_histogram(bins = 30) +     facet_wrap(~contrast, scale = \"free_x\") +     labs(x = \"Distribution of unit-level contrasts\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/contrasts.html","id":"contrasts-at-the-mean","dir":"Articles","previous_headings":"Quantities of interest","what":"Contrasts at the mean","title":"Contrasts","text":"alternative used common now fallen bit disfavor compute “Contrasts mean.” idea create “synthetic” “hypothetical” individual (row dataset) whose characteristics completely average. , compute report contrast specific hypothetical individual. can achieved setting newdata=\"mean\" newdata=datagrid(), fix variables means modes: Contrasts mean can differ substantially average contrasts. advantage approach cheap fast computationally. disadvantage interpretation somewhat ambiguous. Often times, simply exist individual perfectly average across dimensions dataset. also clear analyst particularly interested contrast one, synthetic, perfectly average individual.","code":"comparisons(mod, variables = \"mpg\", newdata = \"mean\") #>   rowid     type term contrast comparison  std.error statistic     p.value #> 1     1 response  mpg       +1  0.1664787 0.06245542   2.66556 0.007686022 #>     conf.low conf.high predicted predicted_hi predicted_lo     vs gear      mpg #> 1 0.04406829  0.288889 0.5649327    0.6463425    0.4798638 0.4375    3 20.09062 #>       eps #> 1 0.00235"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/contrasts.html","id":"contrasts-between-marginal-means","dir":"Articles","previous_headings":"Quantities of interest","what":"Contrasts between marginal means","title":"Contrasts","text":"Yet another type contrast “Contrast marginal means.” type contrast closely related “Contrast mean”, wrinkles. default approach used emmeans package R. Roughly speaking, procedure follows: Create prediction grid one cell combination categorical predictors model, numeric variables held means. Make adjusted predictions cell prediction grid. Take average predictions (marginal means) combination btype (focal variable) resp (group variable). Compute pairwise differences (contrasts) marginal means across different levels focal variable btype. contrast obtained approach two critical characteristics: contrast synthetic individual perfectly average qualities every (numeric) predictor. weighted average unit-level contrasts, weights assume perfectly balanced dataset across every categorical predictor. respect (), analyst ask : quantity interest contrast perfectly average hypothetical individual? respect (b), analyst ask : quantity interest contrast model estimated using (potentially) unbalanced data, interpreted data perfectly balanced? example, imagine one control variables model variable measuring educational attainment 4 categories: high school, High school, college, Completed college. contrast marginal weighted average contrasts estimated 4 cells, contrasts weighted equally overall estimate. population interest highly unbalanced educational categories, estimate computed way useful. contrasts marginal means really quantity interest, easy use comparisons() estimate contrasts marginal means. newdata determines values predictors want compute contrasts. can set newdata=\"marginalmeans\" emulate emmeans behavior. example, compute contrasts model interaction: equivalent emmeans: emmeans section Alternative Software vignette shows examples. excellent vignette emmeans package discuss issues slightly different (positive) way: point marginal means cell.means give equal weight cell. many situations (especially experimental data), much fairer way compute marginal means, biased imbalances data. , sense, estimating marginal means , experiment balanced. Estimated marginal means (EMMs) serve need. said, certainly situations equal weighting appropriate. Suppose, example, data sales product given different packaging features. data unbalanced customers attracted combinations others. goal understand scientifically packaging features inherently profitable, equally weighted EMMs may appropriate; goal predict maximize profit, ordinary marginal means provide better estimates can expect marketplace.","code":"dat <- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\") mod <- lm(bill_length_mm ~ species * sex + island + body_mass_g, data = dat)  cmp <- comparisons(     mod,     newdata = \"marginalmeans\",     variables = c(\"species\", \"island\")) summary(cmp) #>      Term           Contrast   Effect Std. Error z value Pr(>|z|)   2.5 % #> 1 species Chinstrap - Adelie 10.26934     0.4067  25.252  < 2e-16  9.4723 #> 2 species    Gentoo - Adelie  5.89568     0.6773   8.705  < 2e-16  4.5683 #> 3  island     Dream - Biscoe -0.45571     0.4533  -1.005  0.31472 -1.3441 #> 4  island Torgersen - Biscoe  0.08507     0.4701   0.181  0.85639 -0.8363 #>    97.5 % #> 1 11.0664 #> 2  7.2231 #> 3  0.4327 #> 4  1.0064 #>  #> Model type:  lm  #> Prediction type:  response emm <- emmeans(     mod,     specs = c(\"species\", \"island\")) contrast(emm, method = \"trt.vs.ctrl1\") #>  contrast                            estimate    SE  df t.ratio p.value #>  Chinstrap Biscoe - Adelie Biscoe     10.2693 0.407 324  25.252  <.0001 #>  Gentoo Biscoe - Adelie Biscoe         5.8957 0.677 324   8.705  <.0001 #>  Adelie Dream - Adelie Biscoe         -0.4557 0.453 324  -1.005  0.8274 #>  Chinstrap Dream - Adelie Biscoe       9.8136 0.434 324  22.630  <.0001 #>  Gentoo Dream - Adelie Biscoe          5.4400 0.941 324   5.779  <.0001 #>  Adelie Torgersen - Adelie Biscoe      0.0851 0.470 324   0.181  0.9994 #>  Chinstrap Torgersen - Adelie Biscoe  10.3544 0.622 324  16.656  <.0001 #>  Gentoo Torgersen - Adelie Biscoe      5.9808 0.954 324   6.268  <.0001 #>  #> Results are averaged over the levels of: sex  #> P value adjustment: dunnettx method for 8 tests"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/contrasts.html","id":"conditional-contrasts","dir":"Articles","previous_headings":"","what":"Conditional contrasts","title":"Contrasts","text":"Consider model interaction term. happens dependent variable hp variable increases 10 units?","code":"library(marginaleffects)  mod <- lm(mpg ~ hp * wt, data = mtcars)  plot_cco(     mod,     effect = list(hp = 10),     condition = \"wt\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/contrasts.html","id":"transformations","dir":"Articles","previous_headings":"","what":"Transformations","title":"Contrasts","text":"far focused simple differences adjusted predictions. Now, show use ratios, back transformations, arbitrary functions estimate slew quantities interest. Powerful transformations custom contrasts made possible using three arguments act different stages computation process: transform_pre transform_post transform_avg Consider case model single predictor \\(x\\). compute average contrasts, proceed follows: Compute adjusted predictions row dataset observed values \\(x\\): \\(\\hat{y}_x\\) Compute adjusted predictions row dataset observed values \\(x + 1\\): \\(\\hat{y}_{x+1}\\) transform_pre: Compute unit-level contrasts taking difference (function ) adjusted predictions: \\(\\hat{y}_{x+1} - \\hat{y}_x\\) transform_post: Transform unit-level contrasts return -. Compute average contrast taking mean unit-level contrasts: \\(1/N \\sum_{=1}^N \\hat{y}_{x+1} - \\hat{y}_x\\) transform_avg: Transform average contrast return -. transform_pre argument comparisons() function determines adjusted predictions combined create contrast. default, take simple difference predictions hi value \\(x\\), predictions lo value \\(x\\): function(hi, lo) hi-lo. transform_post argument comparisons() function applies custom transformation unit-level contrasts. transform_avg argument available tidy() summary() functions. applies custom transformation average contrast. difference transform_post transform_avg former applied take average, latter applied average. seems like subtle distinction, can important practical implications, since function average rarely average function:","code":"set.seed(1024) x <- rnorm(100) exp(mean(x)) #> [1] 0.9806912 mean(exp(x)) #> [1] 1.587238"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/contrasts.html","id":"differences","dir":"Articles","previous_headings":"","what":"Differences","title":"Contrasts","text":"default contrast calculate comparisons() function (untransformed) difference two adjusted predictions. instance, estimate effect change 1 unit, : can use comparisons() summary() functions obtain results:","code":"library(marginaleffects) library(magrittr)  mod <- glm(vs ~ mpg, data = mtcars, family = binomial)  # construct data  mtcars_minus <- mtcars_plus <- mtcars mtcars_minus$mpg <- mtcars_minus$mpg - 0.5 mtcars_plus$mpg <- mtcars_plus$mpg + 0.5  # adjusted predictions yhat_minus <- predict(mod, newdata = mtcars_minus, type = \"response\") yhat_plus <- predict(mod, newdata = mtcars_plus, type = \"response\")  # unit-level contrasts con <- yhat_plus - yhat_minus  # average contrasts mean(con) #> [1] 0.05540227 con <- comparisons(mod) summary(con) #>   Term Contrast Effect Std. Error z value   Pr(>|z|)   2.5 %  97.5 % #> 1  mpg       +1 0.0554   0.008327   6.653 2.8699e-11 0.03908 0.07172 #>  #> Model type:  glm  #> Prediction type:  response"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/contrasts.html","id":"difference-in-differences-in-differences","dir":"Articles","previous_headings":"","what":"Difference-in-Differences(-in-Differences)","title":"Contrasts","text":"Going back Titanic example: case, contrast difference predicted probabilities. can compute contrast different types individuals: One can notice , gap predicted probabilities survival men women larger 1st class 3rd class. woman matters chances survival travel first class. difference contrasts (diff--diff) statistically significant? answer question, can compute difference--difference using hypothesis argument (see Hypothesis vignette details). example, using b1 b2 refer contrasts first second rows output , can test difference two quantities different 0: Now, let’s say consider types individuals: results, compute triple difference:","code":"dat <- \"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Titanic.csv\" dat <- read.csv(dat) titanic <- glm(Survived ~ PClass * SexCode * Age, data = dat, family = binomial) comparisons(   titanic,   variables = \"SexCode\",   newdata = datagrid(PClass = c(\"1st\", \"3rd\"))) #>   rowid     type    term contrast comparison  std.error statistic      p.value #> 1     1 response SexCode    1 - 0  0.4827743 0.06308077  7.653273 1.959271e-14 #> 2     2 response SexCode    1 - 0  0.3350865 0.06342644  5.283074 1.270342e-07 #>    conf.low conf.high predicted predicted_hi predicted_lo Survived SexCode #> 1 0.3591383 0.6064104 0.4640805    0.9468549    0.4640805        0       0 #> 2 0.2107730 0.4594001 0.1145926    0.4496791    0.1145926        0       0 #>        Age PClass   eps #> 1 30.39799    1st 1e-04 #> 2 30.39799    3rd 1e-04 comparisons(   titanic,   hypothesis = \"b1 - b2 = 0\",   variables = \"SexCode\",   newdata = datagrid(PClass = c(\"1st\", \"3rd\"))) #>       type    term comparison  std.error statistic    p.value    conf.low #> 1 response b1-b2=0  0.1476878 0.08945444  1.650984 0.09874191 -0.02763966 #>   conf.high #> 1 0.3230153 comparisons(   titanic,   variables = \"SexCode\",   newdata = datagrid(PClass = c(\"1st\", \"3rd\"), Age = range)) #>   rowid     type    term contrast comparison  std.error  statistic      p.value #> 1     1 response SexCode    1 - 0 0.10807095 0.12243867  0.8826537 3.774234e-01 #> 2     2 response SexCode    1 - 0 0.87952322 0.05700339 15.4293143 1.039689e-53 #> 3     3 response SexCode    1 - 0 0.08049283 0.15699263  0.5127172 6.081491e-01 #> 4     4 response SexCode    1 - 0 0.42648000 0.20306937  2.1001690 3.571398e-02 #>      conf.low conf.high  predicted predicted_hi predicted_lo Survived SexCode #> 1 -0.13190445 0.3480463 0.81694809    0.9250190   0.81694809        0       0 #> 2  0.76779863 0.9912478 0.08735226    0.9668755   0.08735226        0       0 #> 3 -0.22720707 0.3881927 0.37434756    0.4548404   0.37434756        0       0 #> 4  0.02847135 0.8244887 0.01628383    0.4427638   0.01628383        0       0 #>   PClass   Age   eps #> 1    1st  0.17 1e-04 #> 2    1st 71.00 1e-04 #> 3    3rd  0.17 1e-04 #> 4    3rd 71.00 1e-04 comparisons(   titanic,   hypothesis = \"(b1 - b3) - (b2 - b4) = 0\",   variables = \"SexCode\",   newdata = datagrid(PClass = c(\"1st\", \"3rd\"), Age = range)) #>       type              term comparison std.error statistic   p.value  conf.low #> 1 response (b1-b3)-(b2-b4)=0 -0.4254651 0.3589113 -1.185432 0.2358466 -1.128918 #>   conf.high #> 1 0.2779882"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/contrasts.html","id":"ratios","dir":"Articles","previous_headings":"","what":"Ratios","title":"Contrasts","text":"Instead taking simple differences adjusted predictions, can sometimes useful compute ratios functions predictions. example, adjrr function Stata software package can compute “adjusted risk ratios”, ratios adjusted predictions. R, use transform_pre argument: result average adjusted risk ratio, , adjusted predictions mpg incremented 1, divided adjusted predictions mpg original value. transform_pre accepts different values common types contrasts: ‘difference’, ‘ratio’, ‘lnratio’, ‘ratioavg’, ‘lnratioavg’, ‘lnoravg’, ‘differenceavg’. strings shortcuts functions accept two vectors adjusted predictions returns single vector contrasts. example, two commands yield identical results: mechanism powerful, lets users create fully customized contrasts. non-sensical example: arguments work plotting function plot_cco() well, allows us plot various custom contrasts. comparison Adjusted Risk Ratio Adjusted Risk Difference model probability survival aboard Titanic:  default, standard errors around contrasts computed using delta method scale determined type argument (e.g., “link” “response”). analysts may prefer proceed differently. example, Stata, adjrr computes adjusted risk ratios (ARR) two steps: Compute natural log ratio mean adjusted predictions \\(x+1\\) mean adjusted predictions \\(x\\). Exponentiate estimate confidence interval bounds. Step 1 easy achieve transform_pre argument described . Step 2 can achieved transform_post argument: Note can use lnratioavg shortcut instead defining function . order operations previous command : Compute custom unit-level log ratios Exponentiate Take average using summary() function subtle difference procedure code: Since exp function now passed transform_avg argument summary() function, exponentiation now done unit-level contrasts averaged. Stata appears hood, results slightly different. Note equivalent results can obtained using shortcut strings transform_pre argument: “ratio”, “lnratio”, “lnratioavg”. arguments apply plotting functions marginaleffects package well. example can plot Adjusted Risk Ratio model quadratic term:","code":"comparisons(mod, transform_pre = \"ratio\") %>% summary() #>   Term Contrast Effect Std. Error z value   Pr(>|z|) 2.5 % 97.5 % #> 1  mpg       +1  1.287     0.1328   9.697 < 2.22e-16 1.027  1.548 #>  #> Model type:  glm  #> Prediction type:  response comparisons(mod, transform_pre = \"ratio\") %>% summary() #>   Term Contrast Effect Std. Error z value   Pr(>|z|) 2.5 % 97.5 % #> 1  mpg       +1  1.287     0.1328   9.697 < 2.22e-16 1.027  1.548 #>  #> Model type:  glm  #> Prediction type:  response  comparisons(mod, transform_pre = function(hi, lo) hi / lo) %>% summary() #>   Term Contrast Effect Std. Error z value   Pr(>|z|) 2.5 % 97.5 % #> 1  mpg       +1  1.287     0.1328   9.697 < 2.22e-16 1.027  1.548 #>  #> Model type:  glm  #> Prediction type:  response  #> Pre-transformation:  function(hi, lo) hi/lo comparisons(mod, transform_pre = function(hi, lo) sqrt(hi) / log(lo + 10)) %>% summary() #>   Term Contrast Effect Std. Error z value   Pr(>|z|)  2.5 % 97.5 % #> 1  mpg       +1 0.2641    0.02614    10.1 < 2.22e-16 0.2128 0.3153 #>  #> Model type:  glm  #> Prediction type:  response  #> Pre-transformation:  function(hi, lo) sqrt(hi)/log(lo + 10) library(ggplot2) library(patchwork) titanic <- \"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Titanic.csv\" titanic <- read.csv(titanic) mod_titanic <- glm(     Survived ~ Sex * PClass + Age + I(Age^2),     family = binomial,     data = titanic)  cmp <- comparisons(mod_titanic) summary(cmp) #>     Term      Contrast    Effect Std. Error z value   Pr(>|z|)     2.5 % #> 1    Sex male - female -0.484676   0.030607 -15.835 < 2.22e-16 -0.544665 #> 2 PClass     2nd - 1st -0.205782   0.039374  -5.226 1.7296e-07 -0.282954 #> 3 PClass     3rd - 1st -0.404283   0.039839 -10.148 < 2.22e-16 -0.482367 #> 4    Age            +1 -0.006504   0.001072  -6.069 1.2904e-09 -0.008605 #>      97.5 % #> 1 -0.424687 #> 2 -0.128609 #> 3 -0.326199 #> 4 -0.004403 #>  #> Model type:  glm  #> Prediction type:  response  p1 <- plot_cco(     mod_titanic,     effect = \"Age\",     condition = \"Age\",     transform_pre = \"ratio\") +     ylab(\"Adjusted Risk Ratio\\nP(Survival | Age + 1) / P(Survival | Age)\")  p2 <- plot_cco(     mod_titanic,     effect = \"Age\",     condition = \"Age\") +     ylab(\"Adjusted Risk Difference\\nP(Survival | Age + 1) - P(Survival | Age)\")  p1 + p2 comparisons(     mod,     transform_pre = function(hi, lo) log(hi / lo),     transform_post = exp) |>     summary() #>   Term Contrast Effect Std. Error z value   Pr(>|z|) 2.5 % 97.5 % #> 1  mpg       +1  1.287    0.09313   13.82 < 2.22e-16 1.105   1.47 #>  #> Model type:  glm  #> Prediction type:  response  #> Pre-transformation:  function(hi, lo) log(hi/lo)  #> Post-transformation:  transform_post comparisons(     mod,     transform_pre = function(hi, lo) log(hi / lo)) %>%     summary(transform_avg = exp) #>   Term Contrast Effect  Pr(>|z|) 2.5 % 97.5 % #> 1  mpg       +1  1.274 0.0093462 1.061  1.529 #>  #> Model type:  glm  #> Prediction type:  response  #> Pre-transformation:  function(hi, lo) log(hi/lo)  #> Average-transformation:  exp comparisons(     mod,     transform_pre = function(hi, lo) log(mean(hi) / mean(lo)),     transform_post = exp) #>       type term contrast comparison      p.value conf.low conf.high predicted #> 1 response  mpg       +1   1.135065 2.380805e-10 1.091432  1.180442  1.735373 #>   predicted_hi predicted_lo #> 1     0.603679    0.4976012 comparisons(     mod,     transform_pre = \"lnratioavg\",     transform_post = exp) #>       type term contrast comparison      p.value conf.low conf.high predicted #> 1 response  mpg mean(+1)   1.135065 2.380805e-10 1.091432  1.180442  1.735373 #>   predicted_hi predicted_lo #> 1     0.603679    0.4976012 library(ggplot2)  mod2 <- glm(vs ~ mpg + mpg^2, data = mtcars, family = binomial)  plot_cco(     mod2,     effect = list(\"mpg\" = 10),     condition = \"mpg\",     transformation_pre = \"ratio\") +     ylab(\"Adjusted Risk Ratio\\nP(vs = 1 | mpg + 10) / P(vs = 1 | mpg)\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/contrasts.html","id":"forward-backward-centered-and-custom-differences","dir":"Articles","previous_headings":"","what":"Forward, Backward, Centered, and Custom Differences","title":"Contrasts","text":"default, comparisons() function computes “centered” difference. example, ask comparisons() estimate effect 10-unit change predictor x outcome y, comparisons() compare predicted values x-5 x+5. Since version 0.7.2 marginaleffects, can supply arbitrary functions create custom differences. functions must accept vector values predictor interest, return data frame number rows length, two columns values compare. example, can : Notice last “centered” difference gives results default comparisons() call.","code":"dat <- mtcars dat$new_hp <- 49 * (mtcars$hp - min(mtcars$hp)) / (max(mtcars$hp) - min(mtcars$hp)) + 1 mod <- lm(mpg ~ log(new_hp), data = dat)  comparisons(   mod,   variables = list(new_hp = 10)) |>   summary() #>     Term Contrast Effect Std. Error z value   Pr(>|z|)  2.5 % 97.5 % #> 1 new_hp      +10 -4.056      0.464  -8.742 < 2.22e-16 -4.966 -3.147 #>  #> Model type:  lm  #> Prediction type:  response forward_diff <- \\(x) data.frame(x, x + 10) backward_diff <- \\(x) data.frame(x - 10, x) center_diff <- \\(x) data.frame(x - 5, x + 5)  comparisons(   mod,   variables = list(new_hp = forward_diff)) |>   summary() #>     Term Contrast Effect Std. Error z value   Pr(>|z|)  2.5 % 97.5 % #> 1 new_hp   custom -3.799     0.4346  -8.742 < 2.22e-16 -4.651 -2.948 #>  #> Model type:  lm  #> Prediction type:  response  comparisons(   mod,   variables = list(new_hp = backward_diff)) |>   summary() #>     Term Contrast Effect Std. Error z value   Pr(>|z|)  2.5 % 97.5 % #> 1 new_hp   custom -6.507     0.7443  -8.742 < 2.22e-16 -7.966 -5.048 #>  #> Model type:  lm  #> Prediction type:  response  comparisons(   mod,   variables = list(new_hp = center_diff)) |>   summary() #>     Term Contrast Effect Std. Error z value   Pr(>|z|)  2.5 % 97.5 % #> 1 new_hp   custom -4.056      0.464  -8.742 < 2.22e-16 -4.966 -3.147 #>  #> Model type:  lm  #> Prediction type:  response"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/contrasts.html","id":"lognormal-hurdle-model","dir":"Articles","previous_headings":"","what":"Lognormal hurdle model","title":"Contrasts","text":"hurdle models, can fit two separate models simultaneously: model predicts outcome zero zero outcome zero, model predicts value outcome can calculate predictions marginal effects hurdle model processes, requires variable transformation since stages models use different link functions. hurdle_lognormal() family brms uses logistic regression (logit link) hurdle part model lognormal regression (outcome logged getting used model) non-hurdled part. Let’s look example predicting GDP per capita (distributed exponentially) using life expectancy. ’ll add artificial zeros can work hurdle stage model. two different sets coefficients two different processes. hurdle part (hu) uses logit link, non-hurdle part (mu) uses identity link. However, ’s slight misnomer—true identity link show coefficients non-logged dollar value scale. ’re using lognormal family, GDP per capita pre-logged, “original” identity scale actually logged dollars. can get predictions hu part model link (logit) scale: …response (percentage point) scale: can also get slopes hu part model link (logit) response (percentage point) scales: Working mu part model trickier. Switching type = \"link\" type = \"response\" doesn’t change anything, since outcome pre-logged: predictions, need exponentiate results scale back dollar amounts. can post-processing results (e.g. dplyr::mutate(predicted = exp(predicted))), can use transform_post argument predictions() pass results exp() getting calculated: can pass transform_post = exp plot_cap() :  marginal effects, need transform predictions calculating instantaneous slopes. also can’t use marginaleffects() function directly—need use comparisons() compute numerical derivative (.e. predict gdpPercap lifeExp 40 40.001 calculate slope predictions). can use transform_pre argument pass pair predicted values exp() calculating slopes: can visually confirm instantaneous slopes levels life expectancy:","code":"library(dplyr) library(ggplot2) library(patchwork) library(brms) library(marginaleffects) library(gapminder)  # Build some 0s into the GDP column set.seed(1234) gapminder <- gapminder::gapminder %>%    filter(continent != \"Oceania\") %>%    # Make a bunch of GDP values 0   mutate(prob_zero = ifelse(lifeExp < 50, 0.3, 0.02),          will_be_zero = rbinom(n(), 1, prob = prob_zero),          gdpPercap0 = ifelse(will_be_zero, 0, gdpPercap)) %>%    select(-prob_zero, -will_be_zero)  mod <- brm(   bf(gdpPercap0 ~ lifeExp,      hu ~ lifeExp),   data = gapminder,   family = hurdle_lognormal(),   chains = 4, cores = 4, seed = 1234) summary(mod) #>  Family: hurdle_lognormal  #>   Links: mu = identity; sigma = identity; hu = logit  #> Formula: gdpPercap0 ~ lifeExp  #>          hu ~ lifeExp #>    Data: gapminder (Number of observations: 1680)  #>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #>          total post-warmup draws = 4000 #>  #> Population-Level Effects:  #>              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS #> Intercept        3.47      0.09     3.29     3.65 1.00     4757     3378 #> hu_Intercept     3.16      0.40     2.37     3.96 1.00     2773     2679 #> lifeExp          0.08      0.00     0.08     0.08 1.00     5112     3202 #> hu_lifeExp      -0.10      0.01    -0.12    -0.08 1.00     2385     2652 #> ... predictions(mod, dpar = \"hu\", type = \"link\",             newdata = datagrid(lifeExp = seq(40, 80, 20))) #>   rowid type predicted  conf.low  conf.high gdpPercap0 lifeExp #> 1     1 link -0.817487 -1.033982 -0.6043308     6797.2      40 #> 2     2 link -2.805488 -3.062906 -2.5550801     6797.2      60 #> 3     3 link -4.790200 -5.337808 -4.2745563     6797.2      80 predictions(mod, dpar = \"hu\", type = \"response\",             newdata = datagrid(lifeExp = seq(40, 80, 20))) #>   rowid     type   predicted    conf.low  conf.high gdpPercap0 lifeExp #> 1     1 response 0.306297360 0.262312829 0.35335351     6797.2      40 #> 2     2 response 0.057028334 0.044663565 0.07208594     6797.2      60 #> 3     3 response 0.008242295 0.004783404 0.01372716     6797.2      80 marginaleffects(mod, dpar = \"hu\", type = \"link\",                 newdata = datagrid(lifeExp = seq(40, 80, 20))) #>   rowid type    term        dydx   conf.low   conf.high predicted predicted_hi #> 1     1 link lifeExp -0.09930925 -0.1157859 -0.08366088 -0.817487   -0.8180725 #> 2     2 link lifeExp -0.09930925 -0.1157859 -0.08366088 -2.805488   -2.8060666 #> 3     3 link lifeExp -0.09930925 -0.1157859 -0.08366088 -4.790200   -4.7908031 #>   predicted_lo gdpPercap0 lifeExp       eps #> 1    -0.817487     6797.2      40 0.0059004 #> 2    -2.805488     6797.2      60 0.0059004 #> 3    -4.790200     6797.2      80 0.0059004  marginaleffects(mod, dpar = \"hu\", type = \"response\",                 newdata = datagrid(lifeExp = seq(40, 80, 20))) #>   rowid     type    term          dydx     conf.low     conf.high   predicted #> 1     1 response lifeExp -0.0210776902 -0.025913450 -0.0165879119 0.306297360 #> 2     2 response lifeExp -0.0053208087 -0.006148655 -0.0045608559 0.057028334 #> 3     3 response lifeExp -0.0008118892 -0.001154388 -0.0005429417 0.008242295 #>   predicted_hi predicted_lo gdpPercap0 lifeExp       eps #> 1  0.306172973  0.306297360     6797.2      40 0.0059004 #> 2  0.056997229  0.057028334     6797.2      60 0.0059004 #> 3  0.008237367  0.008242295     6797.2      80 0.0059004 predictions(mod, dpar = \"mu\", type = \"link\",             newdata = datagrid(lifeExp = seq(40, 80, 20))) #>   rowid type predicted conf.low conf.high gdpPercap0 lifeExp #> 1     1 link  6.612435 6.542113  6.685787     6797.2      40 #> 2     2 link  8.183520 8.145944  8.220893     6797.2      60 #> 3     3 link  9.753512 9.687209  9.820665     6797.2      80 predictions(mod, dpar = \"mu\", type = \"response\",             newdata = datagrid(lifeExp = seq(40, 80, 20))) #>   rowid     type predicted conf.low conf.high gdpPercap0 lifeExp #> 1     1 response  6.612435 6.542113  6.685787     6797.2      40 #> 2     2 response  8.183520 8.145944  8.220893     6797.2      60 #> 3     3 response  9.753512 9.687209  9.820665     6797.2      80 predictions(mod, dpar = \"mu\",              newdata = datagrid(lifeExp = seq(40, 80, 20)),             transform_post = exp) #>   rowid     type  predicted   conf.low  conf.high gdpPercap0 lifeExp #> 1     1 response   744.2932   693.7513   800.9406     6797.2      40 #> 2     2 response  3581.4392  3449.3600  3717.8204     6797.2      60 #> 3     3 response 17214.5804 16110.2130 18410.2831     6797.2      80 plot_cap(   mod,   dpar = \"hu\",   type = \"link\",   condition = \"lifeExp\") +   labs(y = \"hu\",        title = \"Hurdle part (hu)\",        subtitle = \"Logit-scale predictions\") + plot_cap(   mod,   dpar = \"hu\",   type = \"response\",   condition = \"lifeExp\") +   labs(y = \"hu\",        subtitle = \"Percentage point-scale predictions\") + plot_cap(   mod,   dpar = \"mu\",   condition = \"lifeExp\") +   labs(y = \"mu\",        title = \"Non-hurdle part (mu)\",        subtitle = \"Log-scale predictions\") + plot_cap(   mod,   dpar = \"mu\",   transform_post = exp,   condition = \"lifeExp\") +   labs(y = \"mu\",        subtitle = \"Dollar-scale predictions\") # step size of the numerical derivative eps <- 0.001  comparisons(   mod,   dpar = \"mu\",   variables = list(lifeExp = eps),   newdata = datagrid(lifeExp = seq(40, 80, 20)),   # rescale the elements of the slope   # (exp(40.001) - exp(40)) / exp(0.001)   transform_pre = function(hi, lo) ((exp(hi) - exp(lo)) / exp(eps)) / eps ) #>   rowid     type    term contrast comparison   conf.low  conf.high predicted #> 1     1 response lifeExp   +0.001   58.39448   55.84743   61.02206  6.612435 #> 2     2 response lifeExp   +0.001  280.89410  266.57621  295.50894  8.183520 #> 3     3 response lifeExp   +0.001 1349.40503 1222.58608 1490.38119  9.753512 #>   predicted_hi predicted_lo gdpPercap0 lifeExp       eps #> 1     6.612474     6.612396     6797.2      40 0.0059004 #> 2     8.183559     8.183481     6797.2      60 0.0059004 #> 3     9.753551     9.753473     6797.2      80 0.0059004 predictions_data <- predictions(   mod,   newdata = datagrid(lifeExp = seq(30, 80, 1)),   dpar = \"mu\",   transform_post = exp) |>   select(lifeExp, predicted)  slopes_data <- comparisons(   mod,   dpar = \"mu\",   variables = list(lifeExp = eps),   newdata = datagrid(lifeExp = seq(40, 80, 20)),   transform_pre = function(hi, lo) ((exp(hi) - exp(lo)) / exp(eps)) / eps) %>%   select(lifeExp, comparison) %>%   left_join(predictions_data, by = \"lifeExp\") %>%   # Point-slope formula: (y - y1) = m(x - x1)   mutate(intercept = comparison * (-lifeExp) + predicted)  ggplot(predictions_data, aes(x = lifeExp, y = predicted)) +   geom_line(size = 1) +    geom_abline(data = slopes_data, aes(slope = comparison, intercept = intercept),                size = 0.5, color = \"red\") +   geom_point(data = slopes_data) +   geom_label(data = slopes_data, aes(label = paste0(\"Slope: \", round(comparison, 1))),              nudge_x = -1, hjust = 1) +   theme_minimal()"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/experiments.html","id":"regression-adjustment-in-experiments","dir":"Articles","previous_headings":"","what":"Regression adjustment in experiments","title":"Experiments","text":"Many analysts conduct analyze experiments wish use regression adjustment linear regression model improve precision estimate treatment effect. Unfortunately, regression adjustment can introduce small-sample bias undesirable properties (Freedman 2008). Lin (2013) proposes simple strategy fix problems sufficiently large samples: Center predictors subtracting means. Estimate linear model treatment interacted covariates. estimatr package includes convenient function implement strategy: can obtain results fitting model standard lm function using comparisons() function: Notice treat coefficient associate standard error lm_lin regression exactly estimates produced comparisons() function.","code":"library(estimatr) library(marginaleffects) data(\"lalonde\", package = \"MatchIt\")  mod <- lm_lin(     re78 ~ treat,     covariates = ~ age + educ + race,     data = lalonde,     se_type = \"HC3\") summary(mod) #>  #> Call: #> lm_lin(formula = re78 ~ treat, covariates = ~age + educ + race,  #>     data = lalonde, se_type = \"HC3\") #>  #> Standard error type:  HC3  #>  #> Coefficients: #>                    Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper  DF #> (Intercept)         6488.05     356.71 18.1885 2.809e-59  5787.50   7188.6 604 #> treat                489.73     878.52  0.5574 5.774e-01 -1235.59   2215.0 604 #> age_c                 85.88      35.42  2.4248 1.561e-02    16.32    155.4 604 #> educ_c               464.04     131.51  3.5286 4.495e-04   205.77    722.3 604 #> racehispan_c        2775.47    1155.40  2.4022 1.660e-02   506.38   5044.6 604 #> racewhite_c         2291.67     793.30  2.8888 4.006e-03   733.71   3849.6 604 #> treat:age_c           17.23      76.37  0.2256 8.216e-01  -132.75    167.2 604 #> treat:educ_c         226.71     308.43  0.7350 4.626e-01  -379.02    832.4 604 #> treat:racehispan_c -1057.84    2652.42 -0.3988 6.902e-01 -6266.92   4151.2 604 #> treat:racewhite_c  -1205.68    1805.21 -0.6679 5.045e-01 -4750.92   2339.6 604 #>  #> Multiple R-squared:  0.05722 ,   Adjusted R-squared:  0.04317  #> F-statistic: 4.238 on 9 and 604 DF,  p-value: 2.424e-05 mod <- lm(re78 ~ treat * (age + educ + race), data = lalonde) comparisons(     mod,     variables = \"treat\",     vcov = \"HC3\") |>     summary() #>    Term Contrast Effect Std. Error z value Pr(>|z|) 2.5 % 97.5 % #> 1 treat    1 - 0  489.7      878.5  0.5574  0.57722 -1232   2212 #>  #> Model type:  lm  #> Prediction type:  response"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/experiments.html","id":"references","dir":"Articles","previous_headings":"Regression adjustment in experiments","what":"References","title":"Experiments","text":"Freedman, David . “Regression Adjustments Experimental Data.” Advances Applied Mathematics 40, . 2 (February 2008): 180–93. Lin, Winston. “Agnostic Notes Regression Adjustments Experimental Data: Reexamining Freedman’s Critique.” Annals Applied Statistics 7, . 1 (March 2013): 295–318. https://doi.org/10.1214/12-AOAS583.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/extensions.html","id":"support-a-new-model-type","dir":"Articles","previous_headings":"","what":"Support a new model type","title":"Extending or modifying marginaleffects","text":"easy add support new models marginaleffects. need set global option define 4 simple functions. add support class models produced CRAN package, please consider submitting code inclusion package: https://github.com/vincentarelbundock/marginaleffects add support class models produced package hosted elsewhere CRAN, can submit inclusion unsupported user-submitted library extensions: Currently countreg package. Thanks Olivier Beaumais. rest section illustrates add support simple lm_manual model.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/extensions.html","id":"fit-function","dir":"Articles","previous_headings":"Support a new model type","what":"Fit function","title":"Extending or modifying marginaleffects","text":"begin, define function fits model. Normally, function supplied modeling package published CRAN. , create function called lm_manual(), estimates linear regression model using simple linear algebra operates: IMPORTANT: custom fit function must assign new class name object returns. example , model assigned class lm_manual (see penultimate line code function). new function replicates results lm():","code":"lm_manual <- function(f, data, ...) {     # design matrix     X <- model.matrix(f, data = data)     # response matrix     Y <- data[[as.character(f[2])]]     # coefficients     b <- solve(crossprod(X)) %*% crossprod(X, Y)     Yhat <- X %*% b     # variance-covariance matrix     e <- Y - Yhat     df <- nrow(X) - ncol(X)     s2 <- sum(e^2) / df     V <- s2 * solve(crossprod(X))     # model object     out <- list(         d = data,         f = f,         X = X,         Y = Y,         V = V,         b = b)     # class name: lm_manual     class(out) <- c(\"lm_manual\", \"list\")     return(out) } model <- lm_manual(mpg ~ hp + drat, data = mtcars) model$b #>                    [,1] #> (Intercept) 10.78986122 #> hp          -0.05178665 #> drat         4.69815776  model_lm <- lm(mpg ~ hp + drat, data = mtcars) coef(model_lm) #> (Intercept)          hp        drat  #> 10.78986122 -0.05178665  4.69815776"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/extensions.html","id":"marginaleffects-extension","dir":"Articles","previous_headings":"Support a new model type","what":"marginaleffects extension","title":"Extending or modifying marginaleffects","text":"extend support marginaleffects, first step tell package new class supported. defining global option: , define 4 methods: Mandatory arguments: model, ... Returns: named vector parameters (coefficients). Mandatory arguments: model, coefs (named vector coefficients), ... Returns: new model object original coefficients replaced new vector. Example Mandatory arguments: model, .... Optional arguments: vcov Returns: named square variance-covariance matrix. Mandatory arguments: model, newdata (data frame), ... Option arguments: type model-specific arguments. Returns: data frame two columns: unique rowid column predicted values. Note methods named suffix .lm_manual indicate used whenever marginaleffects needs process object class lm_manual. methods just defined work expected: Now can use marginaleffects function: Note , custom model, typically supply values newdata variables arguments explicitly.","code":"library(marginaleffects)  options(\"marginaleffects_model_classes\" = \"lm_manual\") get_coef.lm_manual <- function(model, ...) {     b <- model$b     b <- setNames(as.vector(b), row.names(b))     return(b) }  set_coef.lm_manual <- function(model, coefs, ...) {     out <- model     out$b <- coefs     return(out) }  get_vcov.lm_manual <- function(model, ...) {     return(model$V) }  get_predict.lm_manual <- function(model, newdata, ...) {     newX <- model.matrix(model$f, data = newdata)     Yhat <- newX %*% model$b     out <- data.frame(         rowid = seq_len(nrow(Yhat)),         predicted = as.vector(Yhat))     return(out) } get_coef(model) #> (Intercept)          hp        drat  #> 10.78986122 -0.05178665  4.69815776  get_vcov(model) #>             (Intercept)            hp         drat #> (Intercept) 25.78356135 -3.054007e-02 -5.836030687 #> hp          -0.03054007  8.635615e-05  0.004969385 #> drat        -5.83603069  4.969385e-03  1.419990359  get_predict(model, newdata = head(mtcars)) #>   rowid predicted #> 1     1  23.41614 #> 2     2  23.41614 #> 3     3  24.06161 #> 4     4  19.56366 #> 5     5  16.52639 #> 6     6  18.31918 marginaleffects(model, newdata = mtcars, variables = c(\"hp\", \"drat\")) |>     summary() #>   Term   Effect Std. Error z value   Pr(>|z|)  2.5 %   97.5 % #> 1   hp -0.05179   0.009293  -5.573 2.5072e-08 -0.070 -0.03357 #> 2 drat  4.69816   1.191633   3.943 8.0596e-05  2.363  7.03372 #>  #> Model type:  lm_manual  #> Prediction type:  response  predictions(model, newdata = mtcars) |>     head() #>   rowid     type predicted std.error statistic       p.value conf.low conf.high #> 1     1 response  23.41614 0.6711195  34.89117 1.011973e-266 22.10077  24.73152 #> 2     2 response  23.41614 0.6711195  34.89117 1.011973e-266 22.10077  24.73152 #> 3     3 response  24.06161 0.7203817  33.40119 1.317292e-244 22.64969  25.47353 #> 4     4 response  19.56366 0.9987782  19.58759  1.973210e-85 17.60609  21.52122 #> 5     5 response  16.52639 0.7353921  22.47290 7.642913e-112 15.08505  17.96774 #> 6     6 response  18.31918 1.3433197  13.63724  2.404772e-42 15.68632  20.95204 #>    mpg cyl disp  hp drat    wt  qsec vs am gear carb #> 1 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4 #> 2 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4 #> 3 22.8   4  108  93 3.85 2.320 18.61  1  1    4    1 #> 4 21.4   6  258 110 3.08 3.215 19.44  1  0    3    1 #> 5 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2 #> 6 18.1   6  225 105 2.76 3.460 20.22  1  0    3    1"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/extensions.html","id":"modify-or-extend-supported-models","dir":"Articles","previous_headings":"","what":"Modify or extend supported models","title":"Extending or modifying marginaleffects","text":"Let’s say want estimate model using mclogit::mblogit function. package already supported marginaleffects, want use type (scale) predictions currently supported: “centered link scale.” achieve , need override get_predict.mblogit() method. However, can unsafe reassign methods supplied package loaded library. safe, assign new model class object (“customclass”) inherit mblogit. , define get_predict.customclass method make new kinds preditions. Load libraries, estimate model: Tell marginaleffects adding support new class model models, assign new inherited class name duplicate model object: Define new get_predict.customclass method. use default predict() function obtain predictions. Since multinomial model, predict() returns matrix predictions one column per level response variable. new get_predict.customclass method takes matrix predictions, modifies , reshapes return data frame three columns: rowid, group, predicted: Finally, can call marginaleffects function obtain results. Notice object class customclass now produces different results default mblogit object:","code":"library(mclogit) library(data.table)  model <- mblogit(     factor(gear) ~ am + mpg,     data = mtcars,     trace = FALSE) options(\"marginaleffects_model_classes\" = \"customclass\")  model_custom <- model  class(model_custom) <- c(\"customclass\", class(model)) get_predict.customclass <- function(model, newdata, ...) {     out <- predict(model, newdata = newdata, type = \"link\")     out <- cbind(0, out)     colnames(out)[1] <- dimnames(model$D)[[1]][[1]]     out <- out - rowMeans(out)     out <- as.data.frame(out)     out$rowid <- seq_len(nrow(out))     out <- data.table(out)     out <- melt(         out,         id.vars = \"rowid\",         value.name = \"predicted\",         variable.name = \"group\") } predictions(model) |> summary() #>   Group Predicted Std. Error z value   Pr(>|z|)  CI low CI high #> 1     3    0.4688    0.04440  10.558 < 2.22e-16 0.38173  0.5558 #> 2     4    0.3750    0.06764   5.544 2.9505e-08 0.24244  0.5076 #> 3     5    0.1563    0.05103   3.062  0.0021976 0.05624  0.2563 #>  #> Model type:  mblogit  #> Prediction type:  response  predictions(model_custom) |> summary() #>   Group Predicted Std. Error    z value Pr(>|z|) CI low CI high #> 1     3    -1.418       2525 -0.0005614  0.99955  -4950    4947 #> 2     4     6.365       1779  0.0035776  0.99715  -3480    3493 #> 3     5    -4.947       3074 -0.0016094  0.99872  -6030    6020 #>  #> Model type:  customclass  #> Prediction type:  response"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/faq.html","id":"stack-overflow-questions","dir":"Articles","previous_headings":"","what":"Stack Overflow questions","title":"Frequently Asked Questions","text":"plot_cap() range unobserved values Plot marginal effects plm package model Models demeaned, polynomials, transformed variables","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/faq.html","id":"calling-marginaleffects-in-functions-loops-environments-or-after-re-assigning-variables","dir":"Articles","previous_headings":"","what":"Calling marginaleffects in functions, loops, environments, or after re-assigning variables","title":"Frequently Asked Questions","text":"Functions marginaleffects package can sometimes fail called inside function, loop, environments. see , important know marginaleffects often needs operate original data used fit model. extract original data, use get_data() function insight package. cases, get_data() can extract data stored inside model object created modeling package. However, modeling packages save original data model object (order save memory). cases, get_data() parse call find name data object, search data object global environment. users fit models different environment (e.g., function calls), get_data() may able retrieve original data. related problem can arise users fit model, assign new value variable used store dataset. Recommendations: Supply dataset explicitly newdata argument marginaleffects functions. Avoid assigning new value variable use store dataset model fitting.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/gam.html","id":"estimate-a-gam-model","dir":"Articles","previous_headings":"","what":"Estimate a GAM model","title":"Generalized Additive Models","text":"estimate GAM model using mgcv package simdat dataset distributed itsadug package: Fit model random effect group-time smooths:","code":"library(marginaleffects) library(itsadug) library(mgcv)  simdat$Subject <- as.factor(simdat$Subject)  dim(simdat) #> [1] 75600     6 head(simdat) #>    Group      Time Trial Condition Subject         Y #> 1 Adults   0.00000   -10        -1     a01 0.7554469 #> 2 Adults  20.20202   -10        -1     a01 2.7834759 #> 3 Adults  40.40404   -10        -1     a01 1.9696963 #> 4 Adults  60.60606   -10        -1     a01 0.6814298 #> 5 Adults  80.80808   -10        -1     a01 1.6939195 #> 6 Adults 101.01010   -10        -1     a01 2.3651969 model <- bam(Y ~ Group + s(Time, by = Group) + s(Subject, bs = \"re\"),              data = simdat)  summary(model) #>  #> Family: gaussian  #> Link function: identity  #>  #> Formula: #> Y ~ Group + s(Time, by = Group) + s(Subject, bs = \"re\") #>  #> Parametric coefficients: #>             Estimate Std. Error t value Pr(>|t|)    #> (Intercept)   2.0574     0.6903   2.980  0.00288 ** #> GroupAdults   3.1265     0.9763   3.202  0.00136 ** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Approximate significance of smooth terms: #>                         edf Ref.df    F p-value     #> s(Time):GroupChildren  8.26  8.850 3649  <2e-16 *** #> s(Time):GroupAdults    8.66  8.966 6730  <2e-16 *** #> s(Subject)            33.94 34.000  569  <2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> R-sq.(adj) =  0.609   Deviance explained =   61% #> fREML = 2.3795e+05  Scale est. = 31.601    n = 75600"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/gam.html","id":"adjusted-predictions-predictions-and-plot_cap","dir":"Articles","previous_headings":"","what":"Adjusted Predictions: predictions() and plot_cap()","title":"Generalized Additive Models","text":"Compute adjusted predictions observed combination regressor dataset used fit model. gives us dataset number rows original data, new columns predicted values uncertainty estimates: can easily plot adjusted predictions different values regressor using plot_cap() function:","code":"pred <- predictions(model) dim(pred) #> [1] 75600    12 head(pred) #>   rowid     type  predicted std.error statistic      p.value    conf.low #> 1     1 response -1.8738546 0.1992173 -9.406085 5.149621e-21 -2.26431957 #> 2     2 response -1.3462927 0.1817494 -7.407413 1.287873e-13 -1.70252064 #> 3     3 response -0.8191262 0.1671242 -4.901304 9.520267e-07 -1.14668881 #> 4     4 response -0.2929805 0.1560516 -1.877459 6.045522e-02 -0.59884099 #> 5     5 response  0.2312910 0.1489156  1.553168 1.203830e-01 -0.06058298 #> 6     6 response  0.7526640 0.1455161  5.172377 2.311341e-07  0.46745317 #>     conf.high         Y  Group      Time Subject #> 1 -1.48338968 0.7554469 Adults   0.00000     a01 #> 2 -0.99006473 2.7834759 Adults  20.20202     a01 #> 3 -0.49156368 1.9696963 Adults  40.40404     a01 #> 4  0.01287995 0.6814298 Adults  60.60606     a01 #> 5  0.52316491 1.6939195 Adults  80.80808     a01 #> 6  1.03787477 2.3651969 Adults 101.01010     a01 plot_cap(model, condition = \"Time\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/gam.html","id":"marginal-effects-marginaleffects-and-plot_cme","dir":"Articles","previous_headings":"","what":"Marginal Effects: marginaleffects() and plot_cme()","title":"Generalized Additive Models","text":"Marginal effects slopes prediction equation. observation-level quantity. marginaleffects() function produces dataset number rows original data, new columns slop uncertainty estimates: can plot marginal effects different values regressor using plot_cme() function. next plot shows slope prediction equation, , slope previous plot, every value Time variable.  marginal effects plot can interpreted measuring change Y associated small increase Time, different baseline values Time.","code":"mfx <- marginaleffects(model, variables = \"Time\") head(mfx) #>   rowid     type term       dydx   std.error statistic       p.value   conf.low #> 1     1 response Time 0.02611718 0.001367279  19.10158  2.449658e-81 0.02343737 #> 2     2 response Time 0.02610850 0.001360254  19.19384  4.167026e-82 0.02344245 #> 3     3 response Time 0.02607541 0.001334433  19.54044  4.975241e-85 0.02345997 #> 4     4 response Time 0.02600520 0.001282381  20.27884  1.977388e-91 0.02349178 #> 5     5 response Time 0.02588800 0.001201131  21.55302 4.960033e-103 0.02353382 #> 6     6 response Time 0.02571676 0.001092275  23.54421 1.438981e-122 0.02357594 #>    conf.high  predicted predicted_hi predicted_lo         Y  Group      Time #> 1 0.02879700 -1.8738546   -1.8686312   -1.8738546 0.7554469 Adults   0.00000 #> 2 0.02877454 -1.3462927   -1.3410710   -1.3462927 2.7834759 Adults  20.20202 #> 3 0.02869086 -0.8191262   -0.8139112   -0.8191262 1.9696963 Adults  40.40404 #> 4 0.02851862 -0.2929805   -0.2877795   -0.2929805 0.6814298 Adults  60.60606 #> 5 0.02824217  0.2312910    0.2364686    0.2312910 1.6939195 Adults  80.80808 #> 6 0.02785758  0.7526640    0.7578073    0.7526640 2.3651969 Adults 101.01010 #>   Subject eps #> 1     a01 0.2 #> 2     a01 0.2 #> 3     a01 0.2 #> 4     a01 0.2 #> 5     a01 0.2 #> 6     a01 0.2 plot_cme(model, effect = \"Time\", condition = \"Time\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/gam.html","id":"excluding-terms","dir":"Articles","previous_headings":"","what":"Excluding terms","title":"Generalized Additive Models","text":"predict() method mgcv package allows users “exclude” smoothing terms, using exclude argument. can pass argument function marginaleffects package: See documentation ?mgcv:::predict.bam details.","code":"predictions(model, newdata = \"mean\", exclude = \"s(Subject)\") #>   rowid     type predicted std.error statistic      p.value conf.low conf.high #> 1     1 response  11.74971 0.6946584  16.91438 3.525235e-64 10.38819  13.11124 #>         Y  Group Time Subject #> 1 3.63899 Adults 1000     a01"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/gformula.html","id":"what-is-the-parametric-g-formula","dir":"Articles","previous_headings":"","what":"What is the parametric g-formula?","title":"Causal Inference with the Parametric g-Formula","text":"parametric g-formula method standardization can used address confounding problems causal inference observational data. relies identification assumptions Inverse Probability Weighting (IPW), uses different modeling assumptions. Whereas IPW models treatment equation, standardization models mean outcome equation. Hernán Robins note: “IP weighting standardization estimators g-formula, general method causal inference first described 1986. … say standardization ”plug-g-formula estimator\" simply replaces conditional mean outcome g-formula estimates. , like Chapter 13, estimates come parametric models, refer method parametric g-formula.\"","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/gformula.html","id":"how-does-it-work","dir":"Articles","previous_headings":"","what":"How does it work?","title":"Causal Inference with the Parametric g-Formula","text":"Imagine causal model like :  want estimate effect binary treatment \\(X\\) outcome \\(Y\\), confounding variable \\(W\\). can use standardization parametric g-formula handle . Roughly speaking, procedure follows: Use observed data fit regression model \\(Y\\) outcome, \\(X\\) treatment, \\(W\\) control variable (perhaps polynomials /interactions multiple control variables). Create new dataset exactly identical original data, \\(X=1\\) every row. Create new dataset exactly identical original data, \\(X=0\\) every row. Use model Step 1 compute adjusted predictions two counterfactual datasets Steps 2 3. quantity interest difference means adjusted predictions two counterfactual datasets. equivalent computing “Average Contrast”, value \\(X\\) moves 0 1. Thanks equivalence, can apply parametric g-formula method using single line code marginaleffects, obtain delta method standard errors automatically.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/gformula.html","id":"example-with-real-world-data","dir":"Articles","previous_headings":"","what":"Example with real-world data","title":"Causal Inference with the Parametric g-Formula","text":"Let’s illustrate method replicating example Chapter 13 Hernán Robins. data come National Health Nutrition Examination Survey Data Epidemiologic Follow-Study (NHEFS). outcome wt82_71, measure weight gain. treatment qsmk, binary measure smoking cessation. many confounders. Step 1 fit regression model outcome treatment control variables: Steps 2 3 require us replicate full dataset setting qsmk treatment counterfactual values. can automatically calling comparisons().","code":"library(boot) library(marginaleffects)  f <- wt82_71 ~ qsmk + sex + race + age + I(age * age) + factor(education) +      smokeintensity + I(smokeintensity * smokeintensity) + smokeyrs +      I(smokeyrs * smokeyrs) + factor(exercise) + factor(active) + wt71 +      I(wt71 * wt71) + I(qsmk * smokeintensity)  url <- \"https://raw.githubusercontent.com/vincentarelbundock/modelarchive/main/data-raw/nhefs.csv\" nhefs <- read.csv(url) nhefs <- na.omit(nhefs[, all.vars(f)])  fit <- glm(f, data = nhefs)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/gformula.html","id":"tldr","dir":"Articles","previous_headings":"Example with real-world data","what":"TLDR","title":"Causal Inference with the Parametric g-Formula","text":"simple commands everything need apply parametric g-formula: rest vignette walks process bit detail compares replication code Hernán Robins.","code":"cmp <- comparisons(fit, variables = list(qsmk = 0:1)) summary(cmp) ##   Term Contrast Effect Std. Error z value   Pr(>|z|) 2.5 % 97.5 % ## 1 qsmk    1 - 0  3.517     0.4403   7.989 1.3613e-15 2.654   4.38 ##  ## Model type:  glm  ## Prediction type:  response"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/gformula.html","id":"adjusted-predictions","dir":"Articles","previous_headings":"Example with real-world data","what":"Adjusted Predictions","title":"Causal Inference with the Parametric g-Formula","text":"can compute average predictions original data, average predictions two counterfactual datasets like : R code accompanies book, Hernán Robins compute quantities manually, follows: may useful note datagrid() function provided marginaleffects can create counterfactual datasets automatically. equivalent onesample dataset:","code":"# average predicted outcome in the original data p <- predictions(fit) mean(p$predicted) ## [1] 2.6383 # average predicted outcome in the two counterfactual datasets p <- predictions(fit, newdata = datagrid(qsmk = 0:1, grid_type = \"counterfactual\")) aggregate(predicted ~ qsmk, data = p, FUN = mean) ##   qsmk predicted ## 1    0  1.756213 ## 2    1  5.273587 # create a dataset with 3 copies of each subject nhefs$interv <- -1 # 1st copy: equal to original one  interv0 <- nhefs # 2nd copy: treatment set to 0, outcome to missing interv0$interv <- 0 interv0$qsmk <- 0 interv0$wt82_71 <- NA  interv1 <- nhefs # 3rd copy: treatment set to 1, outcome to missing interv1$interv <- 1 interv1$qsmk <- 1 interv1$wt82_71 <- NA  onesample <- rbind(nhefs, interv0, interv1) # combining datasets  # linear model to estimate mean outcome conditional on treatment and confounders # parameters are estimated using original observations only (nhefs) # parameter estimates are used to predict mean outcome for observations with  # treatment set to 0 (interv=0) and to 1 (interv=1)  std <- glm(f, data = onesample) onesample$predicted_meanY <- predict(std, onesample)  # estimate mean outcome in each of the groups interv=0, and interv=1 # this mean outcome is a weighted average of the mean outcomes in each combination  # of values of treatment and confounders, that is, the standardized outcome mean(onesample[which(onesample$interv == -1), ]$predicted_meanY) ## [1] 2.6383 mean(onesample[which(onesample$interv == 0), ]$predicted_meanY) ## [1] 1.756213 mean(onesample[which(onesample$interv == 1), ]$predicted_meanY) ## [1] 5.273587 nd <- datagrid(     model = fit,     qsmk = c(0, 1),     grid_type = \"counterfactual\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/gformula.html","id":"contrast","dir":"Articles","previous_headings":"Example with real-world data","what":"Contrast","title":"Causal Inference with the Parametric g-Formula","text":"Now want compute treatment effect parametric g-formula, difference average predicted outcomes two counterfactual datasets. equivalent taking average contrast comparisons() function. three important things note command follows: variables argument used indicate want estimate “contrast” adjusted predictions qsmk equal 1 0. comparisons() automatically produces estimates uncertainty. hood, comparisons() exactly described g-formula steps : can obtain result manually computing quantities, using replication code Hernán Robins: Although manual computation simple, provide uncertainty estimates. contrast, comparisons() already computed standard error confidence interval using delta method. Instead delta method, analysts rely bootstrapping. example, replication code Hernán Robins : results close obtained comparisons(), confidence interval differs slightly difference bootstrapping delta method.","code":"cmp <- comparisons(std, variables = list(qsmk = 0:1)) summary(cmp) ##   Term Contrast Effect Std. Error z value   Pr(>|z|) 2.5 % 97.5 % ## 1 qsmk    1 - 0  3.517     0.4403   7.989 1.3613e-15 2.654   4.38 ##  ## Model type:  glm  ## Prediction type:  response mean(onesample[which(onesample$interv == 1), ]$predicted_meanY) - mean(onesample[which(onesample$interv == 0), ]$predicted_meanY) ## [1] 3.517374 # function to calculate difference in means standardization <- function(data, indices) {     # create a dataset with 3 copies of each subject     d <- data[indices, ] # 1st copy: equal to original one`     d$interv <- -1     d0 <- d # 2nd copy: treatment set to 0, outcome to missing     d0$interv <- 0     d0$qsmk <- 0     d0$wt82_71 <- NA     d1 <- d # 3rd copy: treatment set to 1, outcome to missing     d1$interv <- 1     d1$qsmk <- 1     d1$wt82_71 <- NA     d.onesample <- rbind(d, d0, d1) # combining datasets      # linear model to estimate mean outcome conditional on treatment and confounders     # parameters are estimated using original observations only (interv= -1)     # parameter estimates are used to predict mean outcome for observations with set     # treatment (interv=0 and interv=1)     fit <- glm(f, data = d.onesample)      d.onesample$predicted_meanY <- predict(fit, d.onesample)      # estimate mean outcome in each of the groups interv=-1, interv=0, and interv=1     return(mean(d.onesample$predicted_meanY[d.onesample$interv == 1]) -            mean(d.onesample$predicted_meanY[d.onesample$interv == 0])) }  # bootstrap results <- boot(data = nhefs, statistic = standardization, R = 1000)  # generating confidence intervals se <- sd(results$t[, 1]) meant0 <- results$t0 ll <- meant0 - qnorm(0.975) * se ul <- meant0 + qnorm(0.975) * se  bootstrap <- data.frame(     \" \" = \"Treatment - No Treatment\",     estimate = meant0,     std.error = se,     conf.low = ll,     conf.high = ul,     check.names = FALSE) bootstrap ##                            estimate std.error conf.low conf.high ## 1 Treatment - No Treatment 3.517374 0.4791326 2.578292  4.456457 summary(cmp) ##   Term Contrast Effect Std. Error z value   Pr(>|z|) 2.5 % 97.5 % ## 1 qsmk    1 - 0  3.517     0.4403   7.989 1.3613e-15 2.654   4.38 ##  ## Model type:  glm  ## Prediction type:  response"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/hypothesis.html","id":"delta-method","dir":"Articles","previous_headings":"","what":"Delta method","title":"Hypothesis Tests and Custom Contrasts using the Delta Method","text":"Version 0.6.0 marginaleffects includes simple yet powerful function called deltamethod(). function emulates behavior well-established car::deltaMethod car::linearHypothesis functions, supports models, requires fewer dependencies, offers convenience features like shortcuts robust standard errors. deltamethod() can used compute estimates standard errors arbitrary functions model parameters. example, can used conduct tests equality coefficients, test value linear non-linear combination quantities interest. deltamethod() can also used conduct hypothesis tests functions model’s parameter, adjusted predictions marginal effects. Let’s start estimating simple model: FUN hypothesis arguments deltamethod() equal NULL (default), function returns data.frame raw estimates: Test equality coefficients: Non-linear function coefficients vcov argument behaves marginaleffects() function. allows us easily compute robust standard errors: can use shortcuts like b1, b2, ... identify position parameter output FUN. example, b2=b3 equivalent hp=wt term names appear 2nd 3rd row call deltamethod(mod). Term names special characters must enclosed backticks: FUN argument can used compute standard errors arbitrary functions model parameters. user-supplied function must accept single model object, return numeric vector data.frame two columns named term estimate. Test equality two predictions (row 2 vs row 3): Note specified newdata argument f function. predict() method associated lm objects automatically original fitted values newdata NULL, instead returning slightly altered fitted values need compute numerical derivatives delta method. can also use numeric vectors specify linear combinations parameters. example, 3 coefficients last model estimated. test null hypothesis sum 2nd 3rd coefficients equal 0, can : See example use string formulas, numeric vectors, matrices calculate custom contrasts, linear combinations, linear non-linear hypothesis tests.","code":"library(marginaleffects) mod <- lm(mpg ~ hp + wt + factor(cyl), data = mtcars) deltamethod(mod) #>           term    estimate #> 1  (Intercept) 35.84599532 #> 2           hp -0.02311981 #> 3           wt -3.18140405 #> 4 factor(cyl)6 -3.35902490 #> 5 factor(cyl)8 -3.18588444 deltamethod(mod, \"hp = wt\") #>      term estimate std.error statistic      p.value conf.low conf.high #> 1 hp = wt 3.158284 0.7199081  4.387066 1.148899e-05  1.74729  4.569278 deltamethod(mod, \"exp(hp + wt) = 0.1\") #>                 term    estimate  std.error statistic    p.value   conf.low #> 1 exp(hp + wt) = 0.1 -0.05942178 0.02919718 -2.035189 0.04183184 -0.1166472 #>      conf.high #> 1 -0.002196363 deltamethod(mod, \"hp = wt\", vcov = \"HC3\") #>      term estimate std.error statistic      p.value conf.low conf.high #> 1 hp = wt 3.158284 0.8051929  3.922394 8.767334e-05 1.580135  4.736433 deltamethod(mod, \"b2 = b3\") #>      term estimate std.error statistic      p.value conf.low conf.high #> 1 b2 = b3 3.158284 0.7199081  4.387066 1.148899e-05  1.74729  4.569278 deltamethod(mod, \"`factor(cyl)6` = `factor(cyl)8`\") #>                              term   estimate std.error  statistic  p.value #> 1 `factor(cyl)6` = `factor(cyl)8` -0.1731405  1.653923 -0.1046847 0.916626 #>   conf.low conf.high #> 1 -3.41477   3.06849 mod <- glm(am ~ hp + mpg, data = mtcars, family = binomial)  f <- function(x) predict(x, type = \"link\", newdata = mtcars) p <- deltamethod(mod, FUN = f) head(p) #>   term   estimate std.error  statistic    p.value  conf.low  conf.high #> 1   b1 -1.0983601 0.7160423 -1.5339319 0.12504640 -2.501777  0.3050570 #> 2   b2 -1.0983601 0.7160423 -1.5339319 0.12504640 -2.501777  0.3050570 #> 3   b3  0.2331884 0.7808207  0.2986452 0.76521076 -1.297192  1.7635688 #> 4   b4 -0.5945143 0.6471012 -0.9187346 0.35823441 -1.862809  0.6737808 #> 5   b5 -0.4175761 0.6474633 -0.6449417 0.51896494 -1.686581  0.8514287 #> 6   b6 -5.0264654 2.1949096 -2.2900558 0.02201808 -9.328409 -0.7245217 f <- function(x) predict(x, newdata = mtcars) deltamethod(mod, FUN = f, hypothesis = \"b2 = b3\") #>      term  estimate std.error statistic    p.value  conf.low  conf.high #> 1 b2 = b3 -1.331548 0.6155513  -2.16318 0.03052731 -2.538007 -0.1250901 deltamethod(mod, hypothesis = c(0, 1, 1)) #>     term estimate std.error statistic    p.value  conf.low conf.high #> 1 custom 1.314659 0.5927081  2.218055 0.02655107 0.1529728  2.476346"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/hypothesis.html","id":"hypothesis-formulas","dir":"Articles","previous_headings":"","what":"hypothesis Formulas","title":"Hypothesis Tests and Custom Contrasts using the Delta Method","text":"4 core functions package support hypothesis argument behaves similarly deltamethod() function. argument allows users specify custom hypothesis tests contrasts, order test null hypotheses : coefficients \\(\\beta_1\\) \\(\\beta_2\\) equal. marginal effects \\(X_1\\) \\(X_2\\) equal. marginal effect \\(X\\) \\(W=0\\) equal marginal effect \\(X\\) \\(W=1\\). non-linear function adjusted predictions equal 100. marginal mean control group equal average marginal means 3 treatment arms. Cross-level contrasts: multinomial model, effect \\(X\\) 1st outcome level equal effect \\(X\\) 2nd outcome level.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/hypothesis.html","id":"marginal-effects","dir":"Articles","previous_headings":"hypothesis Formulas","what":"Marginal effects","title":"Hypothesis Tests and Custom Contrasts using the Delta Method","text":"example, let’s fit model compute marginal effects mean: marginal effect different marginal effect vs? answer question can run linear hypothesis test using deltamethod function: Alternatively, can specify hypothesis directly original call: hypothesis string can include valid R expression, can run silly non-linear tests:","code":"library(marginaleffects)  mod <- lm(mpg ~ am + vs, data = mtcars)  mfx <- marginaleffects(mod, newdata = \"mean\") mfx #>   rowid     type term     dydx std.error statistic      p.value conf.low #> 1     1 response   am 6.066667  1.274842  4.758758 1.947875e-06 3.568022 #> 2     1 response   vs 6.929365  1.262132  5.490207 4.014620e-08 4.455632 #>   conf.high predicted predicted_hi predicted_lo      mpg      am     vs   eps #> 1  8.565312  20.09062     20.09123     20.09062 20.09062 0.40625 0.4375 1e-04 #> 2  9.403098  20.09062     20.09132     20.09062 20.09062 0.40625 0.4375 1e-04 deltamethod(mfx, hypothesis = \"am = vs\") #>       type  term       dydx std.error  statistic   p.value conf.low conf.high #> 1 response am=vs -0.8626984  1.939057 -0.4449063 0.6563875 -4.66318  2.937783 library(marginaleffects)  mod <- lm(mpg ~ am + vs, data = mtcars)  marginaleffects(     mod,     newdata = \"mean\",     hypothesis = \"am = vs\") #>       type  term       dydx std.error  statistic   p.value conf.low conf.high #> 1 response am=vs -0.8626984  1.939057 -0.4449063 0.6563875 -4.66318  2.937783 marginaleffects(     mod,     newdata = \"mean\",     hypothesis = \"exp(am) - 2 * vs = -400\") #>       type              term     dydx std.error statistic   p.value  conf.low #> 1 response exp(am)-2*vs=-400 817.3821  550.2221  1.485549 0.1373984 -261.0335 #>   conf.high #> 1  1895.798"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/hypothesis.html","id":"adjusted-predictions","dir":"Articles","previous_headings":"hypothesis Formulas","what":"Adjusted Predictions","title":"Hypothesis Tests and Custom Contrasts using the Delta Method","text":"Now consider case adjusted predictions: Since term column output predictions function, must use parameter identifiers like b1, b2, etc. determine estimates want compare: directly: next section, see can get equivalent results using vector contrast weights, used compute linear combination estimates: many possibilities:","code":"p <- predictions(     mod,     newdata = datagrid(am = 0:1, vs = 0:1)) p #>   rowid     type predicted std.error statistic       p.value conf.low conf.high #> 1     1 response  14.59444 0.9261514  15.75816  6.036286e-56 12.70025  16.48864 #> 2     2 response  21.52381 1.1300269  19.04717  6.935682e-81 19.21265  23.83497 #> 3     3 response  20.66111 1.1830035  17.46496  2.648808e-68 18.24160  23.08063 #> 4     4 response  27.59048 1.1300269  24.41577 1.163052e-131 25.27931  29.90164 #>        mpg am vs #> 1 20.09062  0  0 #> 2 20.09062  0  1 #> 3 20.09062  1  0 #> 4 20.09062  1  1 deltamethod(p, hypothesis = \"b1 = b2\") #>       type  term predicted std.error statistic     p.value  conf.low conf.high #> 1 response b1=b2 -6.929365  1.262132 -5.490208 4.01461e-08 -9.403098 -4.455633 predictions(     mod,     hypothesis = \"b1 = b2\",     newdata = datagrid(am = 0:1, vs = 0:1)) #>       type  term predicted std.error statistic     p.value  conf.low conf.high #> 1 response b1=b2 -6.929365  1.262132 -5.490208 4.01461e-08 -9.403098 -4.455633  p$predicted[1] - p$predicted[2] #> [1] -6.929365 predictions(     mod,     hypothesis = c(1, -1, 0, 0),     newdata = datagrid(am = 0:1, vs = 0:1)) #>       type   term predicted std.error statistic     p.value  conf.low conf.high #> 1 response custom -6.929365  1.262132 -5.490208 4.01461e-08 -9.403098 -4.455633 predictions(     mod,     hypothesis = \"b1 + b2 = 30\",     newdata = datagrid(am = 0:1, vs = 0:1)) #>       type     term predicted std.error statistic      p.value conf.low #> 1 response b1+b2=30  6.118254  1.635988   3.73979 0.0001841737 2.911776 #>   conf.high #> 1  9.324732  p$predicted[1] + p$predicted[2] - 30 #> [1] 6.118254  predictions(     mod,     hypothesis = \"(b2 - b1) / (b3 - b2) = 0\",     newdata = datagrid(am = 0:1, vs = 0:1)) #>       type              term predicted std.error  statistic   p.value  conf.low #> 1 response (b2-b1)/(b3-b2)=0 -8.032199  16.96625 -0.4734223 0.6359119 -41.28543 #>   conf.high #> 1  25.22103"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/hypothesis.html","id":"average-contrasts-or-marginal-effects","dir":"Articles","previous_headings":"hypothesis Formulas","what":"Average contrasts or marginal effects","title":"Hypothesis Tests and Custom Contrasts using the Delta Method","text":"standard workflow marginaleffects package first call function like marginaleffects() comparisons() compute unit-level quantities, call summary() aggregate unit-level quantities “Average Marginal Effects” “Average Contrasts.” Unfortunately, summary() tidy() functions hypothesis argument, use conduct hypothesis tests aggregated quantities. Instead, can use transform_pre argument emulate behavior summary(), computing average marginal effects single step. First, note three commands produce results: Notice last one need use tidy() summary(), yet still obtained average contrasts. See transformations section Contrasts vignette details. results hand, can finally conduct linear hypothesis test average marginal effects: Computing contrasts average marginal effects requires little care obtain right scale. particular, need specify variables transform_pre:","code":"comparisons(mod) |>     tidy() #>       type term contrast estimate std.error statistic      p.value conf.low #> 1 response   am    1 - 0 6.066667  1.274842  4.758759 1.947871e-06 3.568022 #> 2 response   vs    1 - 0 6.929365  1.262132  5.490208 4.014610e-08 4.455633 #>   conf.high #> 1  8.565312 #> 2  9.403098  comparisons(     mod,     transform_pre = \"differenceavg\") #>       type term          contrast comparison std.error statistic      p.value #> 1 response   am mean(1) - mean(0)   6.066667  1.274842  4.758759 1.947871e-06 #> 2 response   vs mean(1) - mean(0)   6.929365  1.262132  5.490208 4.014610e-08 #>   conf.low conf.high predicted predicted_hi predicted_lo #> 1 3.568022  8.565312  20.66111     20.66111     14.59444 #> 2 4.455633  9.403098  20.66111     27.59048     20.66111 comparisons(     mod,     hypothesis = \"am = vs\",     transform_pre = \"differenceavg\") #>       type  term comparison std.error  statistic   p.value  conf.low conf.high #> 1 response am=vs -0.8626984  1.939056 -0.4449063 0.6563875 -4.663179  2.937782 comparisons(     mod,     hypothesis = \"am = vs\",     variables = c(\"am\", \"vs\"),     transform_pre = \"dydxavg\") #>       type  term comparison std.error  statistic   p.value conf.low conf.high #> 1 response am=vs -0.8626984  1.939057 -0.4449062 0.6563875 -4.66318  2.937783"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/hypothesis.html","id":"hypothesis-vectors-and-matrices","dir":"Articles","previous_headings":"","what":"hypothesis Vectors and Matrices","title":"Hypothesis Tests and Custom Contrasts using the Delta Method","text":"marginalmeans() function computes estimated marginal means. hypothesis argument function offers powerful mechanism estimate custom contrasts marginal means, way linear combination. Consider simple example: contrast marginal means carb==1 carb==2 : last two commands express contrast interest linear combination marginal means.","code":"library(marginaleffects) library(emmeans) library(nnet)  dat <- mtcars dat$carb <- factor(dat$carb) dat$cyl <- factor(dat$cyl) dat$am <- as.logical(dat$am)  mod <- lm(mpg ~ carb + cyl, dat) mm <- marginalmeans(mod, variables = \"carb\") mm #>   term value marginalmean std.error conf.low conf.high      p.value statistic #> 1 carb     1     21.66232  1.438417 18.84307  24.48156 2.975538e-51 15.059829 #> 2 carb     2     21.34058  1.234609 18.92079  23.76037 6.071610e-67 17.285289 #> 3 carb     3     21.41667  2.191616 17.12118  25.71215 1.483584e-22  9.772091 #> 4 carb     4     18.88406  1.210941 16.51066  21.25746 7.929506e-55 15.594538 #> 5 carb     6     19.76014  3.551143 12.80003  26.72026 2.629853e-08  5.564447 #> 6 carb     8     20.11667  3.510156 13.23689  26.99645 9.984697e-09  5.730989 21.66232 - 21.34058  #> [1] 0.32174 21.66232 + -(21.34058) #> [1] 0.32174 sum(c(21.66232, 21.34058) * c(1, -1)) #> [1] 0.32174 c(21.66232, 21.34058) %*% c(1, -1) #>         [,1] #> [1,] 0.32174"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/hypothesis.html","id":"simple-contrast","dir":"Articles","previous_headings":"hypothesis Vectors and Matrices","what":"Simple contrast","title":"Hypothesis Tests and Custom Contrasts using the Delta Method","text":"marginalmeans() function, can supply hypothesis argument compute linear combinations marginal means. argument must numeric vector length number rows output marginalmeans(). example, previous six rows, two marginal means want compare first two positions:","code":"lc <- c(1, -1, 0, 0, 0, 0) marginalmeans(mod, variables = \"carb\", hypothesis = lc) #>     term marginalmean std.error  conf.low conf.high   p.value statistic #> 1 custom    0.3217391  1.773733 -3.154713  3.798191 0.8560607  0.181391"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/hypothesis.html","id":"complex-contrast","dir":"Articles","previous_headings":"hypothesis Vectors and Matrices","what":"Complex contrast","title":"Hypothesis Tests and Custom Contrasts using the Delta Method","text":"course, can also estimate complex contrasts: emmeans produces similar results:","code":"lc <- c(-2, 1, 1, 0, -1, 1) marginalmeans(mod, variables = \"carb\", hypothesis = lc) #>     term marginalmean std.error  conf.low conf.high   p.value   statistic #> 1 custom   -0.2108696  6.928859 -13.79118  13.36945 0.9757213 -0.03043352 library(emmeans) em <- emmeans(mod, \"carb\") lc <- data.frame(custom_contrast = c(-2, 1, 1, 0, -1, 1)) contrast(em, method = lc) #>  contrast        estimate   SE df t.ratio p.value #>  custom_contrast   -0.211 6.93 24  -0.030  0.9760 #>  #> Results are averaged over the levels of: cyl"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/hypothesis.html","id":"multiple-contrasts","dir":"Articles","previous_headings":"hypothesis Vectors and Matrices","what":"Multiple contrasts","title":"Hypothesis Tests and Custom Contrasts using the Delta Method","text":"Users can also compute multiple linear combinations simultaneously supplying numeric matrix hypothesis. matrix must number rows output marginaleffects(), column represents distinct set weights different linear combinations. column names matrix become labels output. example:","code":"lc <- matrix(c(     -2, 1, 1, 0, -1, 1,     1, -1, 0, 0, 0, 0     ), ncol = 2) colnames(lc) <- c(\"Contrast A\", \"Contrast B\") lc #>      Contrast A Contrast B #> [1,]         -2          1 #> [2,]          1         -1 #> [3,]          1          0 #> [4,]          0          0 #> [5,]         -1          0 #> [6,]          1          0  marginalmeans(mod, variables = \"carb\", hypothesis = lc) #>         term marginalmean std.error   conf.low conf.high   p.value   statistic #> 1 Contrast A   -0.2108696  6.928859 -13.791184 13.369445 0.9757213 -0.03043352 #> 2 Contrast B    0.3217391  1.773733  -3.154713  3.798191 0.8560607  0.18139099"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/hypothesis.html","id":"contrasts-across-response-levels","dir":"Articles","previous_headings":"hypothesis Vectors and Matrices","what":"Contrasts across response levels","title":"Hypothesis Tests and Custom Contrasts using the Delta Method","text":"models multinomial outcomes, one may interested comparing outcomes contrasts across response levels. example, model 18 estimated marginal means, across 6 outcome levels (group column): Let’s contrast marginal means first outcome level cyl equals 4 6. marginal means located rows 1 7 respectively: indeed equal results obtained manually: Now let’s say want calculate “contrast contrasts”, , outcome 3-step process: Contrast cyl=6 cyl=4 1st outcome level Contrast cyl=6 cyl=4 2nd outcome level Contrast contrasts defined steps 1 2. create linear combination weights follows: make sure weights correct, can display side side original marginalmeans() output: Compute results:","code":"library(nnet) mod <- multinom(carb ~ mpg + cyl, data = dat, trace = FALSE) mm <- marginalmeans(mod, type = \"probs\") mm #>    group term value marginalmean    std.error #> 1      1  cyl     4 3.678521e-01 2.598299e-01 #> 2      2  cyl     4 6.310922e-01 2.600886e-01 #> 3      3  cyl     4 6.852625e-04 1.192096e-02 #> 4      4  cyl     4 2.118825e-04 1.750265e-02 #> 5      6  cyl     4 8.815299e-06 8.406582e-05 #> 6      8  cyl     4 1.496776e-04 7.970023e-03 #> 7      1  cyl     6 2.828726e-01 1.957050e-01 #> 8      2  cyl     6 1.848644e-06 2.394710e-06 #> 9      3  cyl     6 1.121687e-05 1.323445e-03 #> 10     4  cyl     6 5.562672e-01 2.184901e-01 #> 11     6  cyl     6 1.608378e-01 1.539716e-01 #> 12     8  cyl     6 9.291803e-06 7.982244e-04 #> 13     1  cyl     8 4.625030e-04 9.586613e-03 #> 14     2  cyl     8 6.654572e-01 3.745272e-01 #> 15     3  cyl     8 3.103763e-01 3.714795e-01 #> 16     4  cyl     8 9.582000e-03 2.289015e-02 #> 17     6  cyl     8 4.345753e-09 9.895429e-08 #> 18     8  cyl     8 1.412195e-02 4.673316e-02 lc <- rep(0, nrow(mm)) lc[1] <- -1 lc[7] <- 1 marginalmeans(     mod,     type = \"probs\",     hypothesis = lc) #>     term marginalmean std.error #> 1 custom  -0.08497951  0.320746 2.828726e-01 - 3.678521e-01 #> [1] -0.0849795 lc <- rep(0, nrow(mm)) lc[c(1, 8)] <- -1 lc[c(7, 2)] <- 1 transform(mm[, 1:3], lc = lc) #>    group term value lc #> 1      1  cyl     4 -1 #> 2      2  cyl     4  1 #> 3      3  cyl     4  0 #> 4      4  cyl     4  0 #> 5      6  cyl     4  0 #> 6      8  cyl     4  0 #> 7      1  cyl     6  1 #> 8      2  cyl     6 -1 #> 9      3  cyl     6  0 #> 10     4  cyl     6  0 #> 11     6  cyl     6  0 #> 12     8  cyl     6  0 #> 13     1  cyl     8  0 #> 14     2  cyl     8  0 #> 15     3  cyl     8  0 #> 16     4  cyl     8  0 #> 17     6  cyl     8  0 #> 18     8  cyl     8  0 marginalmeans(mod, type = \"probs\", hypothesis = lc) #>     term marginalmean std.error #> 1 custom    0.5461109 0.5498044"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/hypothesis.html","id":"pairwise-contrasts-difference-in-differences","dir":"Articles","previous_headings":"","what":"Pairwise contrasts: Difference-in-Differences","title":"Hypothesis Tests and Custom Contrasts using the Delta Method","text":"Now illustrate use machinery described pairwise comparisons contrasts, type analysis often associated “Difference--Differences” research design. First, simulate data two treatment groups pre/post periods: , estimate linear model multiple interaction time treatment indicators. also compute contrasts mean treatment level: Finally, compute pairwise differences contrasts. Diff--Diff estimate:","code":"library(data.table)  N <- 1000 did <- data.table(     id = 1:N,     pre = rnorm(N),     trt = sample(0:1, N, replace = TRUE)) did$post <- did$pre + did$trt * 0.3 + rnorm(N) did <- melt(     did,     value.name = \"y\",     variable.name = \"time\",     id.vars = c(\"id\", \"trt\")) head(did) #>    id trt time           y #> 1:  1   1  pre  0.81696551 #> 2:  2   0  pre  0.35507924 #> 3:  3   0  pre -0.10530645 #> 4:  4   1  pre  2.01119658 #> 5:  5   0  pre -0.07428201 #> 6:  6   1  pre -0.18135331 did_model <- lm(y ~ time * trt, data = did)  comparisons(     did_model,     newdata = datagrid(trt = 0:1),     variables = \"time\") #>   rowid     type term   contrast comparison  std.error statistic      p.value #> 1     1 response time post - pre 0.01294222 0.07780797 0.1663354 8.678930e-01 #> 2     2 response time post - pre 0.34338605 0.07657284 4.4844365 7.310688e-06 #>     conf.low conf.high   predicted predicted_hi predicted_lo         y time trt #> 1 -0.1395586 0.1654430  0.06330218    0.0762444   0.06330218 0.1087575  pre   0 #> 2  0.1933060 0.4934661 -0.02517907    0.3182070  -0.02517907 0.1087575  pre   1 comparisons(     did_model,     variables = \"time\",     newdata = datagrid(trt = 0:1),     hypothesis = \"pairwise\") #>       type          term comparison std.error statistic     p.value   conf.low #> 1 response Row 1 - Row 2 -0.3304438 0.1091672 -3.026951 0.002470338 -0.5444076 #>   conf.high #> 1  -0.11648"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/lme4.html","id":"unit-level-predictions","dir":"Articles","previous_headings":"","what":"Unit-level predictions","title":"Mixed effects models with lme4","text":"Predict weight chick time:  Predictions chick, 4 counterfactual worlds different values Diet variable:","code":"pred1 <- predictions(fit1,                      newdata = datagrid(Chick = ChickWeight$Chick,                                         Time = 0:21))  p1 <- ggplot(pred1, aes(Time, predicted, level = Chick)) +       geom_line() +       labs(y = \"Predicted weight\", x = \"Time\", title = \"Linear growth model\")  pred2 <- predictions(fit2,                      newdata = datagrid(Chick = ChickWeight$Chick,                                         Time = 0:21))  p2 <- ggplot(pred2, aes(Time, predicted, level = Chick)) +       geom_line() +       labs(y = \"Predicted weight\", x = \"Time\", title = \"Quadratic growth model\")  p1 + p2 pred <- predictions(fit2)  ggplot(pred, aes(Time, predicted, level = Chick)) +     geom_line() +     ylab(\"Predicted Weight\") +     facet_wrap(~ Diet, labeller = label_both)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/lme4.html","id":"population-level-predictions","dir":"Articles","previous_headings":"","what":"Population-level predictions","title":"Mixed effects models with lme4","text":"make population-level predictions, set Chick variable NA, set include_ranom=FALSE. last argument offered insight::get_predicted function used behind scenes compute predictions:","code":"pred <- predictions(     fit2,     newdata = datagrid(Chick = NA,                        Diet = 1:4,                        Time = 0:21),     include_random = FALSE)  ggplot(pred, aes(x = Time, y = predicted, ymin = conf.low, ymax = conf.high)) +     geom_ribbon(alpha = .1, fill = \"red\") +     geom_line() +     facet_wrap(~ Diet, labeller = label_both) +     labs(title = \"Population-level trajectories\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/logistic_contrasts.html","id":"data","dir":"Articles","previous_headings":"","what":"Data","title":"Unit-level contrasts in logistic regression","text":"focus subset data GUSTO-study, patients randomly assigned accelerated tissue plasminogen activator (tPA) streptokinase (SK). Load libraries, data fit covariate-adjusted logistic regression model.","code":"library(marginaleffects) library(modelsummary) library(rms)  load(url( \"https://github.com/vincentarelbundock/modelarchive/raw/main/data-raw/gusto.rda\" ))  gusto <- subset(gusto, tx %in% c(\"tPA\", \"SK\")) gusto$tx <- factor(gusto$tx, levels = c(\"tPA\", \"SK\"))  mod <- glm(     day30 ~ tx + rcs(age, 4) + Killip + pmin(sysbp, 120) + lsp(pulse, 50) +     pmi + miloc + sex, family = \"binomial\",     data = gusto)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/logistic_contrasts.html","id":"one-number-summaries","dir":"Articles","previous_headings":"Data","what":"One-Number Summaries","title":"Unit-level contrasts in logistic regression","text":"usual, can produce one-number summary relationship interest exponentiating coefficients, yields Odds Ratio (): Unlike ORs, adjusted risk differences vary individual individual based values control variables. comparisons() function can compute adjusted risk differences every individual. , display first 6 : Population-averaged (aka “marginal”) adjusted risk difference (see vignette) can obtained using summary() function: comparisons() function computed predicted probability mortality (day30==1) observed row data two counterfactual cases: tx “SK”, tx “tPA”. , computed differences two sets predictions. Finally, computed population-average risk differences. Instead risk differences, compute population-averaged (marginal) adjusted risk ratios: Population-averaged (marginal) odds ratios:","code":"modelsummary(mod, exponentiate = TRUE, coef_omit = \"^(?!txSK)\") comparisons(     mod,     variables = \"tx\") |>     head() #>   rowid     type term contrast   comparison    std.error statistic    p.value #> 1     1 response   tx SK - tPA 0.0010741928 0.0004966749  2.162768 0.03055900 #> 2     2 response   tx SK - tPA 0.0008573104 0.0003799743  2.256233 0.02405605 #> 3     3 response   tx SK - tPA 0.0017797796 0.0007784409  2.286339 0.02223446 #> 4     4 response   tx SK - tPA 0.0011367499 0.0004999032  2.273940 0.02296960 #> 5     5 response   tx SK - tPA 0.0013655083 0.0005934013  2.301155 0.02138288 #> 6     6 response   tx SK - tPA 0.0024015964 0.0010127226  2.371426 0.01771961 #>       conf.low   conf.high   predicted predicted_hi predicted_lo day30  tx #> 1 0.0001007278 0.002047658 0.005769605  0.005769605  0.004695412     0  SK #> 2 0.0001125746 0.001602046 0.003742994  0.004600304  0.003742994     0 tPA #> 3 0.0002540634 0.003305496 0.009589391  0.009589391  0.007809612     0  SK #> 4 0.0001569575 0.002116542 0.004970544  0.006107294  0.004970544     0 tPA #> 5 0.0002024631 0.002528553 0.007343757  0.007343757  0.005978249     0  SK #> 6 0.0004166965 0.004386496 0.012975875  0.012975875  0.010574279     0  SK #>   Killip pmi    miloc    sex    age pulse sysbp #> 1      I  no Anterior   male 19.027    60   130 #> 2      I  no Inferior   male 20.781    75   124 #> 3      I  no Anterior   male 20.969    85   135 #> 4      I  no Inferior   male 20.984    90   129 #> 5      I  no Anterior   male 21.449    70   157 #> 6      I  no Anterior female 22.523    84   135 comparisons(     mod,     variables = \"tx\") |>     summary() #>   Term Contrast  Effect Std. Error z value   Pr(>|z|)    2.5 % 97.5 % #> 1   tx SK - tPA 0.01108   0.002766   4.005 6.1955e-05 0.005658 0.0165 #>  #> Model type:  glm  #> Prediction type:  response comparisons(     mod,     variables = \"tx\",     transform_pre = \"lnratioavg\",     transform_post = exp) |>     summary() #>   Term                 Contrast Effect   Pr(>|z|) 2.5 % 97.5 % #> 1   tx ln(mean(SK) / mean(tPA))  1.177 9.8075e-05 1.085  1.278 #>  #> Model type:  glm  #> Prediction type:  response  #> Post-transformation:  transform_post comparisons(     mod,     variables = \"tx\",     transform_pre = \"lnoravg\",     transform_post = exp) |>     summary() #>   Term                 Contrast Effect   Pr(>|z|) 2.5 % 97.5 % #> 1   tx ln(odds(SK) / odds(tPA))  1.192 9.4701e-05 1.091  1.301 #>  #> Model type:  glm  #> Prediction type:  response  #> Post-transformation:  transform_post"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/logistic_contrasts.html","id":"unit-level-summaries","dir":"Articles","previous_headings":"Data","what":"Unit-level Summaries","title":"Unit-level contrasts in logistic regression","text":"Instead estimating one-number summaries, can focus unit-level proportion differences using comparisons(). function applies fitted logistic regression model predict outcome probabilities patient, .e., unit-level. Show predicted probability individual patients treatment alternatives.  Lastly, present entire distribution unit-level proportion differences mean median.","code":"cmp <- comparisons(mod, variables = \"tx\")  head(cmp) #>   rowid     type term contrast   comparison    std.error statistic    p.value #> 1     1 response   tx SK - tPA 0.0010741928 0.0004966749  2.162768 0.03055900 #> 2     2 response   tx SK - tPA 0.0008573104 0.0003799743  2.256233 0.02405605 #> 3     3 response   tx SK - tPA 0.0017797796 0.0007784409  2.286339 0.02223446 #> 4     4 response   tx SK - tPA 0.0011367499 0.0004999032  2.273940 0.02296960 #> 5     5 response   tx SK - tPA 0.0013655083 0.0005934013  2.301155 0.02138288 #> 6     6 response   tx SK - tPA 0.0024015964 0.0010127226  2.371426 0.01771961 #>       conf.low   conf.high   predicted predicted_hi predicted_lo day30  tx #> 1 0.0001007278 0.002047658 0.005769605  0.005769605  0.004695412     0  SK #> 2 0.0001125746 0.001602046 0.003742994  0.004600304  0.003742994     0 tPA #> 3 0.0002540634 0.003305496 0.009589391  0.009589391  0.007809612     0  SK #> 4 0.0001569575 0.002116542 0.004970544  0.006107294  0.004970544     0 tPA #> 5 0.0002024631 0.002528553 0.007343757  0.007343757  0.005978249     0  SK #> 6 0.0004166965 0.004386496 0.012975875  0.012975875  0.010574279     0  SK #>   Killip pmi    miloc    sex    age pulse sysbp #> 1      I  no Anterior   male 19.027    60   130 #> 2      I  no Inferior   male 20.781    75   124 #> 3      I  no Anterior   male 20.969    85   135 #> 4      I  no Inferior   male 20.984    90   129 #> 5      I  no Anterior   male 21.449    70   157 #> 6      I  no Anterior female 22.523    84   135 plot(x = cmp$predicted_hi,      y = cmp$predicted_lo,      main = \"Risk of Mortality\",      xlab = \"SK\",      ylab = \"tPA\")  abline(0, 1) hist(cmp$comparison,      breaks = 100,      main = \"Distribution of unit-level contrasts\",      xlab = \"SK - tPA\") abline(v = mean(cmp$comparison), col = \"red\") abline(v = median(cmp$comparison), col = \"blue\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/logistic_contrasts.html","id":"appendix","dir":"Articles","previous_headings":"Data","what":"Appendix","title":"Unit-level contrasts in logistic regression","text":"comparisons() performed following calculations hood: original dataset contains 30510 patients, thus comparisons() generates output amount rows.","code":"d  <- gusto  d$tx = \"SK\" predicted_hi <- predict(mod, newdata = d, type = \"response\")  d$tx = \"tPA\" predicted_lo <- predict(mod, newdata = d, type = \"response\")  comparison <- predicted_hi - predicted_lo nrow(gusto) #> [1] 30510 nrow(cmp) #> [1] 30510"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/marginaleffects.html","id":"definition","dir":"Articles","previous_headings":"","what":"Definition","title":"Marginal Effects","text":"“marginal effect” (MFX) measure association change regressor, change response variable. formally, excellent margins vignette defines concept follows: Marginal effects partial derivatives regression equation respect variable model unit data. Put differently, marginal effect measures association change regressor \\(x\\), change response \\(y\\). Put differently, differently, marginal effect slope prediction function, measured specific value regressor \\(x\\). Marginal effects extremely useful, intuitive easy interpret. often main quantity interest empirical analysis. scientific practice, “Marginal Effect” falls toolbox “Contrast.” try answer counterfactual question: happen \\(y\\) \\(x\\) different? allow us model “effect” change/difference regressor \\(x\\) response \\(y\\).1 illustrate concept, consider quadratic function: \\[y = -x^2\\] definition , know marginal effect partial derivative \\(y\\) respect \\(x\\): \\[\\frac{\\partial y}{\\partial x} = -2x\\] get intuition interpret quantity, consider response \\(y\\) \\(x\\). looks like :  \\(x\\) increases, \\(y\\) starts increase. , \\(x\\) increases , \\(y\\) creeps back negative territory. marginal effect slope response function certain value \\(x\\). next plot adds three tangent lines, highlighting slopes response function three values \\(x\\). slopes tangents tell us three things: \\(x<0\\), slope positive: increase \\(x\\) associated increase \\(y\\): marginal effect positive. \\(x=0\\), slope null: (small) change \\(x\\) associated change \\(y\\). marginal effect null. \\(x>0\\), slope negative: increase \\(x\\) associated decrease \\(y\\). marginal effect negative.  , show reach conclusions estimation context, simulated data marginaleffects function.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/marginaleffects.html","id":"marginaleffects-function","dir":"Articles","previous_headings":"","what":"marginaleffects function","title":"Marginal Effects","text":"marginal effect unit-level measure association changes regressor changes response. Except simplest linear models, value marginal effect different individual individual, depend values covariates individual. marginaleffects function thus produces distinct estimates marginal effect row data used fit model. output marginaleffects simple data.frame, can inspected usual R commands. show , load library, download Palmer Penguins data Rdatasets archive, estimate GLM model:","code":"library(marginaleffects)  dat <- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/palmerpenguins/penguins.csv\") dat$large_penguin <- ifelse(dat$body_mass_g > median(dat$body_mass_g, na.rm = TRUE), 1, 0)  mod <- glm(large_penguin ~ bill_length_mm + flipper_length_mm + species,            data = dat, family = binomial) mfx <- marginaleffects(mod) head(mfx) #>   rowid     type           term contrast       dydx   std.error statistic #> 1     1 response bill_length_mm    dY/dX 0.01763035 0.007841310  2.248393 #> 2     2 response bill_length_mm    dY/dX 0.03586004 0.011923232  3.007577 #> 3     3 response bill_length_mm    dY/dX 0.08444404 0.021123004  3.997729 #> 4     4 response bill_length_mm    dY/dX 0.03472711 0.006508685  5.335504 #> 5     5 response bill_length_mm    dY/dX 0.05089119 0.013414434  3.793763 #> 6     6 response bill_length_mm    dY/dX 0.01651544 0.007256548  2.275937 #>        p.value   conf.low  conf.high  predicted predicted_hi predicted_lo #> 1 2.455116e-02 0.00226166 0.03299903 0.05123266   0.05128115   0.05123266 #> 2 2.633393e-03 0.01249093 0.05922914 0.11125087   0.11134949   0.11125087 #> 3 6.395319e-05 0.04304371 0.12584437 0.36919834   0.36943056   0.36919834 #> 4 9.527951e-08 0.02197033 0.04748390 0.10725326   0.10734876   0.10725326 #> 5 1.483813e-04 0.02459938 0.07718299 0.16882994   0.16896989   0.16882994 #> 6 2.284981e-02 0.00229287 0.03073802 0.04782069   0.04786611   0.04782069 #>   large_penguin bill_length_mm flipper_length_mm species     eps #> 1             0           39.1               181  Adelie 0.00275 #> 2             0           39.5               186  Adelie 0.00275 #> 3             0           40.3               195  Adelie 0.00275 #> 4             0           36.7               193  Adelie 0.00275 #> 5             0           39.3               190  Adelie 0.00275 #> 6             0           38.9               181  Adelie 0.00275"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/marginaleffects.html","id":"the-marginal-effects-zoo","dir":"Articles","previous_headings":"","what":"The Marginal Effects Zoo","title":"Marginal Effects","text":"dataset one marginal effect estimate per unit observation bit unwieldy difficult interpret. ways make information easier digest, computing various quantities interest. characteristically excellent blog post, Professor Andrew Heiss introduces many quantities: Average Marginal Effects Group-Average Marginal Effects Marginal Effects User-Specified Values (Representative Values) Marginal Effects Mean Counterfactual Marginal Effects Conditional Marginal Effects rest vignette defines quantities explains use marginaleffects() plot_cme() functions compute . main differences quantities pertain () regressor values estimate marginal effects, (b) way unit-level marginal effects aggregated. Heiss drew exceedingly helpful graph summarizes information rest vignette:","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/marginaleffects.html","id":"average-marginal-effect-ame","dir":"Articles","previous_headings":"","what":"Average Marginal Effect (AME)","title":"Marginal Effects","text":"dataset one marginal effect estimate per unit observation bit unwieldy difficult interpret. Many analysts like report “Average Marginal Effect”, , average observation-specific marginal effects. easy compute based full data.frame shown , summary function convenient: Note since marginal effects derivatives, properly defined continuous numeric variables. model also includes categorical regressors, summary function try display relevant (regression-adjusted) contrasts different categories, shown . can also extract average marginal effects using tidy glance methods conform broom package specification:","code":"summary(mfx) #>                Term           Contrast   Effect Std. Error z value   Pr(>|z|) #> 1    bill_length_mm              dY/dX  0.02757   0.005784  4.7675 1.8653e-06 #> 2 flipper_length_mm              dY/dX  0.01058   0.002357  4.4895 7.1390e-06 #> 3           species Chinstrap - Adelie -0.41479   0.056900 -7.2898 3.1032e-13 #> 4           species    Gentoo - Adelie  0.06170   0.106856  0.5774    0.56367 #>       2.5 %   97.5 % #> 1  0.016238  0.03891 #> 2  0.005963  0.01520 #> 3 -0.526312 -0.30327 #> 4 -0.147735  0.27113 #>  #> Model type:  glm  #> Prediction type:  response tidy(mfx) #>       type              term           contrast    estimate   std.error #> 1 response    bill_length_mm              dY/dX  0.02757371 0.005783687 #> 2 response flipper_length_mm              dY/dX  0.01058283 0.002357239 #> 3 response           species Chinstrap - Adelie -0.41479008 0.056899735 #> 4 response           species    Gentoo - Adelie  0.06169819 0.106855875 #>    statistic      p.value     conf.low   conf.high #> 1  4.7674971 1.865287e-06  0.016237894  0.03890953 #> 2  4.4895005 7.139036e-06  0.005962722  0.01520293 #> 3 -7.2898420 3.103188e-13 -0.526311511 -0.30326865 #> 4  0.5773963 5.636718e-01 -0.147735476  0.27113186  glance(mfx) #>        aic      bic   r2.tjur      rmse nobs        F    logLik #> 1 179.8451 199.0192 0.6949385 0.2763254  342 15.66122 -84.92257"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/marginaleffects.html","id":"group-average-marginal-effect-g-ame","dir":"Articles","previous_headings":"","what":"Group-Average Marginal Effect (G-AME)","title":"Marginal Effects","text":"can also use argument average marginal effects within different subgroups observed data, based values regressors. example, compute average marginal effects Bill Length Species, : equivalent manually taking mean observation-level marginal effect species sub-group: Note marginaleffects follows Stata margins package computing standard errors using group-wise averaged Jacobian.","code":"mfx2 <- marginaleffects(mod, by = \"species\", variables = \"bill_length_mm\") summary(mfx2) #>             Term    Contrast   species   Effect Std. Error z value   Pr(>|z|) #> 1 bill_length_mm mean(dY/dX)    Adelie 0.043540   0.008828   4.932 8.1365e-07 #> 2 bill_length_mm mean(dY/dX)    Gentoo 0.002872   0.002846   1.009 0.31299360 #> 3 bill_length_mm mean(dY/dX) Chinstrap 0.036801   0.009801   3.755 0.00017337 #>       2.5 %  97.5 % #> 1  0.026237 0.06084 #> 2 -0.002707 0.00845 #> 3  0.017592 0.05601 #>  #> Model type:  glm  #> Prediction type:  response aggregate(dydx ~ species, data = mfx2, FUN = mean) #>     species        dydx #> 1    Adelie 0.043539914 #> 2 Chinstrap 0.036801185 #> 3    Gentoo 0.002871562"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/marginaleffects.html","id":"marginal-effect-at-user-specified-values","dir":"Articles","previous_headings":"","what":"Marginal Effect at User-Specified Values","title":"Marginal Effects","text":"Sometimes, interested unit-specific marginal effects, rather look estimated marginal effects certain “typical” individuals, user-specified values regressors. datagrid function helps us build data grid full “typical” rows. example, generate artificial Adelies Gentoos 180mm flippers: command can used (omitting model argument) marginaleffects’s newdata argument compute marginal effects (fictional) individuals: variables omitted datagrid call, automatically set mean mode (depending variable type).","code":"datagrid(flipper_length_mm = 180,          species = c(\"Adelie\", \"Gentoo\"),          model = mod) #>   large_penguin bill_length_mm flipper_length_mm species #> 1     0.4853801       43.92193               180  Adelie #> 2     0.4853801       43.92193               180  Gentoo marginaleffects(mod,                 newdata = datagrid(flipper_length_mm = 180,                                    species = c(\"Adelie\", \"Gentoo\"))) #>   rowid     type              term           contrast        dydx   std.error #> 1     1 response    bill_length_mm              dY/dX  0.06069179 0.033264242 #> 2     2 response    bill_length_mm              dY/dX  0.08467378 0.040399763 #> 3     1 response flipper_length_mm              dY/dX  0.02329304 0.005497946 #> 4     2 response flipper_length_mm              dY/dX  0.03249805 0.008609938 #> 5     1 response           species Chinstrap - Adelie -0.21105002 0.103178237 #> 6     2 response           species Chinstrap - Adelie -0.21105002 0.103178237 #> 7     1 response           species    Gentoo - Adelie  0.15912111 0.303473386 #> 8     2 response           species    Gentoo - Adelie  0.15912111 0.303473386 #>   statistic      p.value     conf.low   conf.high predicted predicted_hi #> 1  1.824536 6.807114e-02 -0.004504923  0.12588851 0.2125242   0.21269115 #> 2  2.095898 3.609126e-02  0.005491694  0.16385586 0.3716454   0.37187821 #> 3  4.236681 2.268483e-05  0.012517266  0.03406882 0.2125242   0.21266168 #> 4  3.774482 1.603406e-04  0.015622885  0.04937322 0.3716454   0.37183710 #> 5 -2.045490 4.080661e-02 -0.413275648 -0.00882439 0.2125242   0.00147423 #> 6 -2.045490 4.080661e-02 -0.413275648 -0.00882439 0.3716454   0.00147423 #> 7  0.524333 6.000470e-01 -0.435675798  0.75391802 0.2125242   0.37164536 #> 8  0.524333 6.000470e-01 -0.435675798  0.75391802 0.3716454   0.37164536 #>   predicted_lo large_penguin bill_length_mm flipper_length_mm species     eps #> 1    0.2125242     0.4853801       43.92193               180  Adelie 0.00275 #> 2    0.3716454     0.4853801       43.92193               180  Gentoo 0.00275 #> 3    0.2125242     0.4853801       43.92193               180  Adelie 0.00590 #> 4    0.3716454     0.4853801       43.92193               180  Gentoo 0.00590 #> 5    0.2125242     0.4853801       43.92193               180  Adelie      NA #> 6    0.2125242     0.4853801       43.92193               180  Gentoo      NA #> 7    0.2125242     0.4853801       43.92193               180  Adelie      NA #> 8    0.2125242     0.4853801       43.92193               180  Gentoo      NA"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/marginaleffects.html","id":"marginal-effect-at-the-mean-mem","dir":"Articles","previous_headings":"","what":"Marginal Effect at the Mean (MEM)","title":"Marginal Effects","text":"“Marginal Effect Mean” marginal effect calculated hypothetical observation regressor set mean mode. default, datagrid function used previous section sets regressors means modes. calculate MEM, can set newdata argument, determines values predictors want compute marginal effects:","code":"marginaleffects(mod, newdata = \"mean\") #>   rowid     type              term           contrast        dydx   std.error #> 1     1 response    bill_length_mm              dY/dX  0.05023916 0.011987319 #> 2     1 response flipper_length_mm              dY/dX  0.01928351 0.005560114 #> 3     1 response           species Chinstrap - Adelie -0.80703586 0.073295749 #> 4     1 response           species    Gentoo - Adelie  0.08285863 0.113544597 #>     statistic      p.value     conf.low   conf.high predicted predicted_hi #> 1   4.1910258 2.776961e-05  0.026744450  0.07373388 0.8337359    0.8338740 #> 2   3.4681865 5.239835e-04  0.008385889  0.03018114 0.8337359    0.8338496 #> 3 -11.0106775 3.394415e-28 -0.950692885 -0.66337883 0.8337359    0.0267000 #> 4   0.7297452 4.655459e-01 -0.139684692  0.30540195 0.8337359    0.9165945 #>   predicted_lo large_penguin bill_length_mm flipper_length_mm species     eps #> 1    0.8337359     0.4853801       43.92193               201  Adelie 0.00275 #> 2    0.8337359     0.4853801       43.92193               201  Adelie 0.00590 #> 3    0.8337359     0.4853801       43.92193               201  Adelie      NA #> 4    0.8337359     0.4853801       43.92193               201  Adelie      NA"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/marginaleffects.html","id":"counterfactual-marginal-effects","dir":"Articles","previous_headings":"","what":"Counterfactual Marginal Effects","title":"Marginal Effects","text":"datagrid function allowed us look completely fictional individuals. Setting grid_type argument function \"counterfactual\" lets us compute marginal effects actual observations dataset, manipulated values. example, code create data.frame twice long original dat, observation repeated different values flipper_length_mm variable: see rows 1, 2, 3 original dataset replicated twice, different values flipper_length_mm variable: can use observation-level marginal effects compute average (median, anything else) marginal effects counterfactual individuals:","code":"nd <- datagrid(flipper_length_mm = c(160, 180),                model = mod,                grid_type = \"counterfactual\") nd[nd$rowid %in% 1:3,] #>     rowidcf large_penguin bill_length_mm species flipper_length_mm #> 1         1             0           39.1  Adelie               160 #> 2         2             0           39.5  Adelie               160 #> 3         3             0           40.3  Adelie               160 #> 343       1             0           39.1  Adelie               180 #> 344       2             0           39.5  Adelie               180 #> 345       3             0           40.3  Adelie               180 library(dplyr)  marginaleffects(mod, newdata = nd) %>%     group_by(term) %>%     summarize(dydx = median(dydx)) #> # A tibble: 3 × 2 #>   term                   dydx #>   <chr>                 <dbl> #> 1 bill_length_mm    0.00985   #> 2 flipper_length_mm 0.00378   #> 3 species           0.0000226"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/marginaleffects.html","id":"conditional-marginal-effects-plot","dir":"Articles","previous_headings":"","what":"Conditional Marginal Effects (Plot)","title":"Marginal Effects","text":"plot_cme function can used draw “Conditional Marginal Effects.” useful model includes interaction terms want plot marginal effect variable changes value “condition” (“moderator”) variable changes:  marginal effects plot computed values regressors – except effect condition – held means modes, depending variable type. Since plot_cme() produces ggplot2 object, easy customize. example:","code":"mod <- lm(mpg ~ hp * wt + drat, data = mtcars)  plot_cme(mod, effect = \"hp\", condition = \"wt\") plot_cme(mod, effect = \"hp\", condition = \"wt\") +     geom_rug(aes(x = wt), data = mtcars) +     theme_classic()"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/marginaleffects.html","id":"example-quadratic","dir":"Articles","previous_headings":"","what":"Example: Quadratic","title":"Marginal Effects","text":"“Definition” section vignette, considered marginal effects can computed analytically simple quadratic equation context. can now use marginaleffects function replicate analysis quadratic function regression application. Say estimate linear regression model quadratic term: \\[Y = \\beta_0 + \\beta_1 X^2 + \\varepsilon\\] obtain estimates \\(\\beta_0=1\\) \\(\\beta_1=2\\). Taking partial derivative respect \\(X\\) plugging estimates gives us marginal effect \\(X\\) \\(Y\\): \\[\\partial Y / \\partial X = \\beta_0 + 2 \\cdot \\beta_1 X\\] \\[\\partial Y / \\partial X = 1 + 4X\\] result suggests effect change \\(X\\) \\(Y\\) depends level \\(X\\). \\(X\\) large positive, increase \\(X\\) associated large increase \\(Y\\). \\(X\\) small positive, increase \\(X\\) associated small increase \\(Y\\). \\(X\\) large negative value, increase \\(X\\) associated decrease \\(Y\\). marginaleffects arrives conclusion simulated data: can plot conditional adjusted predictions plot_cap function:  can plot conditional marginal effects plot_cme function (see section ):  , conclusion . \\(x<0\\), increase \\(x\\) associated increase \\(y\\). \\(x=0\\), marginal effect equal 0. \\(x>0\\), increase \\(x\\) associated decrease \\(y\\).","code":"library(tidyverse) N <- 1e5 quad <- data.frame(x = rnorm(N)) quad$y <- 1 + 1 * quad$x + 2 * quad$x^2 + rnorm(N) mod <- lm(y ~ x + I(x^2), quad)  marginaleffects(mod, newdata = datagrid(x = -2:2))  %>%     mutate(truth = 1 + 4 * x) %>%     select(dydx, truth) #>        dydx truth #> 1 -6.979229    -7 #> 2 -2.987647    -3 #> 3  1.003934     1 #> 4  4.995516     5 #> 5  8.987097     9 plot_cap(mod, condition = \"x\") plot_cme(mod, effect = \"x\", condition = \"x\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/marginaleffects.html","id":"prediction-types","dir":"Articles","previous_headings":"","what":"Prediction types","title":"Marginal Effects","text":"marginaleffect function takes derivative fitted (predicted) values model, typically generated predict(model) function. default, predict produces predictions \"response\" scale, marginal effects interpreted scale. However, users can pass string vector strings type argument, marginaleffects consider different outcomes. Typical values include \"response\" \"link\", users refer documentation predict package used fit model know values allowable. documentation.","code":"mod <- glm(am ~ mpg, family = binomial, data = mtcars) mfx <- marginaleffects(mod, type = \"response\") summary(mfx) #>   Term  Effect Std. Error z value   Pr(>|z|)   2.5 %  97.5 % #> 1  mpg 0.04649   0.008857   5.249 1.5303e-07 0.02913 0.06385 #>  #> Model type:  glm  #> Prediction type:  response  mfx <- marginaleffects(mod, type = \"link\") summary(mfx) #>   Term Effect Std. Error z value  Pr(>|z|)   2.5 % 97.5 % #> 1  mpg  0.307     0.1148   2.673 0.0075066 0.08194 0.5321 #>  #> Model type:  glm  #> Prediction type:  link"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/marginaleffects.html","id":"regression-tables-and-coefficient-plots","dir":"Articles","previous_headings":"","what":"Regression tables and coefficient plots","title":"Marginal Effects","text":"Average marginal effects easy display regression table using packages like modelsummary. See tables plots vignette.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/marginaleffects.html","id":"supporting-new-models","dir":"Articles","previous_headings":"","what":"Supporting new models","title":"Marginal Effects","text":"cases, extending marginaleffects support new models easy. Imagine want add support object called model class EXAMPLE N observations.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/marginaleffects.html","id":"step-1-check-if-marginaleffects-default-functions-work","dir":"Articles","previous_headings":"Supporting new models","what":"Step 1: Check if marginaleffects default functions work:","title":"Marginal Effects","text":"functions work ---box, ’s good chance model supported automatically. work, move …","code":"# returns a named vector of coefficients get_coef(model)  # returns a named vector of predictions  # returns a named matrix of size NxK for models with K levels (e.g., multinomial logit) get_predict(model)  # returns a named square matrix of size equal to the number of coefficients get_vcov(model)  # returns a new model object with different stored coefficients  # calling get_predict(model) and get_predict(model_new) should produce different results model_new <- set_coef(model, rep(0, length(get_coef(model)))) predict(model) != predict(model_new)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/marginaleffects.html","id":"step-2-define-the-missing-methods-","dir":"Articles","previous_headings":"Supporting new models","what":"Step 2: Define the missing methods.","title":"Marginal Effects","text":"Find class name model calling: , create functions (methods) called get_coef.EXAMPLE, get_predict.EXAMPLE, vcov.EXAMPLE, set_coef.EXAMPLE, “EXAMPLE” replaced name model class.","code":"class(model)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/marginaleffects.html","id":"step-3-add-tests","dir":"Articles","previous_headings":"Supporting new models","what":"Step 3: Add tests","title":"Marginal Effects","text":"Create file called tests/testthat/test-PKGNAME.R write tests. Ideally, like compare results obtained marginaleffects external source, like margins package R, margins command Stata.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/marginaleffects.html","id":"step-4-finalize","dir":"Articles","previous_headings":"Supporting new models","what":"Step 4: Finalize","title":"Marginal Effects","text":"Add new model class lists supported models : sanity_model function R/sanity.R file. supported models CSV table data-raw/supported_models.csv “Suggests” list DESCRIPTION file.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/marginalmeans.html","id":"interactions","dir":"Articles","previous_headings":"","what":"Interactions","title":"Marginal Means","text":"default, marginalmeans() function calculates marginal means categorical predictor one . can also compute marginal means combinations categories setting cross=TRUE: Regardless scale predictions (type argument), marginalmeans() always computes standard errors using Delta Method: model linear link scale, also produces confidence intervals: easy transform link-scale marginal means arbitrary functions using transform_post argument: marginalmeans() defaults reporting EMMs category individually, without cross-margins: can force cross:","code":"library(lme4)  dat <- \"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Titanic.csv\" dat <- read.csv(dat) titanic <- glmer(     Survived ~ Sex * PClass + Age + (1 | PClass),     family = binomial,     data = dat) marginalmeans(     titanic,     type = \"response\",     variables = c(\"Sex\", \"PClass\")) #>     term  value marginalmean  std.error #> 1 PClass    1st    0.7076062 0.02726375 #> 2 PClass    2nd    0.5113187 0.02349549 #> 3 PClass    3rd    0.2417159 0.02814300 #> 4    Sex female    0.7383418 0.02069275 #> 5    Sex   male    0.2354188 0.02025242 marginalmeans(     titanic,     type = \"link\",     variables = c(\"Sex\", \"PClass\")) #>     term  value marginalmean std.error   conf.low  conf.high      p.value #> 1 PClass    1st   1.63065474 0.2705172  1.1004508  2.1608587 1.660877e-09 #> 2 PClass    2nd   0.09968203 0.2109697 -0.3138111  0.5131751 6.365739e-01 #> 3 PClass    3rd  -1.27917256 0.1549518 -1.5828724 -0.9754727 1.515276e-16 #> 4    Sex female   1.64068554 0.2055020  1.2379090  2.0434621 1.419041e-15 #> 5    Sex   male  -1.33990940 0.1237476 -1.5824502 -1.0973686 2.542950e-27 #>     statistic #> 1   6.0279156 #> 2   0.4724944 #> 3  -8.2552949 #> 4   7.9837928 #> 5 -10.8277618 marginalmeans(     titanic,     type = \"link\",     transform_post = insight::link_inverse(titanic),     variables = c(\"Sex\", \"PClass\")) #>     term  value marginalmean  conf.low conf.high      p.value #> 1 PClass    1st    0.8362593 0.7503446 0.8966791 1.660877e-09 #> 2 PClass    2nd    0.5248999 0.4221848 0.6255505 6.365739e-01 #> 3 PClass    3rd    0.2176911 0.1703891 0.2737910 1.515276e-16 #> 4    Sex female    0.8376282 0.7751998 0.8852853 1.419041e-15 #> 5    Sex   male    0.2075250 0.1704488 0.2502333 2.542950e-27 titanic2 <- glmer(     Survived ~ Sex + PClass + Age + (1 | PClass),     family = binomial,     data = dat)  marginalmeans(     titanic2,     variables = c(\"Sex\", \"PClass\")) #>     term  value marginalmean  conf.low conf.high      p.value #> 1 PClass    1st    0.7778338 0.7059595 0.8362154 7.498210e-11 #> 2 PClass    2nd    0.4902824 0.4071513 0.5739545 8.210648e-01 #> 3 PClass    3rd    0.2195429 0.1683384 0.2810591 4.247510e-14 #> 4    Sex female    0.7854373 0.7307995 0.8315419 1.779451e-17 #> 5    Sex   male    0.2085450 0.1709283 0.2519246 1.660045e-26 marginalmeans(     titanic2,     cross = TRUE,     variables = c(\"Sex\", \"PClass\")) #>      Sex PClass marginalmean   conf.low conf.high      p.value #> 1 female    1st   0.92882414 0.89008215 0.9546074 5.036296e-26 #> 2 female    2nd   0.78190514 0.70413410 0.8437691 1.012089e-09 #> 3 female    3rd   0.51183442 0.42257389 0.6003465 7.963418e-01 #> 4   male    1st   0.48435732 0.39415021 0.5755954 7.383894e-01 #> 5   male    2nd   0.20512692 0.15125465 0.2720369 7.462936e-13 #> 6   male    3rd   0.07017461 0.04785084 0.1017996 1.310275e-35"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/marginalmeans.html","id":"group-averages-with-the-by-argument","dir":"Articles","previous_headings":"","what":"Group averages with the by argument","title":"Marginal Means","text":"can collapse marginal means via averaging using argument: can use hypothesis argument compare new collapsed subgroups:","code":"dat <- mtcars dat$am <- factor(dat$am) dat$vs <- factor(dat$vs) dat$cyl <- factor(dat$cyl)  mod <- glm(gear ~ cyl + vs + am, data = dat, family = poisson)  by <- data.frame(     by = c(\"(4 & 6)\", \"(4 & 6)\", \"(8)\"),     cyl = c(4, 6, 8))  marginalmeans(mod, by = by) #>        by marginalmean conf.low conf.high      p.value #> 1 (4 & 6)     3.861699 2.856543  5.220546 1.587406e-18 #> 2     (8)     3.593085 2.106679  6.128253 2.662085e-06 marginalmeans(mod, by = by, hypothesis = \"pairwise\") #>            term marginalmean  conf.low conf.high   p.value #> 1 (4 & 6) - (8)     1.074758 0.5149323  2.243218 0.8477116"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/marginalmeans.html","id":"custom-contrasts-and-linear-combinations","dir":"Articles","previous_headings":"","what":"Custom Contrasts and Linear Combinations","title":"Marginal Means","text":"See vignette Custom Contrasts Combinations","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/marginalmeans.html","id":"tidy-summaries","dir":"Articles","previous_headings":"","what":"Tidy summaries","title":"Marginal Means","text":"summary, tidy, glance functions also available summarize manipulate results: Thanks tidiers, can also present results style regression table using modelsummary package. examples, see tables plots vignette.","code":"mm <- marginalmeans(mod)  tidy(mm) #>   term value estimate      p.value conf.low conf.high #> 1   am     0 3.271615 3.955749e-15 2.434117  4.397269 #> 2   am     1 4.344309 6.833090e-19 3.141106  6.008399 #> 3  cyl     4 3.826645 2.336920e-08 2.389395  6.128417 #> 4  cyl     6 3.897074 1.573029e-12 2.672537  5.682685 #> 5  cyl     8 3.593085 2.662085e-06 2.106679  6.128253 #> 6   vs     0 3.794921 1.882061e-12 2.618291  5.500313 #> 7   vs     1 3.745245 5.820764e-10 2.466321  5.687361  glance(mm) #>        aic     bic r2.nagelkerke      rmse nobs         F    logLik #> 1 113.0034 120.332     0.6720045 0.4368402   32 0.7371939 -51.50168  summary(mm) #>   Term Value  Mean   Pr(>|z|) 2.5 % 97.5 % #> 1   am     0 3.272 3.9557e-15 2.434  4.397 #> 2   am     1 4.344 < 2.22e-16 3.141  6.008 #> 3  cyl     4 3.827 2.3369e-08 2.389  6.128 #> 4  cyl     6 3.897 1.5730e-12 2.673  5.683 #> 5  cyl     8 3.593 2.6621e-06 2.107  6.128 #> 6   vs     0 3.795 1.8821e-12 2.618  5.500 #> 7   vs     1 3.745 5.8208e-10 2.466  5.687 #>  #> Model type:  glm  #> Prediction type:  link  #> Results averaged over levels of: cyl, vs, am"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/marginalmeans.html","id":"case-study-multinomial-logit","dir":"Articles","previous_headings":"","what":"Case study: Multinomial Logit","title":"Marginal Means","text":"example requires version 0.2.0 marginaleffects package. begin, generate data estimate large model: Try compute marginal means, realize grid won’t fit memory: Use variables variables_grid arguments compute marginal means reasonably sized grid:","code":"library(nnet) library(marginaleffects)  set.seed(1839) n <- 1200 x <- factor(sample(letters[1:3], n, TRUE)) y <- vector(length = n) y[x == \"a\"] <- sample(letters[4:6], sum(x == \"a\"), TRUE) y[x == \"b\"] <- sample(letters[4:6], sum(x == \"b\"), TRUE, c(1 / 4, 2 / 4, 1 / 4)) y[x == \"c\"] <- sample(letters[4:6], sum(x == \"c\"), TRUE, c(1 / 5, 3 / 5, 2 / 5))  dat <- data.frame(x = x, y = factor(y)) tmp <- as.data.frame(replicate(20, factor(sample(letters[7:9], n, TRUE)))) dat <- cbind(dat, tmp) void <- capture.output({     mod <- multinom(y ~ ., dat) }) marginalmeans(mod, type = \"probs\") #> Error: You are trying to create a prediction grid with more than 1 billion rows, which is likely to exceed the memory and computational power available on your local machine. Presumably this is because you are considering many variables with many levels. All of the functions in the `marginaleffects` package include arguments to specify a restricted list of variables over which to create a prediction grid. marginalmeans(mod,               type = \"probs\",               variables = c(\"x\", \"V1\"),               variables_grid = paste0(\"V\", 2:3))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/marginalmeans.html","id":"plot-conditional-marginal-means","dir":"Articles","previous_headings":"","what":"Plot conditional marginal means","title":"Marginal Means","text":"marginaleffects package offers several functions plot quantities vary function others: plot_cap: Conditional adjusted predictions – predicted outcome change function regressors? plot_cco: Conditional comparisons – contrasts change function regressors? plot_cme: Conditional marginal effects – slope change function regressors? analogous function marginal means. However, easy achieve similar effect using predictions() function, argument, standard plotting functions. example , take steps: Estimate model one continuous (hp) one categorical regressor (cyl). Create perfectly “balanced” data grid combination hp cyl. specified user datagrid() call. Compute fitted values (aka “adjusted predictions”) cell grid. Use argument take average predicted values value hp, across margins cyl. Compute standard errors around averaged predicted values (.e., marginal means). Create symmetric confidence intervals usual manner. Plot results.","code":"library(ggplot2)  mod <- lm(mpg ~ hp + factor(cyl), data = mtcars)  p <- predictions(mod,     by = \"hp\",     newdata = datagrid(         model = mod,         hp = seq(100, 120, length.out = 10),         cyl = mtcars$cyl))  ggplot(p) +     geom_ribbon(aes(hp, ymin = conf.low, ymax = conf.high), alpha = .2) +     geom_line(aes(hp, predicted))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/mlogit.html","id":"nnet-package","dir":"Articles","previous_headings":"","what":"nnet package","title":"Multinomial Logit and Discrete Choice Models","text":"multinom function nnet package allows users fit log-linear models via neural networks. data used function data frame one observation per row, response variable coded factor. marginaleffects package function work seamlessly model. example, can estimate model compute average marginal effects follows: Notice models, get one marginal effect term, level response variable. reason, use \"group\" condition argument (facet_*() function) calling one plotting functions:","code":"library(nnet)  head(mtcars) #>                    mpg cyl disp  hp drat    wt  qsec vs am gear carb #> Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4 #> Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4 #> Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1 #> Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1 #> Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2 #> Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1  mod <- multinom(factor(gear) ~ hp + mpg, data = mtcars, trace = FALSE)  marginaleffects(mod, type = \"probs\") %>% summary() #>   Group Term     Effect Std. Error  z value   Pr(>|z|)     2.5 %     97.5 % #> 1     3   hp -3.438e-05   0.002253 -0.01526 0.98782440 -0.004450  0.0043815 #> 2     3  mpg -7.131e-02   0.026441 -2.69703 0.00699606 -0.123134 -0.0194886 #> 3     4   hp -4.667e-03   0.002199 -2.12294 0.03375920 -0.008976 -0.0003583 #> 4     4  mpg  1.591e-02   0.020003  0.79525 0.42646997 -0.023298  0.0551125 #> 5     5   hp  4.702e-03   0.001304  3.60439 0.00031289  0.002145  0.0072584 #> 6     5  mpg  5.540e-02   0.016469  3.36416 0.00076776  0.023126  0.0876827 #>  #> Model type:  multinom  #> Prediction type:  probs library(ggplot2)  plot_cap(mod, condition = c(\"mpg\", \"group\"), type = \"probs\") plot_cap(mod, condition = \"mpg\", type = \"probs\") + facet_wrap(~group) plot_cco(     mod,     effect = list(mpg = c(15, 30)),     condition = \"group\",     type = \"probs\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/mlogit.html","id":"mlogit-package","dir":"Articles","previous_headings":"","what":"mlogit package","title":"Multinomial Logit and Discrete Choice Models","text":"mlogit package uses data slightly different structure, one row per observation-choice combination. example, data choice travel mode includes 4 rows per individual, one mode transportation: Note marginaleffects function always return estimates zero regressors vertical bar formula. predict() function supplied mlogit package produce different predictions different values variables. compute different kinds marginal effects, can construct customized data frames feed newdata argument marginaleffects function. Important: newdata argument mlogit models must “balanced” data frame, , must number rows multiple number choices. want compute slope response function (marginal effects) predictors fixed global mean, can : want compute marginal effects gcost wait fixed mean value, conditional choice transportation mode: can also explore complex alternatives. , example, one alternative affected cost reduction:","code":"library(\"AER\") library(\"mlogit\") library(tidyverse) data(\"TravelMode\", package = \"AER\")  head(TravelMode) #>   individual  mode choice wait vcost travel gcost income size #> 1          1   air     no   69    59    100    70     35    1 #> 2          1 train     no   34    31    372    71     35    1 #> 3          1   bus     no   35    25    417    70     35    1 #> 4          1   car    yes    0    10    180    30     35    1 #> 5          2   air     no   64    58     68    68     30    2 #> 6          2 train     no   44    31    354    84     30    2  mod <- mlogit(choice ~ wait + gcost | income + size, TravelMode)  marginaleffects(mod, variables = c(\"income\", \"size\")) %>% summary() #>   Group   Term     Effect Std. Error z value   Pr(>|z|)      2.5 %    97.5 % #> 1   air income  0.0027855   0.001218  2.2876   0.022159  0.0003990  0.005172 #> 2   bus income -0.0003721   0.001103 -0.3374   0.735811 -0.0025337  0.001790 #> 3   car income  0.0033731   0.001373  2.4559   0.014052  0.0006812  0.006065 #> 4 train income -0.0057865   0.001319 -4.3861 1.1540e-05 -0.0083723 -0.003201 #> 5   air   size -0.1264647   0.028918 -4.3732 1.2245e-05 -0.1831434 -0.069786 #> 6   bus   size  0.0113450   0.025867  0.4386   0.660962 -0.0393539  0.062044 #> 7   car   size  0.0458798   0.024755  1.8534   0.063830 -0.0026388  0.094398 #> 8 train   size  0.0692398   0.024785  2.7936   0.005212  0.0206624  0.117817 #>  #> Model type:  mlogit  #> Prediction type:  response nd <- TravelMode %>%     summarize(across(c(\"wait\", \"gcost\", \"income\", \"size\"),               function(x) rep(mean(x), 4))) nd #>       wait    gcost   income     size #> 1 34.58929 110.8798 34.54762 1.742857 #> 2 34.58929 110.8798 34.54762 1.742857 #> 3 34.58929 110.8798 34.54762 1.742857 #> 4 34.58929 110.8798 34.54762 1.742857  marginaleffects(mod, newdata = nd, variables = c(\"income\", \"size\")) |> summary() #>   Group   Term     Effect Std. Error z value  Pr(>|z|)      2.5 %     97.5 % #> 1   air income  6.656e-03  2.426e-03   2.743 0.0060816  1.901e-03  0.0114108 #> 2   bus income -1.141e-03  9.454e-04  -1.207 0.2273591 -2.994e-03  0.0007117 #> 3   car income  6.480e-06  2.032e-05   0.319 0.7497346 -3.334e-05  0.0000463 #> 4 train income -5.521e-03  1.910e-03  -2.890 0.0038527 -9.265e-03 -0.0017767 #> 5   air   size -1.694e-01  5.877e-02  -2.883 0.0039386 -2.846e-01 -0.0542485 #> 6   bus   size  4.672e-02  2.723e-02   1.716 0.0862434 -6.656e-03  0.1000991 #> 7   car   size  1.358e-03  8.808e-04   1.542 0.1230361 -3.680e-04  0.0030845 #> 8 train   size  1.214e-01  4.447e-02   2.729 0.0063528  3.420e-02  0.2085119 #>  #> Model type:  mlogit  #> Prediction type:  response nd <- TravelMode %>%     group_by(mode) %>%     summarize(across(c(\"wait\", \"gcost\", \"income\", \"size\"), mean)) nd #> # A tibble: 4 × 5 #>   mode   wait gcost income  size #>   <fct> <dbl> <dbl>  <dbl> <dbl> #> 1 air    61.0 103.    34.5  1.74 #> 2 train  35.7 130.    34.5  1.74 #> 3 bus    41.7 115.    34.5  1.74 #> 4 car     0    95.4   34.5  1.74  marginaleffects(mod, newdata = nd, variables = c(\"income\", \"size\")) |> summary() #>   Group   Term     Effect Std. Error z value   Pr(>|z|)      2.5 %    97.5 % #> 1   air income  0.0060149   0.002332  2.5793  0.0098996  0.0014443  0.010586 #> 2   bus income -0.0007128   0.001461 -0.4878  0.6256800 -0.0035768  0.002151 #> 3   car income  0.0054450   0.002288  2.3800  0.0173140  0.0009609  0.009929 #> 4 train income -0.0107471   0.002563 -4.1925 2.7592e-05 -0.0157713 -0.005723 #> 5   air   size -0.2329273   0.056622 -4.1137 3.8936e-05 -0.3439050 -0.121950 #> 6   bus   size  0.0204397   0.034364  0.5948  0.5519797 -0.0469129  0.087792 #> 7   car   size  0.0678200   0.041226  1.6451  0.0999517 -0.0129810  0.148621 #> 8 train   size  0.1446676   0.047752  3.0295  0.0024493  0.0510747  0.238261 #>  #> Model type:  mlogit  #> Prediction type:  response nd <- datagrid(mode = TravelMode$mode, newdata = TravelMode) nd <- lapply(1:4, function(i) mutate(nd, gcost = ifelse(1:4 == i, 30, gcost))) nd <- bind_rows(nd) nd #>    individual choice wait vcost travel gcost income size  mode #> 1           1     no   35    48    486    30     35    2   air #> 2           1     no   35    48    486   111     35    2 train #> 3           1     no   35    48    486   111     35    2   bus #> 4           1     no   35    48    486   111     35    2   car #> 5           1     no   35    48    486   111     35    2   air #> 6           1     no   35    48    486    30     35    2 train #> 7           1     no   35    48    486   111     35    2   bus #> 8           1     no   35    48    486   111     35    2   car #> 9           1     no   35    48    486   111     35    2   air #> 10          1     no   35    48    486   111     35    2 train #> 11          1     no   35    48    486    30     35    2   bus #> 12          1     no   35    48    486   111     35    2   car #> 13          1     no   35    48    486   111     35    2   air #> 14          1     no   35    48    486   111     35    2 train #> 15          1     no   35    48    486   111     35    2   bus #> 16          1     no   35    48    486    30     35    2   car  marginaleffects(mod, newdata = nd, variables = c(\"income\", \"size\")) |> summary() #>   Group   Term     Effect Std. Error z value   Pr(>|z|)      2.5 %     97.5 % #> 1   air income  8.240e-03  2.463e-03  3.3454 0.00082164  0.0034123  0.0130668 #> 2   bus income -1.328e-03  1.304e-03 -1.0183 0.30853207 -0.0038827  0.0012276 #> 3   car income  2.659e-05  4.321e-05  0.6154 0.53832121 -0.0000581  0.0001113 #> 4 train income -6.939e-03  1.860e-03 -3.7298 0.00019166 -0.0105848 -0.0032924 #> 5   air   size -2.124e-01  6.027e-02 -3.5247 0.00042400 -0.3305707 -0.0943084 #> 6   bus   size  6.062e-02  3.791e-02  1.5993 0.10974995 -0.0136709  0.1349205 #> 7   car   size  2.378e-03  1.571e-03  1.5130 0.13028300 -0.0007024  0.0054575 #> 8 train   size  1.494e-01  4.286e-02  3.4870 0.00048852  0.0654413  0.2334331 #>  #> Model type:  mlogit  #> Prediction type:  response"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/modelsummary.html","id":"marginal-effects","dir":"Articles","previous_headings":"","what":"Marginal effects","title":"Tables and Plots","text":"can summarize results comparisons() marginaleffects() functions using modelsummary package. results can visualized modelplot():","code":"library(modelsummary) library(marginaleffects)  mod <- glm(am ~ wt + drat, family = binomial, data = mtcars) mfx <- marginaleffects(mod)  modelsummary(mfx) modelplot(mfx)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/modelsummary.html","id":"contrasts","dir":"Articles","previous_headings":"","what":"Contrasts","title":"Tables and Plots","text":"Note: code section requires version modelsummary package greater 1.2.0. available CRAN, can install development version following instructions modelsummary website. using comparisons() function (marginaleffects() function categorical variables), output include two columns uniquely identify quantities interest: term contrast. can use group argument modelsummary function structure table properly: Cross-contrasts can bit trickier, since multiple simultaneous groups. Consider example: can see , two relevant grouping columns: contrast_gear contrast_cyl. can simply plug names shape argument:","code":"dat <- mtcars dat$gear <- as.factor(dat$gear) mod <- glm(vs ~ gear + mpg, data = dat, family = binomial)  cmp <- comparisons(mod) tidy(cmp) #>       type term contrast    estimate  std.error  statistic      p.value #> 1 response gear    4 - 3  0.03717842 0.13656702  0.2722357 7.854408e-01 #> 2 response gear    5 - 3 -0.33968823 0.09882783 -3.4371718 5.878226e-04 #> 3 response  mpg       +1  0.06080995 0.01283781  4.7367850 2.171353e-06 #>      conf.low  conf.high #> 1 -0.23048802  0.3048449 #> 2 -0.53338721 -0.1459892 #> 3  0.03564831  0.0859716 modelsummary(cmp, group = term + contrast ~ model) mod <- lm(mpg ~ factor(cyl) + factor(gear), data = mtcars) cmp <- comparisons(   mod,   variables = c(\"gear\", \"cyl\"),   cross = TRUE) tidy(cmp) #>       type  term contrast_gear contrast_cyl  estimate std.error statistic #> 1 response cross         4 - 3        6 - 4 -5.331884  2.768998 -1.925564 #> 2 response cross         4 - 3        8 - 4 -9.218116  3.618491 -2.547503 #> 3 response cross         5 - 3        6 - 4 -5.155797  2.630642 -1.959901 #> 4 response cross         5 - 3        8 - 4 -9.042029  3.185042 -2.838904 #>       p.value  conf.low     conf.high #> 1 0.054158790 -10.75902  0.0952524474 #> 2 0.010849693 -16.31023 -2.1260044175 #> 3 0.050007362 -10.31176  0.0001656772 #> 4 0.004526879 -15.28460 -2.7994608309 modelsummary(   cmp,   shape = contrast_gear + contrast_cyl ~ model)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/modelsummary.html","id":"marginal-means","dir":"Articles","previous_headings":"","what":"Marginal means","title":"Tables and Plots","text":"Estimated Marginal Means","code":"library(marginaleffects) library(\"modelsummary\")  dat <- mtcars dat$cyl <- as.factor(dat$cyl) dat$am <- as.logical(dat$am) mod <- lm(mpg ~ hp + cyl + am, data = dat) mm <- marginalmeans(mod)  modelsummary(mm,              title = \"Estimated Marginal Means\",              estimate = \"{estimate} ({std.error}){stars}\",              statistic = NULL,              group = term + value ~ model)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/multiple_imputation.html","id":"linear-regression-with-mice","dir":"Articles","previous_headings":"","what":"Linear Regression with mice","title":"Multiple Imputation","text":"Let’s first set data. next steps use mice create imputed data sets. , asking m = 20 imputations. Importantly, mice creates multiple imputation, creates list data sets. , dat_mice 20 nearly identical versions data list missing values imputed. work list data sets, ’ll create function (case called fit_reg) fits model computes marginal effects. Using function, can apply data set dat_mice list using lapply(). , can pool get summary. can compare model looked like without missing data. estimates similar (within one standard error) p-value imputed models slightly higher full model (expected).","code":"library(mice) library(marginaleffects) library(modelsummary)  dat <- mtcars dat$am[c(2, 5, 9, 12)] <- NA dat$mpg[c(3, 1, 8, 16)] <- NA dat$hp[c(1, 10, 13, 18)] <- NA dat_mice <- mice(dat, m = 20, printFlag = FALSE, .Random.seed = 1024) dat_mice <- complete(dat_mice, \"all\") fit_reg <- function(dat) {     mod <- lm(mpg ~ hp, data = dat)     out <- marginaleffects(mod, newdata = dat)     return(out) } mod_imputation <- lapply(dat_mice, fit_reg) mod_imputation <- pool(mod_imputation)  summary(mod_imputation) #>   term   estimate  std.error statistic       df      p.value #> 1   hp -0.0648756 0.01124098 -5.771348 14520.87 8.024477e-09 mod_missing <- lm(mpg ~ hp, data = dat) mod_missing <- marginaleffects(mod_missing) mod_complete <- lm(mpg ~ hp, data = mtcars) mod_complete <- marginaleffects(mod_complete)  models <- list(     \"Listwise Deletion\" = mod_missing,     \"Complete\" = mod_complete,     \"Multiple Imputation\" = mod_imputation)  modelsummary(models)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/multiple_imputation.html","id":"categories-and-contrasts-problem-and-solution","dir":"Articles","previous_headings":"","what":"Categories and Contrasts: Problem and Solution","title":"Multiple Imputation","text":"One particular problem arises cases contrasts categorical predictors. see , notice contrasts categorical predictors, tidy() method marginaleffects identifies unique estimates using two columns called term contrast: poses problems mice::pool function merges estimates based term column. means original procedure erroneously combine different contrast levels. example: One hack work around limitation assign custom class object create custom tidy method combines term contrast columns:","code":"mod <- lm(mpg ~ factor(cyl), data = dat) mfx <- marginaleffects(mod) tidy(mfx) #>       type term contrast   estimate std.error statistic      p.value  conf.low #> 1 response  cyl    6 - 4  -7.811111  1.671348 -4.673540 2.960519e-06 -11.08689 #> 2 response  cyl    8 - 4 -11.882906  1.375107 -8.641441 5.550854e-18 -14.57807 #>   conf.high #> 1 -4.535330 #> 2 -9.187746 fit_reg <- function(dat) {     mod <- lm(mpg ~ factor(cyl), data = dat)     out <- marginaleffects(mod, newdata = dat)     return(out) } mod_imputation <- lapply(dat_mice, fit_reg) mod_imputation <- pool(mod_imputation)  summary(mod_imputation) #>   term  estimate std.error statistic       df     p.value #> 1  cyl -9.144838  2.757455 -3.316406 79.30665 0.001377434 fit_reg <- function(dat) {     mod <- lm(mpg ~ factor(cyl), data = dat)     out <- marginaleffects(mod, newdata = dat)     # the next line assigns a custom class     class(out) <- c(\"custom\", class(out))     return(out) }  # this custom method will be called automatically for all objects produced by fit_reg() tidy.custom <- function(x, ...) {     out <- marginaleffects:::tidy.marginaleffects(x, ...)     out$term <- paste(out$term, out$contrast)     return(out) }  mod_imputation <- lapply(dat_mice, fit_reg) mod_imputation <- pool(mod_imputation)  summary(mod_imputation) #>        term   estimate std.error statistic       df      p.value #> 1 cyl 6 - 4  -6.958766  1.760469 -3.952790 1043.860 8.244616e-05 #> 2 cyl 8 - 4 -11.330909  1.446214 -7.834876 1576.039 8.437695e-15"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/multiple_imputation.html","id":"logistic-regression-with-mice","dir":"Articles","previous_headings":"","what":"Logistic Regression with mice","title":"Multiple Imputation","text":"logistic regression, ’ll work dat_mice imputed data sets. ’ll update function run logistic regression want call fit_logistic. Using function, can apply data set dat_mice list using lapply(). , can pool get summary. , can compare model looked like without missing data. estimates, , similar (within one standard error) p-value imputed models slightly higher full model (expected).","code":"fit_logistic <- function(dat) {     mod <- glm(am ~ mpg, data = dat, family = binomial)     out <- marginaleffects(mod, newdata = dat)     return(out) } mod_imputation <- lapply(dat_mice, fit_logistic) mod_imputation <- pool(mod_imputation)  summary(mod_imputation) #>   term  estimate  std.error statistic       df      p.value #> 1  mpg 0.0503705 0.01075946  4.681509 406.9616 3.885234e-06 mod_missing <- glm(am ~ mpg, data = dat, family = binomial) mod_complete <- glm(am ~ mpg, data = mtcars, family = binomial) mod_missing <- marginaleffects(mod_missing) mod_complete <- marginaleffects(mod_complete)  models <- list(     \"Listwise Deletion\" = mod_missing,     \"Complete\" = mod_complete,     \"Multiple Imputation\" = mod_imputation)  modelsummary(models)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/multiple_imputation.html","id":"multilevel-modeling-with-lme4","dir":"Articles","previous_headings":"","what":"Multilevel Modeling with lme4","title":"Multiple Imputation","text":"last example use data lme4 known sleepstudy. Let’s first set data. randomly create missing outcome variable known Reaction. , next steps use mice create imputed data sets. work list data sets, ’ll create function (case called fit_reg) fits model computes marginal effects. Using function, can apply data set dat_mice list using lapply(). , can pool get summary. Like previous models, can compare model looked like without missing data. estimates similar (within one standard error) p-value imputed models slightly higher full model (expected).","code":"library(lme4) data(\"sleepstudy\")  set.seed(1234)  dat2 <- sleepstudy dat2$Reaction[sample(1:180, 10)] <- NA dat_mice2 <- mice(dat2, m = 20, printFlag = FALSE, .Random.seed = 1024) dat_mice2 <- complete(dat_mice2, \"all\") fit_mlm <- function(dat) {     mod <- lmer(Reaction ~ Days + (1 + Days|Subject), data = dat)     out <- marginaleffects(mod, newdata = dat)     return(out) } mod_imputation <- lapply(dat_mice2, fit_mlm) mod_imputation <- pool(mod_imputation)  summary(mod_imputation) #>   term estimate std.error statistic       df      p.value #> 1 Days 10.25971  1.563251  6.563063 172.3149 5.950207e-10 mod_complete <- lmer(Reaction ~ Days + (1 + Days|Subject), data = sleepstudy) mod_missing <- lmer(Reaction ~ Days + (1 + Days|Subject), data = dat2) mod_complete <- marginaleffects(mod_complete) mod_missing <- marginaleffects(mod_missing)  models <- list(     \"Listwise Deletion\" = mod_missing,     \"Complete\" = mod_complete,     \"Multiple Imputation\" = mod_imputation)  modelsummary(models)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/performance.html","id":"what-to-do-when-marginaleffects-is-slow","dir":"Articles","previous_headings":"","what":"What to do when marginaleffects is slow?","title":"Performance","text":"options: Compute marginal effects contrasts mean (representative value) instead observed rows original dataset: Use newdata argument datagrid() function. Compute marginal effects subset variables, paying special attention exclude factor variables can particularly costly process: Use variables argument. compute standard errors: Use vcov = FALSE argument. simulation illustrates computation time varies model 25 regressors 100,000 observations: benchmarks conducted using development version marginaleffects 2022-04-15.","code":"library(marginaleffects)  # simulate data and fit a large model N <- 1e5 dat <- data.frame(matrix(rnorm(N * 26), ncol = 26)) mod <- lm(X1 ~ ., dat)  results <- bench::mark(     # marginal effects at the mean; no standard error     marginaleffects(mod, vcov = FALSE, newdata = \"mean\"),     # marginal effects at the mean     marginaleffects(mod, newdata = datagrid()),     # 1 variable; no standard error     marginaleffects(mod, vcov = FALSE, variables = \"X3\"),     # 1 variable     marginaleffects(mod, variables = \"X3\"),     # 26 variables; no standard error     marginaleffects(mod, vcov = FALSE),     # 26 variables     marginaleffects(mod),     iterations = 1, check = FALSE)  results[, c(1, 3, 5)] #   <bch:expr>                                               <bch:tm> <bch:byt> # 1 marginaleffects(mod, vcov = FALSE, newdata = \"mean\") 141.04ms  233.94MB # 2 marginaleffects(mod, newdata = \"mean\")               276.61ms  236.18MB # 3 marginaleffects(mod, vcov = FALSE, variables = \"X3\")     193.81ms  385.33MB # 4 marginaleffects(mod, variables = \"X3\")                      2.85s    3.14GB # 5 marginaleffects(mod, vcov = FALSE)                          4.32s    7.62GB # 6 marginaleffects(mod)                                        1.15m   76.55GB"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/performance.html","id":"speed-comparison","dir":"Articles","previous_headings":"","what":"Speed comparison","title":"Performance","text":"marginaleffects functions relatively fast. simulation conducted using development version package 2022-04-04: marginaleffects 6x faster margins unit-level standard errors computed: marginaleffects can nearly 600x times faster margins unit-level standard errors computed: Models estimated larger datasets (> 1000 observations) can difficult process using margins package, memory time constraints. contrast, marginaleffects can work well much larger datasets. cases, marginaleffects considerably slower packages like emmeans modmarg. packages make extensive use hard-coded analytical derivatives, reimplement fast prediction functions.","code":"library(margins)  N <- 1e3 dat <- data.frame(     y = sample(0:1, N, replace = TRUE),     x1 = rnorm(N),     x2 = rnorm(N),     x3 = rnorm(N),     x4 = factor(sample(letters[1:5], N, replace = TRUE))) mod <- glm(y ~ x1 + x2 + x3 + x4, data = dat, family = binomial) results <- bench::mark(     marginaleffects(mod, vcov = FALSE),     margins(mod, unit_ses = FALSE),     check = FALSE, relative = TRUE) results[, c(1, 3, 5)]  #   expression                        median mem_alloc #   <bch:expr>                          <dbl>     <dbl> # 1 marginaleffects(mod, vcov = FALSE)   1         1 # 2 margins(mod, unit_ses = FALSE)       6.15      4.17 results <- bench::mark(     marginaleffects(mod, vcov = TRUE),     margins(mod, unit_ses = TRUE),     check = FALSE, relative = TRUE, iterations = 1) results[, c(1, 3, 5)]  #   expression                        median mem_alloc # 1 marginaleffects(mod, vcov = TRUE)     1        1 # 2 margins(mod, unit_ses = TRUE)       581.      20.5"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/plot.html","id":"interactions-conditional-adjusted-predictions","dir":"Articles","previous_headings":"","what":"Interactions: Conditional Adjusted Predictions","title":"Plots: interactions, predictions, contrasts, and slopes","text":"Consider linear model interactions, relationship hp mpg conditional values wt cyl:  can show predicted values mpg different values different predictors:  can include 3rd conditioning variable, specify values want consider, use one several string shortcuts common reference values (“threenum”, “minmax”, “quartile”, etc.):","code":"mod <- lm(mpg ~ hp * wt * factor(cyl), data = mtcars)  plot_cap(mod, condition = \"hp\") plot_cap(mod, condition = c(\"hp\", \"cyl\")) plot_cap(mod, condition = list(hp = 110:120, \"wt\" = \"threenum\")) /  plot_cap(mod, condition = list(\"hp\", \"wt\" = \"minmax\")) /  plot_cap(mod, condition = list(\"hp\", \"wt\" = fivenum)) /  plot_cap(mod, condition = c(\"hp\", \"wt\", \"cyl\"))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/plot.html","id":"customizing-plots","dir":"Articles","previous_headings":"","what":"Customizing plots","title":"Plots: interactions, predictions, contrasts, and slopes","text":"useful feature plotting functions package produce normal ggplot2 objects. can customize heart’s content, using ggplot2 , one many packages designed augment functionalities:  plotting functions work model supported marginaleffects package, can plot output logistic regression model. plot shows probability survival aboard Titanic, different ages different ticket classes:  Thanks Andrew Heiss inspired plot.","code":"library(ggokabeito) library(ggrepel)  mt <- mtcars mt$label <- row.names(mt)  mod <- lm(mpg ~ hp * factor(cyl), data = mt)  plot_cap(mod, condition = c(\"hp\", \"cyl\"), vcov = FALSE) +     geom_point(aes(x = hp, y = mpg, color = factor(cyl)), data = mt) +     geom_rug(aes(x = hp, y = mpg), data = mt) +     geom_text_repel(aes(x = hp, y = mpg, label = label),                     data = subset(mt, hp > 250),                     nudge_y = 2) +     theme_classic() +     scale_color_okabe_ito() library(ggdist)  dat <- \"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Titanic.csv\" dat <- read.csv(dat)  mod <- glm(Survived ~ Age * PClass, data = dat, family = binomial)  plot_cap(mod, condition = c(\"Age\", \"PClass\")) +     geom_dots(         alpha = .8,         scale = .3,         pch = 18,         data = dat, aes(         x = Age,         y = Survived,         side = ifelse(Survived == 1, \"bottom\", \"top\")))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/plot.html","id":"fits-and-smooths","dir":"Articles","previous_headings":"","what":"Fits and smooths","title":"Plots: interactions, predictions, contrasts, and slopes","text":"can compare model predictors fits smoothers using geom_smooth() function ggplot2 package:","code":"dat <- \"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Titanic.csv\" dat <- read.csv(dat) mod <- glm(Survived ~ Age * PClass, data = dat, family = binomial)  plot_cap(mod, condition = c(\"Age\", \"PClass\")) +     geom_smooth(data = dat, aes(Age, Survived), method = \"lm\", se = FALSE, color = \"black\") +     geom_smooth(data = dat, aes(Age, Survived), se = FALSE, color = \"black\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/plot.html","id":"extreme-customization","dir":"Articles","previous_headings":"","what":"Extreme customization","title":"Plots: interactions, predictions, contrasts, and slopes","text":"Designing effective data visualizations requires lot customization specific context data. plotting functions marginaleffects offer powerful way iterate quickly plots models, obviously support features users may want. Thankfully, easy use marginaleffects functions generate datasets can used ggplot2 data visualization tool. Just use draw argument:","code":"p <- plot_cap(mod, condition = c(\"Age\", \"PClass\"), draw = FALSE) head(p) #>   rowid     type predicted  std.error statistic      p.value  conf.low #> 1     1 response 0.8717909 0.04858089 17.945140 5.237868e-72 0.7436448 #> 2     2 response 0.7632110 0.06638393 11.496924 1.367008e-30 0.6107369 #> 3     3 response 0.4079623 0.07663813  5.323228 1.019416e-07 0.2700636 #> 4     4 response 0.8594973 0.04914581 17.488719 1.746399e-68 0.7337014 #> 5     5 response 0.7360650 0.06490403 11.340821 8.236762e-30 0.5916568 #> 6     6 response 0.3859279 0.06737162  5.728346 1.014148e-08 0.2647067 #>   conf.high Survived condition1 condition2 #> 1 0.9409650        0    0.17000        1st #> 2 0.8687919        0    0.17000        2nd #> 3 0.5620556        0    0.17000        3rd #> 4 0.9314231        0    3.12125        1st #> 5 0.8429591        0    3.12125        2nd #> 6 0.5231643        0    3.12125        3rd"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/predictions.html","id":"prediction-type-or-scale","dir":"Articles","previous_headings":"","what":"Prediction type (or scale)","title":"Adjusted Predictions","text":"Using type argument predictions() function can specify “scale” make predictions. refers either scale used estimate model (.e., link scale) interpretable scale (e.g., response scale). example, fitting linear regression model using lm() function, link scale response scale identical. “Adjusted Prediction” computed either scale expressed mean value response variable given values predictor variables. hand, fitting binary logistic regression model using glm() function (uses binomial family logit link ), link scale response scale different: “Adjusted Prediction” computed link scale expressed log odds “successful” response given values predictor variables, whereas “Adjusted Prediction” computed response scale expressed probability response variable equals 1. default value type argument models “response”, means predictions() function compute predicted probabilities (binomial family), Poisson means (poisson family), etc.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/predictions.html","id":"prediction-grid","dir":"Articles","previous_headings":"","what":"Prediction grid","title":"Adjusted Predictions","text":"compute adjusted predictions must first specify values predictors consider: “reference grid.” example, model linear model fitted lm() function relates response variable Happiness predictor variables Age, Gender Income, reference grid data.frame values Age, Gender Income: Age = 40, Gender = Male, Income = 60000. “reference grid” may may correspond actual observations dataset used fit model; example values given match mean values variable, represent specific observed (hypothetical) individual. reference grid can include many different rows want make predictions different combinations predictors. default, predictions() function uses full original dataset reference grid, means compute adjusted predictions individuals observed dataset used fit model.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/predictions.html","id":"the-predictions-function","dir":"Articles","previous_headings":"","what":"The predictions() function","title":"Adjusted Predictions","text":"default, predictions calculates regression-adjusted predicted values every observation original dataset: many cases, limiting, researchers want specify grid “typical” values compute adjusted predictions.","code":"library(marginaleffects)  mod <- lm(mpg ~ hp + factor(cyl), data = mtcars)  pred <- predictions(mod)  head(pred) #>   rowid     type predicted std.error statistic       p.value conf.low conf.high #> 1     1 response  20.03819 1.2041405  16.64107  3.512623e-62 17.57162  22.50476 #> 2     2 response  20.03819 1.2041405  16.64107  3.512623e-62 17.57162  22.50476 #> 3     3 response  26.41451 0.9619738  27.45866 5.476301e-166 24.44399  28.38502 #> 4     4 response  20.03819 1.2041405  16.64107  3.512623e-62 17.57162  22.50476 #> 5     5 response  15.92247 0.9924560  16.04350  6.347069e-58 13.88952  17.95543 #> 6     6 response  20.15839 1.2186288  16.54186  1.832792e-61 17.66214  22.65463 #>    mpg  hp cyl #> 1 21.0 110   6 #> 2 21.0 110   6 #> 3 22.8  93   4 #> 4 21.4 110   6 #> 5 18.7 175   8 #> 6 18.1 105   6"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/predictions.html","id":"adjusted-predictions-at-user-specified-values-aka-adjusted-predictions-at-representative-values-apr","dir":"Articles","previous_headings":"","what":"Adjusted Predictions at User-Specified values (aka Adjusted Predictions at Representative values, APR)","title":"Adjusted Predictions","text":"two main ways select reference grid want compute adjusted predictions. first using variables argument. second newdata argument datagrid() function already introduced marginal effects vignette.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/predictions.html","id":"variables-counterfactual-predictions","dir":"Articles","previous_headings":"Adjusted Predictions at User-Specified values (aka Adjusted Predictions at Representative values, APR)","what":"variables: Counterfactual predictions","title":"Adjusted Predictions","text":"variables argument handy way create make predictions counterfactual datasets. example, dataset used fit model 32 rows. counterfactual dataset two distinct values hp 64 rows: original rows appears twice, , values specified variables argument:","code":"p <- predictions(mod, variables = list(hp = c(100, 120))) head(p) #>   rowid rowidcf     type predicted std.error statistic       p.value conf.low #> 1     1       1 response  20.27858 1.2377512 16.383405  2.512745e-60 17.74316 #> 2     2       2 response  20.27858 1.2377512 16.383405  2.512745e-60 17.74316 #> 3     3       3 response  26.24623 0.9856325 26.628826 3.148430e-156 24.22726 #> 4     4       4 response  20.27858 1.2377512 16.383405  2.512745e-60 17.74316 #> 5     5       5 response  17.72538 1.8811567  9.422599  4.400597e-21 13.87201 #> 6     6       6 response  20.27858 1.2377512 16.383405  2.512745e-60 17.74316 #>   conf.high  mpg cyl  hp #> 1  22.81400 21.0   6 100 #> 2  22.81400 21.0   6 100 #> 3  28.26521 22.8   4 100 #> 4  22.81400 21.4   6 100 #> 5  21.57876 18.7   8 100 #> 6  22.81400 18.1   6 100 nrow(p) #> [1] 64"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/predictions.html","id":"newdata-and-datagrid","dir":"Articles","previous_headings":"Adjusted Predictions at User-Specified values (aka Adjusted Predictions at Representative values, APR)","what":"newdata and datagrid","title":"Adjusted Predictions","text":"second strategy construct grids predictors adjusted predictions combine newdata argument datagrid function. Recall function creates “typical” dataset variables means modes, except explicitly define: can also use datagrid function predictions call (omitting model argument): Users can change summary function used summarize type variables using FUN_numeric, FUN_factor, related arguments. example: data.frame produced predictions “tidy”, makes easy manipulate R packages functions: table Adjusted Predictions","code":"datagrid(cyl = c(4, 6, 8), model = mod) #>        mpg       hp cyl #> 1 20.09062 146.6875   4 #> 2 20.09062 146.6875   6 #> 3 20.09062 146.6875   8 predictions(mod, newdata = datagrid()) #>   rowid     type predicted std.error statistic      p.value conf.low conf.high #> 1     1 response  16.60307  1.278754  12.98379 1.512165e-38 13.98366  19.22248 #>        mpg       hp cyl #> 1 20.09062 146.6875   8  predictions(mod, newdata = datagrid(cyl = c(4, 6, 8))) #>   rowid     type predicted std.error statistic      p.value conf.low conf.high #> 1     1 response  25.12392  1.368888  18.35353 3.093502e-75 22.31988  27.92796 #> 2     2 response  19.15627  1.247190  15.35955 3.057119e-53 16.60151  21.71102 #> 3     3 response  16.60307  1.278754  12.98379 1.512165e-38 13.98366  19.22248 #>        mpg       hp cyl #> 1 20.09062 146.6875   4 #> 2 20.09062 146.6875   6 #> 3 20.09062 146.6875   8 m <- lm(mpg ~ hp + drat + factor(cyl) + factor(am), data = mtcars) predictions(m, newdata = datagrid(FUN_factor = unique, FUN_numeric = median)) #>   rowid     type predicted std.error statistic      p.value conf.low conf.high #> 1     1 response  21.95333  1.288065  17.04365 3.896507e-65 19.30567  24.60099 #> 2     2 response  18.18910  1.270927  14.31168 1.849819e-46 15.57667  20.80153 #> 3     3 response  25.54890  1.322154  19.32369 3.395189e-83 22.83117  28.26663 #> 4     4 response  21.78467  1.541301  14.13395 2.346178e-45 18.61648  24.95286 #> 5     5 response  22.61705  2.140950  10.56403 4.374878e-26 18.21627  27.01784 #> 6     6 response  18.85282  1.734026  10.87228 1.562441e-27 15.28848  22.41716 #>    mpg  hp  drat cyl am #> 1 19.2 123 3.695   6  1 #> 2 19.2 123 3.695   6  0 #> 3 19.2 123 3.695   4  1 #> 4 19.2 123 3.695   4  0 #> 5 19.2 123 3.695   8  1 #> 6 19.2 123 3.695   8  0 library(kableExtra) library(tidyverse)  predictions(     mod,     newdata = datagrid(cyl = mtcars$cyl, hp = c(100, 110))) %>%     select(hp, cyl, predicted) %>%     pivot_wider(values_from = predicted, names_from = cyl) %>%     kbl(caption = \"A table of Adjusted Predictions\") %>%     kable_styling() %>%     add_header_above(header = c(\" \" = 1, \"cyl\" = 3))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/predictions.html","id":"counterfactual-data-grid","dir":"Articles","previous_headings":"Adjusted Predictions at User-Specified values (aka Adjusted Predictions at Representative values, APR)","what":"counterfactual data grid","title":"Adjusted Predictions","text":"alternative approach construct grids predictors use grid_type = \"counterfactual\" argument value. duplicate whole dataset, different values specified user. example, mtcars dataset 32 rows. command produces new dataset 64 rows, row original dataset duplicated two values variable supplied (0 1): , can use dataset predictions function create interesting visualizations:  graph, dot represents predicted probability vs=1 one observation dataset, counterfactual worlds either 0 1.","code":"mod <- glm(vs ~ hp + am, data = mtcars, family = binomial)  nd <- datagrid(model = mod, am = 0:1, grid_type = \"counterfactual\")  dim(nd) #> [1] 64  4 pred <- predictions(mod, newdata = datagrid(am = 0:1, grid_type = \"counterfactual\")) %>%     select(am, predicted, rowidcf) %>%     pivot_wider(id_cols = rowidcf,                  names_from = am,                 values_from = predicted)  ggplot(pred, aes(x = `0`, y = `1`)) +     geom_point() +     geom_abline(intercept = 0, slope = 1) +     labs(x = \"Predicted Pr(vs=1), when am = 0\",          y = \"Predicted Pr(vs=1), when am = 1\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/predictions.html","id":"adjusted-prediction-at-the-mean-apm","dir":"Articles","previous_headings":"","what":"Adjusted Prediction at the Mean (APM)","title":"Adjusted Predictions","text":"analysts may want calculate “Adjusted Prediction Mean,” , predicted outcome regressors held mean (mode). achieve , use datagrid function. default, function produces grid data regressors means modes, need get APM : equivalent calling:","code":"predictions(mod, newdata = \"mean\") #>   rowid     type  predicted  std.error statistic   p.value    conf.low #> 1     1 response 0.06308965 0.08662801 0.7282823 0.4664408 0.003794253 #>   conf.high     vs       hp      am #> 1  0.543491 0.4375 146.6875 0.40625 predictions(mod, newdata = datagrid()) #>   rowid     type  predicted  std.error statistic   p.value    conf.low #> 1     1 response 0.06308965 0.08662801 0.7282823 0.4664408 0.003794253 #>   conf.high     vs       hp      am #> 1  0.543491 0.4375 146.6875 0.40625"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/predictions.html","id":"average-adjusted-predictions-aap","dir":"Articles","previous_headings":"","what":"Average Adjusted Predictions (AAP)","title":"Adjusted Predictions","text":"“Average Adjusted Prediction” outcome two step process: Create new dataset original regressor values, fixing regressors values interest. Take average predicted values new dataset. can obtain AAPs applying tidy() summary() functions object produced predictions() function: equivalent :","code":"pred <- predictions(mod) summary(pred) #>   Predicted Std. Error z value   Pr(>|z|) CI low CI high #> 1    0.4375    0.04288    10.2 < 2.22e-16 0.3535  0.5215 #>  #> Model type:  glm  #> Prediction type:  response mean(pred$predicted) #> [1] 0.4375"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/predictions.html","id":"average-adjusted-predictions-by-group","dir":"Articles","previous_headings":"","what":"Average Adjusted Predictions by Group","title":"Adjusted Predictions","text":"code section requires version 0.8.0 marginaleffects, development version Github. can compute average adjusted predictions different subsets data argument. next example, create “counterfactual” data grid observation dataset repeated twice, different values variable, variables held observed values. also show equivalent results using dplyr:","code":"predictions(mod, by = \"am\") |> summary() #>   am Predicted Std. Error z value   Pr(>|z|) CI low CI high #> 1  1    0.5385    0.08476   6.352 2.1193e-10 0.3723  0.7046 #> 2  0    0.3684    0.04303   8.562 < 2.22e-16 0.2841  0.4528 #>  #> Model type:  glm  #> Prediction type:  response p <- predictions(     mod,     by = \"am\",     newdata = datagridcf(am = 0:1)) summary(p) #>   am Predicted Std. Error z value   Pr(>|z|) CI low CI high #> 1  0    0.5261    0.03303   15.93 < 2.22e-16 0.4614  0.5909 #> 2  1    0.3302    0.06462    5.11 3.2272e-07 0.2035  0.4568 #>  #> Model type:  glm  #> Prediction type:  response  p %>% group_by(am) %>%       summarize(AAP = mean(predicted)) #> # A tibble: 2 × 2 #>      am   AAP #>   <int> <dbl> #> 1     0 0.526 #> 2     1 0.330"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/predictions.html","id":"multinomial-models","dir":"Articles","previous_headings":"Average Adjusted Predictions by Group","what":"Multinomial models","title":"Adjusted Predictions","text":"One place particularly useful multinomial models different response levels. example, compute average predicted outcome outcome level multinomial logit model. Note response levels identified “group” column. can use custom aggregations supplying data frame argument. columns data frame must present output predictions(), data frame must also include column labels. example, “collapse” response groups: can useful combination hypothesis argument. example, compute difference average adjusted predictions 3 4 response levels, compared 5 response level: can also use complicated aggregations. , compute predicted probability outcome levels value cyl, collapsing “3” “4” outcome levels: can compare different groups using hypothesis argument:","code":"library(nnet) nom <- multinom(factor(gear) ~ mpg + am * vs, data = mtcars, trace = FALSE)  # first 5 raw predictions predictions(nom, type = \"probs\") |> head() #>   rowid  type group    predicted    std.error    statistic    p.value #> 1     1 probs     3 3.623918e-05 2.002490e-03   0.01809706 0.98556142 #> 2     2 probs     3 3.623918e-05 2.002490e-03   0.01809706 0.98556142 #> 3     3 probs     3 9.347603e-08 6.911938e-06   0.01352385 0.98920986 #> 4     4 probs     3 4.044657e-01 1.965452e-01   2.05787667 0.03960197 #> 5     5 probs     3 9.999714e-01 1.246217e-03 802.40562752 0.00000000 #> 6     6 probs     3 5.183336e-01 2.898025e-01   1.78857550 0.07368321 #>        conf.low    conf.high gear  mpg am vs #> 1 -3.888569e-03 3.961047e-03    4 21.0  1  0 #> 2 -3.888569e-03 3.961047e-03    4 21.0  1  0 #> 3 -1.345367e-05 1.364063e-05    4 22.8  1  1 #> 4  1.924426e-02 7.896871e-01    3 21.4  0  1 #> 5  9.975289e-01 1.002414e+00    3 18.7  0  0 #> 6 -4.966881e-02 1.086336e+00    3 18.1  0  1  # average predictions predictions(nom, type = \"probs\", by = \"group\") |> summary() #>   Group Predicted Std. Error z value   Pr(>|z|)  CI low CI high #> 1     3    0.4688    0.04043  11.595 < 2.22e-16 0.38952  0.5480 #> 2     4    0.3750    0.06142   6.106 1.0231e-09 0.25462  0.4954 #> 3     5    0.1562    0.04624   3.379  0.0007279 0.06561  0.2469 #>  #> Model type:  multinom  #> Prediction type:  probs by <- data.frame(     group = c(\"3\", \"4\", \"5\"),     by = c(\"3,4\", \"3,4\", \"5\"))  predictions(nom, type = \"probs\", by = by) #>    type predicted  std.error statistic      p.value   conf.low conf.high  by #> 1 probs 0.4218766 0.02312133 18.246210 2.217708e-74 0.37655960 0.4671935 3,4 #> 2 probs 0.1562469 0.04624265  3.378848 7.279037e-04 0.06561294 0.2468808   5 predictions(nom, type = \"probs\", by = by, hypothesis = \"sequential\") |>     summary() #>      Term Predicted Std. Error z value  Pr(>|z|)  CI low CI high #> 1 5 - 3,4   -0.2656    0.06936   -3.83 0.0001284 -0.4016 -0.1297 #>  #> Model type:  multinom  #> Prediction type:  probs nom <- multinom(factor(gear) ~ mpg + factor(cyl), data = mtcars, trace = FALSE)  by <- expand.grid(     group = 3:5,     cyl = c(4, 6, 8),     stringsAsFactors = TRUE) |>     # define labels     transform(by = ifelse(         group %in% 3:4,         sprintf(\"3/4 Gears & %s Cylinders\", cyl),         sprintf(\"5 Gears & %s Cylinders\", cyl)))  predictions(nom, by = by) #>    type predicted  std.error statistic      p.value    conf.low conf.high #> 1 probs 0.4285648 0.06606515  6.487003 8.756078e-11  0.29907950 0.5580501 #> 2 probs 0.4092432 0.05797517  7.058938 1.677800e-12  0.29561390 0.5228724 #> 3 probs 0.4285364 0.04584405  9.347700 8.957431e-21  0.33868374 0.5183891 #> 4 probs 0.1428704 0.13213030  1.081284 2.795709e-01 -0.11610027 0.4018410 #> 5 probs 0.1815137 0.11595035  1.565443 1.174790e-01 -0.04574482 0.4087722 #> 6 probs 0.1429271 0.09168810  1.558841 1.190341e-01 -0.03677823 0.3226325 #>                        by #> 1 3/4 Gears & 6 Cylinders #> 2 3/4 Gears & 4 Cylinders #> 3 3/4 Gears & 8 Cylinders #> 4   5 Gears & 6 Cylinders #> 5   5 Gears & 4 Cylinders #> 6   5 Gears & 8 Cylinders predictions(nom, by = by, hypothesis = \"pairwise\") #>     type                                              term     predicted #> 1  probs 3/4 Gears & 6 Cylinders - 3/4 Gears & 4 Cylinders  1.932166e-02 #> 2  probs 3/4 Gears & 6 Cylinders - 3/4 Gears & 8 Cylinders  2.839251e-05 #> 3  probs   3/4 Gears & 6 Cylinders - 5 Gears & 6 Cylinders  2.856945e-01 #> 4  probs   3/4 Gears & 6 Cylinders - 5 Gears & 4 Cylinders  2.470511e-01 #> 5  probs   3/4 Gears & 6 Cylinders - 5 Gears & 8 Cylinders  2.856377e-01 #> 6  probs 3/4 Gears & 4 Cylinders - 3/4 Gears & 8 Cylinders -1.929327e-02 #> 7  probs   3/4 Gears & 4 Cylinders - 5 Gears & 6 Cylinders  2.663728e-01 #> 8  probs   3/4 Gears & 4 Cylinders - 5 Gears & 4 Cylinders  2.277295e-01 #> 9  probs   3/4 Gears & 4 Cylinders - 5 Gears & 8 Cylinders  2.663160e-01 #> 10 probs   3/4 Gears & 8 Cylinders - 5 Gears & 6 Cylinders  2.856661e-01 #> 11 probs   3/4 Gears & 8 Cylinders - 5 Gears & 4 Cylinders  2.470227e-01 #> 12 probs   3/4 Gears & 8 Cylinders - 5 Gears & 8 Cylinders  2.856093e-01 #> 13 probs     5 Gears & 6 Cylinders - 5 Gears & 4 Cylinders -3.864332e-02 #> 14 probs     5 Gears & 6 Cylinders - 5 Gears & 8 Cylinders -5.678502e-05 #> 15 probs     5 Gears & 4 Cylinders - 5 Gears & 8 Cylinders  3.858654e-02 #>     std.error     statistic    p.value     conf.low conf.high #> 1  0.08789439  0.2198281561 0.82600499 -0.152948169 0.1915915 #> 2  0.08041288  0.0003530841 0.99971828 -0.157577948 0.1576347 #> 3  0.19819546  1.4414783343 0.14944959 -0.102761500 0.6741504 #> 4  0.13345296  1.8512226242 0.06413753 -0.014511856 0.5086141 #> 5  0.11301068  2.5275281722 0.01148686  0.064140813 0.5071345 #> 6  0.07390977 -0.2610381284 0.79406310 -0.164153757 0.1255672 #> 7  0.14429187  1.8460693876 0.06488213 -0.016434064 0.5491797 #> 8  0.17392552  1.3093505208 0.19041564 -0.113158287 0.5686172 #> 9  0.10848095  2.4549565672 0.01409016  0.053697263 0.4789348 #> 10 0.13985777  2.0425469855 0.04109730  0.011549874 0.5597823 #> 11 0.12468539  1.9811682440 0.04757241  0.002643861 0.4914016 #> 12 0.13753215  2.0766728278 0.03783177  0.016051218 0.5551673 #> 13 0.17578877 -0.2198281561 0.82600499 -0.383182981 0.3058963 #> 14 0.16082575 -0.0003530841 0.99971828 -0.315269466 0.3151559 #> 15 0.14781954  0.2610381284 0.79406310 -0.251134441 0.3283075"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/predictions.html","id":"bayesian-models","dir":"Articles","previous_headings":"Average Adjusted Predictions by Group","what":"Bayesian models","title":"Adjusted Predictions","text":"strategy works bayesian models: results show median posterior distribution group-wise means. Note take mean predicted values MCMC draw computing quantiles. equivalent :","code":"library(brms) mod <- brm(am ~ mpg * vs, data = mtcars, family = bernoulli) predictions(mod, by = \"vs\") #>       type vs predicted  conf.low conf.high #> 1 response  0 0.3271836 0.1824479 0.5072074 #> 2 response  1 0.4993250 0.3657956 0.6721267 draws <- posterior_epred(mod) quantile(rowMeans(draws[, mtcars$vs == 0]), probs = c(.5, .025, .975)) #>       50%      2.5%     97.5%  #> 0.3271836 0.1824479 0.5072074 quantile(rowMeans(draws[, mtcars$vs == 1]), probs = c(.5, .025, .975)) #>       50%      2.5%     97.5%  #> 0.4993250 0.3657956 0.6721267"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/predictions.html","id":"conditional-adjusted-predictions-plot","dir":"Articles","previous_headings":"","what":"Conditional Adjusted Predictions (Plot)","title":"Adjusted Predictions","text":"First, download ggplot2movies dataset RDatasets archive. , create variable called certified_fresh movies rating least 8. Finally, discard outliers fit logistic regression model: can plot adjusted predictions, conditional length variable using plot_cap function:  can also introduce another condition display categorical variable like style different colors. can useful models interactions:  Since output plot_cap() ggplot2 object, easy customize. example, can add points actual observations dataset like :  can also use plot_cap() models multinomial outcomes grouped coefficients. example, notice call draw=FALSE, result includes group column: Now use group column:","code":"library(tidyverse) dat <- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/ggplot2movies/movies.csv\") %>%     mutate(style = case_when(Action == 1 ~ \"Action\",                              Comedy == 1 ~ \"Comedy\",                              Drama == 1 ~ \"Drama\",                              TRUE ~ \"Other\"),            style = factor(style),            certified_fresh = rating >= 8) %>%     dplyr::filter(length < 240)  mod <- glm(certified_fresh ~ length * style, data = dat, family = binomial) mod <- glm(certified_fresh ~ length, data = dat, family = binomial)  plot_cap(mod, condition = \"length\") mod <- glm(certified_fresh ~ length * style, data = dat, family = binomial)  plot_cap(mod, condition = c(\"length\", \"style\")) library(ggplot2) library(ggrepel)  mt <- mtcars mt$label <- row.names(mt)  mod <- lm(mpg ~ hp, data = mt)  plot_cap(mod, condition = \"hp\") +     geom_point(aes(x = hp, y = mpg), data = mt) +     geom_rug(aes(x = hp, y = mpg), data = mt) +     geom_text_repel(aes(x = hp, y = mpg, label = label),                     data = subset(mt, hp > 250),                     nudge_y = 2) +     theme_classic() library(MASS) library(ggplot2)  mod <- nnet::multinom(factor(gear) ~ mpg, data = mtcars, trace = FALSE)  p <- plot_cap(     mod,     type = \"probs\",     condition = \"mpg\",     draw = FALSE)  head(p) #>   rowid  type group predicted  std.error statistic       p.value  conf.low #> 1     1 probs     3 0.9714990 0.03871641 25.092693 5.976078e-139 0.8956163 #> 2     2 probs     3 0.9583559 0.04985914 19.221268  2.456932e-82 0.8606338 #> 3     3 probs     3 0.9393514 0.06291986 14.929330  2.123901e-50 0.8160307 #> 4     4 probs     3 0.9122105 0.07727155 11.805256  3.666725e-32 0.7607610 #> 5     5 probs     3 0.8741884 0.09157738  9.545900  1.349314e-21 0.6947001 #> 6     6 probs     3 0.8224163 0.10383644  7.920305  2.369279e-15 0.6189006 #>   conf.high gear condition1 #> 1  1.047382    3   10.40000 #> 2  1.056078    3   11.37917 #> 3  1.062672    3   12.35833 #> 4  1.063660    3   13.33750 #> 5  1.053677    3   14.31667 #> 6  1.025932    3   15.29583 plot_cap(     mod,     type = \"probs\",     condition = \"mpg\") +     facet_wrap(~group)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/predictions.html","id":"prediction-types","dir":"Articles","previous_headings":"","what":"Prediction types","title":"Adjusted Predictions","text":"predictions function computes model-adjusted means scale output predict(model) function. default, predict produces predictions \"response\" scale, adjusted predictions interpreted scale. However, users can pass string type argument, predictions consider different outcomes. Typical values include \"response\" \"link\", users refer documentation predict package used fit model know values allowable. documentation. can also plot predictions different outcome scales:","code":"mod <- glm(am ~ mpg, family = binomial, data = mtcars) pred <- predictions(mod, type = \"response\") head(pred) #>   rowid     type predicted  std.error statistic      p.value  conf.low #> 1     1 response 0.4610951 0.11584004  3.980447 6.878584e-05 0.2554723 #> 2     2 response 0.4610951 0.11584004  3.980447 6.878584e-05 0.2554723 #> 3     3 response 0.5978984 0.13239819  4.515911 6.304522e-06 0.3356711 #> 4     4 response 0.4917199 0.11961263  4.110936 3.940579e-05 0.2746560 #> 5     5 response 0.2969009 0.10051954  2.953663 3.140264e-03 0.1411369 #> 6     6 response 0.2599331 0.09782666  2.657078 7.882118e-03 0.1147580 #>   conf.high am  mpg #> 1 0.6808686  1 21.0 #> 2 0.6808686  1 21.0 #> 3 0.8139794  1 22.8 #> 4 0.7119512  0 21.4 #> 5 0.5204086  0 18.7 #> 6 0.4876032  0 18.1  pred <- predictions(mod, type = \"link\") head(pred) #>   rowid type   predicted std.error   statistic    p.value   conf.low #> 1     1 link -0.15593472 0.4661826 -0.33449281 0.73800772 -1.0696358 #> 2     2 link -0.15593472 0.4661826 -0.33449281 0.73800772 -1.0696358 #> 3     3 link  0.39671602 0.5507048  0.72037875 0.47129183 -0.6826455 #> 4     4 link -0.03312345 0.4785818 -0.06921168 0.94482113 -0.9711265 #> 5     5 link -0.86209956 0.4815290 -1.79033775 0.07339963 -1.8058791 #> 6     6 link -1.04631647 0.5085395 -2.05749308 0.03963882 -2.0430356 #>     conf.high am  mpg #> 1  0.75776637  1 21.0 #> 2  0.75776637  1 21.0 #> 3  1.47607755  1 22.8 #> 4  0.90487956  0 21.4 #> 5  0.08167995  0 18.7 #> 6 -0.04959739  0 18.1 plot_cap(mod, condition = \"mpg\", type = \"response\") plot_cap(mod, condition = \"mpg\", type = \"link\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/python.html","id":"fitting-a-numpyro-model","dir":"Articles","previous_headings":"","what":"Fitting a NumPyro model","title":"Python with `marginaleffects` and `reticulate`","text":"begin, load reticulate package allows us interact Python interpreter R session. , write NumPyro model load memory using source_python() function. important functions note Python code : load_df() downloads data pulmonary fibrosis. model() defines NumPyro model. fit_mcmc_model() fits model using Markov Chain Monte Carlo. predict_mcmc(): accepts data frame returns matrix draws posterior distribution adjusted predictions (fitted values).","code":"library(reticulate) library(marginaleffects)  model <- ' # Model code adapted from the NumPyro documtation under Apache License: # https://num.pyro.ai/en/latest/tutorials/bayesian_hierarchical_linear_regression.html  import pandas as pd import numpy as np import numpyro from numpyro.infer import SVI, Predictive, MCMC,NUTS, autoguide, TraceMeanField_ELBO import numpyro.distributions as dist from numpyro.infer.initialization import init_to_median, init_to_uniform,init_to_sample from jax import random from sklearn.preprocessing import LabelEncoder import pickle  def load_df():     train = pd.read_csv(\"https://raw.githubusercontent.com/vincentarelbundock/modelarchive/main/data-raw/osic_pulmonary_fibrosis.csv\")     return train   def model(data, predict = False):     FVC_obs = data[\"FVC\"].values  if predict == False else None     patient_encoder = LabelEncoder()     Age_obs = data[\"Age\"].values     patient_code = patient_encoder.fit_transform(data[\"Patient\"].values)     μ_α = numpyro.sample(\"μ_α\", dist.Normal(0.0, 500.0))     σ_α = numpyro.sample(\"σ_α\", dist.HalfNormal(100.0))      age = numpyro.sample(\"age\", dist.Normal(0.0, 500.0))      n_patients = len(np.unique(patient_code))      with numpyro.plate(\"plate_i\", n_patients):         α = numpyro.sample(\"α\", dist.Normal(μ_α, σ_α))      σ = numpyro.sample(\"σ\", dist.HalfNormal(100.0))     FVC_est = α[patient_code] + age * Age_obs      with numpyro.plate(\"data\", len(patient_code)):         numpyro.sample(\"obs\", dist.Normal(FVC_est, σ), obs=FVC_obs)   def fit_mcmc_model(train_df, samples = 1000):     numpyro.set_host_device_count(4)     rng_key = random.PRNGKey(0)     mcmc = MCMC(         NUTS(model),         num_samples=samples,         num_warmup=1000,         progress_bar=True,         num_chains = 4         )          mcmc.run(rng_key, train_df)      posterior_draws = mcmc.get_samples()      with open(\"mcmc_posterior_draws.pickle\", \"wb\") as handle:         pickle.dump(posterior_draws, handle, protocol=pickle.HIGHEST_PROTOCOL)  def predict_mcmc(data):      with open(\"mcmc_posterior_draws.pickle\", \"rb\") as handle:         posterior_draws = pickle.load(handle)      predictive = Predictive(model = model,posterior_samples=posterior_draws)     samples = predictive(random.PRNGKey(1), data, predict = True)     y_pred = samples[\"obs\"]     # transpose so that each column is a draw and each row is an observation     y_pred = np.transpose(np.array(y_pred))      return y_pred  '  # save python script to temp file tmp <- tempfile() cat(model, file = tmp)  # load functions source_python(tmp)  # download data df <- load_df()  # fit model fit_mcmc_model(df)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/python.html","id":"analyzing-the-results-in-marginaleffects","dir":"Articles","previous_headings":"","what":"Analyzing the results in marginaleffects","title":"Python with `marginaleffects` and `reticulate`","text":"functions marginaleffects package requires users supply model object function operate. estimating models outside R, model object. thus begin creating “fake” model object: empty data frame define class “custom”. , set global option tell marginaleffects “custom” class supported. Next, define get_predict method new custom class. method must accept three arguments: model, newdata, .... get_predict method must return data frame one row rows newdata, two columns (rowid predicted), attribute called posterior_draws hosts matrix posterior draws number rows newdata. method uses reticulate call predict_mcmc() function defined Python script . predict_mcmc() function accepts data frame returns matrix number rows. Now can use marginaleffects package functions analyze results. Since use “fake” model object, marginaleffects retrieve original data model object, always need supply newdata argument:","code":"mod <- data.frame() class(mod) <- \"custom\"  options(\"marginaleffects_model_classes\" = \"custom\") get_predict.custom <- function(model, newdata, ...) {     pred <- predict_mcmc(newdata)     out <- data.frame(         rowid = seq_len(nrow(newdata)),         predicted = apply(pred, 1, stats::median)     )     attr(out, \"posterior_draws\") <- pred     return(out) } # predictions on the original dataset predictions(mod, newdata = df) |> head() #>   rowid     type predicted conf.low conf.high                   Patient Weeks #> 1     1 response  2120.532 1763.176  2490.323 ID00007637202177411956430    -4 #> 2     2 response  2112.942 1740.647  2480.077 ID00007637202177411956430     5 #> 3     3 response  2116.086 1731.962  2480.866 ID00007637202177411956430     7 #> 4     4 response  2117.830 1740.041  2492.416 ID00007637202177411956430     9 #> 5     5 response  2114.272 1738.427  2490.165 ID00007637202177411956430    11 #> 6     6 response  2120.984 1741.109  2500.270 ID00007637202177411956430    17 #>    FVC  Percent Age  Sex SmokingStatus #> 1 2315 58.25365  79 Male     Ex-smoker #> 2 2214 55.71213  79 Male     Ex-smoker #> 3 2061 51.86210  79 Male     Ex-smoker #> 4 2144 53.95068  79 Male     Ex-smoker #> 5 2069 52.06341  79 Male     Ex-smoker #> 6 2101 52.86865  79 Male     Ex-smoker  # predictions for user-defined predictor values predictions(mod, newdata = datagrid(newdata = df, Age = c(60, 70))) #>   rowid     type predicted conf.low conf.high                   Patient #> 1     1 response  1798.592 1340.386  2318.963 ID00099637202206203080121 #> 2     2 response  1969.797 1583.616  2379.580 ID00099637202206203080121 #>      Weeks      FVC  Percent  Sex SmokingStatus Age #> 1 31.86185 2690.479 77.67265 Male     Ex-smoker  60 #> 2 31.86185 2690.479 77.67265 Male     Ex-smoker  70  predictions(mod, newdata = datagrid(newdata = df, Age = range)) #>   rowid     type predicted conf.low conf.high                   Patient #> 1     1 response  1605.094 1029.323  2301.611 ID00099637202206203080121 #> 2     2 response  2262.574 1860.123  2655.886 ID00099637202206203080121 #>      Weeks      FVC  Percent  Sex SmokingStatus Age #> 1 31.86185 2690.479 77.67265 Male     Ex-smoker  49 #> 2 31.86185 2690.479 77.67265 Male     Ex-smoker  88  # average predictions by group predictions(mod, newdata = df, by = \"Sex\") #>       type    Sex predicted conf.low conf.high #> 1 response Female  1883.243 1854.946  1910.619 #> 2 response   Male  2904.648 2890.626  2918.217  # contrasts (average) comparisons(mod, variables = \"Age\", newdata = df)  |>     summary() #>   Term Contrast Effect   2.5 % 97.5 % #> 1  Age       +1  18.01 -0.6857  33.59 #>  #> Model type:  custom  #> Prediction type:  response  comparisons(mod, variables = list(\"Age\" = \"sd\"), newdata = df)  |>     summary() #>   Term                Contrast Effect 2.5 % 97.5 % #> 1  Age (x + sd/2) - (x - sd/2)  127.1 -4.84  237.1 #>  #> Model type:  custom  #> Prediction type:  response  # slope (elasticity) marginaleffects(mod, variables = \"Age\", slope = \"eyex\", newdata = df) |>     summary() #>   Term Contrast Effect    2.5 % 97.5 % #> 1  Age    eY/eX 0.4997 -0.01924 0.9326 #>  #> Model type:  custom  #> Prediction type:  response"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/sandwich.html","id":"delta-method","dir":"Articles","previous_headings":"","what":"Delta Method","title":"Standard Errors and Confidence Intervals","text":"standard errors generated marginaleffects(), comparisons(), deltamethod() functions package package estimated using delta method. Mathematical treatments method can found statistics textbooks Wikipedia. Roughly speaking, delta method allows us approximate distribution smooth function asymptotically normal estimator. Concretely, allows us generate standard errors around functions model’s coefficient estimates. Predictions, contrasts, marginal effects, marginal means functions coefficients, can use delta method estimate standard errors around quantities. Since lot mathematical treatments available elsewhere, vignette focuses “implementation” marginaleffects. Consider case marginalmeans() function. user calls function, obtain vector marginal means. estimate standard errors around vector: Compute marginal means original model: \\(f(\\beta)\\) Increment first (first) coefficient held inside model object small amount, compute marginal means : \\(f(\\beta+\\varepsilon)\\) Calculate: \\(\\frac{f(\\beta+\\varepsilon) - f(\\beta)}{\\varepsilon}\\) Repeat step 1 every coefficient model construct \\(J\\) matrix. Extract variance-covariance matrix coefficient estimates: \\(V\\) Standard errors square root diagonal \\(JVJ'\\) main function used compute standard errors marginaleffects : https://github.com/vincentarelbundock/marginaleffects/blob/main/R/get_se_delta.R","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/sandwich.html","id":"standard-errors-and-intervals-for-marginaleffects-and-comparisons","dir":"Articles","previous_headings":"","what":"Standard errors and intervals for marginaleffects() and comparisons()","title":"Standard Errors and Confidence Intervals","text":"standard errors marginaleffects() comparisons() functions computed using delta method, described .","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/sandwich.html","id":"standard-error-of-the-average-marginal-effect-or-contrast","dir":"Articles","previous_headings":"Standard errors and intervals for marginaleffects() and comparisons()","what":"Standard Error of the Average Marginal Effect or Contrast","title":"Standard Errors and Confidence Intervals","text":"summary() tidy() functions compute average marginal effect (contrast) applied object produced marginaleffects() (comparisons()). done 3 steps: Extract Jacobian used compute unit-level standard errors. Take average Jacobian. Estimate standard error average marginal effect square root diagonal J’VJ, V variance-covariance matrix. explained succinctly Stack Exchange: want variance Average Marginal Effect (AME) hence transformed function : \\(AME = \\frac{1}{N} \\sum_{=1}^N g_i(x_i,\\hat{\\beta})\\) using delta method \\(Var \\left( g(\\hat{\\beta}) \\right) = J_g' \\Omega_{\\hat{\\beta}} J_g\\) \\(\\Omega_{\\hat{\\beta}} = Var(\\hat{\\beta})\\) \\(J_g' = \\frac{\\partial\\left[\\frac{1}{N}\\sum_{=1}^N g (x_i,\\hat{\\beta})\\right]}{\\partial \\hat\\beta} = \\frac{1}{N}{\\left[\\sum_{=1}^N \\frac{\\partial \\left (g (x_i,\\hat{\\beta})\\right)}{\\partial \\hat\\beta}\\right]}\\) justifies using “average Jacobian” delta method calculate variance AME. References: Dowd, Bryan E, William H Greene, Edward C Norton. “Computation Standard Errors.” Health Services Research 49, . 2 (April 2014): 731–50. https://doi.org/10.1111/1475-6773.12122. https://stats.stackexchange.com/questions/283831/delta-method--marginal-effects--generalized-linear-model?rq=1","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/sandwich.html","id":"standard-errors-and-intervals-for-marginalmeans","dir":"Articles","previous_headings":"","what":"Standard errors and intervals for marginalmeans()","title":"Standard Errors and Confidence Intervals","text":"marginalmeans() function can compute confidence intervals two ways. following conditions hold: user set: type = \"response\" “link” type supported model class transform_post argument NULL marginalmeans() first compute marginal means link scale, back transform using inverse link function supplied insight::link_inverse(model) function. cases, standard errors computed using delta method described .","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/sandwich.html","id":"standard-errors-and-intervals-for-predictions","dir":"Articles","previous_headings":"","what":"Standard errors and intervals for predictions()","title":"Standard Errors and Confidence Intervals","text":"marginaleffects package handles calculations compute standard errors, t statistics, p values, confidence intervals contrasts (comparisons()), marginal effects (marginaleffects()), marginal means (marginalmeans()) functions. possible, however, calculation standard errors confidence intervals output predictions() outsourced insight package. benefit , many popular models, insight can compute confidence intervals via back-transformation, gives certain nice properties. example, ensures confidence intervals around predictions logistic regression model remain 0 1. insight support model, marginaleffects computes standard errors using delta method, described . cases, confidence intervals created automatically, users can easily compute manually, usual, multiplying standard error critical value. standard errors thus estimated desirable properties normal assumptions, since back-transformation, always advisable use construct symmetric confidence intervals around adjusted predictions. One special case use tidy() summary() functions compute average predictions, argument compute average predictions group. cases, may good idea compute predicted values link scale, average predictions, back transform. can done using transform_post transform_avg arguments. example, use link_inverse argument insight package get inverse link function: Note simply add 1.96*SE predictions, upper bound confidence interval exceed logical limit 1. Instead, one possibility estimate predicted values link scale, transform results: can something similar average predictions using tidy() summary() functions: Warning: users aware alternative approaches general yield results, mean transformation always equal transformation mean:","code":"library(insight) library(marginaleffects)  # simulate data set.seed(1024) N <- 25 dat <- data.frame(     y = rbinom(N, 1, prob = .9),     x = rnorm(N),     groupid = rbinom(N, 1, prob = .5))  # estimate model mod <- glm(y ~ x + groupid, family = binomial, data = dat)  # average group-wise predictions predictions(mod, by = \"groupid\") #>       type groupid predicted  std.error statistic      p.value  conf.low #> 1 response       1 0.8888889 0.10282561  8.644626 5.398200e-18 0.6873544 #> 2 response       0 0.8750000 0.07697122 11.367885 6.043421e-30 0.7241392 #>   conf.high #> 1  1.090423 #> 2  1.025861 predictions(     mod,     by = \"groupid\",     type = \"link\",     transform_post = link_inverse(mod)) #>   type groupid predicted    p.value  conf.low conf.high #> 1 link       1 0.9135928 0.03809366 0.5323305 0.9899205 #> 2 link       0 0.9229036 0.02478264 0.5780974 0.9905287 p <- predictions(     mod,     type = \"link\") summary(p, transform_avg = link_inverse(mod)) #>   Predicted  Pr(>|z|) CI low CI high #> 1    0.9197 0.0061301  0.667  0.9849 #>  #> Model type:  glm  #> Prediction type:  link  #> Average-transformation:  link_inverse(mod) x <- rnorm(100) mean(link_inverse(mod)(x)) #> [1] 0.4706487 link_inverse(mod)(mean(x)) #> [1] 0.4665151"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/sandwich.html","id":"bootstrap","dir":"Articles","previous_headings":"","what":"Bootstrap","title":"Standard Errors and Confidence Intervals","text":"easy use bootstrap alternative strategy compute standard errors confidence intervals. Several R packages can help us achieve , including long-established boot package: Note , code , set vcov=FALSE avoid computation delta method standard errors speed things . Compare delta method standard errors:","code":"library(boot) set.seed(123)  bootfun <- function(data, indices, ...) {     d <- data[indices, ]     mod <- lm(mpg ~ am + hp + factor(cyl), data = d)     cmp <- comparisons(mod, newdata = d, vcov = FALSE, variables = \"am\")     tidy(cmp)$estimate }  b <- boot(data = mtcars, statistic = bootfun, R = 1000)  b #>  #> ORDINARY NONPARAMETRIC BOOTSTRAP #>  #>  #> Call: #> boot(data = mtcars, statistic = bootfun, R = 1000) #>  #>  #> Bootstrap Statistics : #>     original     bias    std. error #> t1* 4.157856 0.01543426    1.003461 boot.ci(b, type = \"perc\") #> BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS #> Based on 1000 bootstrap replicates #>  #> CALL :  #> boot.ci(boot.out = b, type = \"perc\") #>  #> Intervals :  #> Level     Percentile      #> 95%   ( 2.240,  6.277 )   #> Calculations and Intervals on Original Scale mod <- lm(mpg ~ am + hp + factor(cyl), data = mtcars) comparisons(mod, variables = \"am\") |> summary() #>   Term Contrast Effect Std. Error z value   Pr(>|z|) 2.5 % 97.5 % #> 1   am    1 - 0  4.158      1.257   3.309 0.00093648 1.695  6.621 #>  #> Model type:  lm  #> Prediction type:  response"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/sandwich.html","id":"robust-standard-errors","dir":"Articles","previous_headings":"","what":"Robust standard errors","title":"Standard Errors and Confidence Intervals","text":"functions marginaleffects package can compute robust standard errors fly model type supported sandwich package. vcov argument supports string shortcuts like \"HC3\", one-sided formula request clustered standard errors, variance-covariance matrices, functions return matrices. examples. Adjusted predictions classical heteroskedasticity-robust standard errors: Marginal effects cluster-robust standard errors: Comparing adjusted predictions classical robust standard errors:","code":"library(marginaleffects) library(patchwork) mod <- lm(mpg ~ hp, data = mtcars)  p <- predictions(mod) head(p, 2) #>   rowid     type predicted std.error statistic       p.value conf.low conf.high #> 1     1 response  22.59375 0.7772744  29.06792 9.135725e-186 21.00634  24.18116 #> 2     2 response  22.59375 0.7772744  29.06792 9.135725e-186 21.00634  24.18116 #>   mpg  hp #> 1  21 110 #> 2  21 110  p <- predictions(mod, vcov = \"HC3\") head(p, 2) #>   rowid     type predicted std.error statistic       p.value conf.low conf.high #> 1     1 response  22.59375 0.8629746  26.18125 4.345995e-151 20.83132  24.35618 #> 2     2 response  22.59375 0.8629746  26.18125 4.345995e-151 20.83132  24.35618 #>   mpg  hp #> 1  21 110 #> 2  21 110 mfx <- marginaleffects(mod, vcov = ~cyl) summary(mfx) #>   Term   Effect Std. Error z value   Pr(>|z|)   2.5 %   97.5 % #> 1   hp -0.06823    0.01868  -3.653 0.00025909 -0.1048 -0.03162 #>  #> Model type:  lm  #> Prediction type:  response p1 <- plot_cap(mod, condition = \"hp\") p2 <- plot_cap(mod, condition = \"hp\", vcov = \"HC3\") p1 + p2"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/sandwich.html","id":"mixed-effects-models-satterthwaite-and-kenward-roger-corrections","dir":"Articles","previous_headings":"","what":"Mixed effects models: Satterthwaite and Kenward-Roger corrections","title":"Standard Errors and Confidence Intervals","text":"linear mixed effects models can apply Satterthwaite Kenward-Roger corrections way : Marginal effects mean classical standard errors z-statistic: Marginal effects mean Kenward-Roger adjusted variance-covariance degrees freedom: can use option package’s core functions, including:","code":"library(marginaleffects) library(patchwork) library(lme4)  dat <- mtcars dat$cyl <- factor(dat$cyl) dat$am <- as.logical(dat$am) mod <- lmer(mpg ~ hp + am + (1 | cyl), data = dat) marginaleffects(mod, newdata = \"mean\") #>   rowid     type term     contrast        dydx  std.error statistic #> 1     1 response   hp        dY/dX -0.05184187 0.01146238 -4.522784 #> 2     1 response   am TRUE - FALSE  4.66614142 1.13425639  4.113833 #>        p.value    conf.low   conf.high predicted predicted_hi predicted_lo #> 1 6.103158e-06 -0.07430773 -0.02937602   17.7327     17.73123      17.7327 #> 2 3.891429e-05  2.44303975  6.88924310   17.7327     22.39884      17.7327 #>        mpg       hp    am cyl    eps #> 1 20.09062 146.6875 FALSE   8 0.0283 #> 2 20.09062 146.6875 FALSE   8     NA marginaleffects(mod,                 newdata = \"mean\",                 vcov = \"kenward-roger\") #>   rowid     type term     contrast        dydx  std.error statistic    p.value #> 1     1 response   hp        dY/dX -0.05184187 0.01518879 -3.413167 0.09642979 #> 2     1 response   am TRUE - FALSE  4.66614142 1.28244270  3.638479 0.08741990 #>     conf.low   conf.high       df predicted predicted_hi predicted_lo      mpg #> 1 -0.1305545  0.02687074 1.682575   17.7327     17.73123      17.7327 20.09062 #> 2 -1.9798401 11.31212296 1.682575   17.7327     22.39884      17.7327 20.09062 #>         hp    am cyl    eps #> 1 146.6875 FALSE   8 0.0283 #> 2 146.6875 FALSE   8     NA plot_cap(mod, condition = \"hp\", vcov = \"satterthwaite\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/sandwich.html","id":"bayesian-estimates-and-credible-intervals","dir":"Articles","previous_headings":"","what":"Bayesian estimates and credible intervals","title":"Standard Errors and Confidence Intervals","text":"See brms vignette discussion bayesian estimates credible intervals.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/supported_models.html","id":"adjusted-predictions-and-marginal-means","dir":"Articles","previous_headings":"","what":"Adjusted predictions and marginal means","title":"Supported Models","text":"hood, marginaleffects’s predictions marginalmeans functions use insight package retrieve adjusted predictions wide variety models. Currently, insight supports many model types, work ---box predictions function. run problems, hesitate report Github via email.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/supported_models.html","id":"marginal-effects-and-contrasts","dir":"Articles","previous_headings":"","what":"Marginal effects and contrasts","title":"Supported Models","text":"table shows list 71 model types marginaleffects() function can compute slopes contrasts. three main alternative software packages compute slopes (1) Stata’s margins command, (2) R’s margins::margins function, (3) R’s emmeans::emtrends function. test suite hosted Github compares numerical equivalence results produced marginaleffects produced 3 alternative software packages: ✓: green check means results least one model equal reasonable tolerance. ✖: red cross means results identical; extra caution warranted. U: grey U means computing slopes model type unsupported alternative packages, supported marginaleffects. empty cell means means comparison made yet. eager add support new models. Feel free file request submit code Github.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/transformation.html","id":"transformations","dir":"Articles","previous_headings":"","what":"Transformations","title":"Transformations and Custom Contrasts","text":"vignette shows move beyond simple differences, estimating “contrasts” consist ratios arbitrary functions adjusted predictions. also shows back-transform contrasts change scales. Powerful transformations custom contrasts made possible using three arguments act different stages computation process: transform_pre transform_post transform_avg Consider case model single predictor \\(x\\). compute average contrasts, proceed follows: Compute adjusted predictions row dataset observed values \\(x\\): \\(\\hat{y}_x\\) Compute adjusted predictions row dataset observed values \\(x + 1\\): \\(\\hat{y}_{x+1}\\) transform_pre: Compute unit-level contrasts taking difference (function ) adjusted predictions: \\(\\hat{y}_{x+1} - \\hat{y}_x\\) transform_post: Transform unit-level contrasts return -. Compute average contrast taking mean unit-level contrasts: \\(1/N \\sum_{=1}^N \\hat{y}_{x+1} - \\hat{y}_x\\) transform_avg: Transform average contrast return -. transform_pre argument comparisons() function determines adjusted predictions combined create contrast. default, take simple difference predictions hi value \\(x\\), predictions lo value \\(x\\): function(hi, lo) hi-lo. transform_post argument comparisons() function applies custom transformation unit-level contrasts. transform_avg argument available tidy() summary() functions. applies custom transformation average contrast. difference transform_post transform_avg former applied take average, latter applied average. seems like subtle distinction, can important practical implications, since function average rarely average function: vignette shows modify steps 3, 4, 6 compute custom contrasts back transformations: Adjusted Risk Ratios (ARR), Adjusted Risk Differences (ARD), Log-Normal Hurdle Models.","code":"set.seed(1024) x <- rnorm(100) exp(mean(x)) #> [1] 0.9806912 mean(exp(x)) #> [1] 1.587238"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/transformation.html","id":"differences","dir":"Articles","previous_headings":"","what":"Differences","title":"Transformations and Custom Contrasts","text":"default contrast calculate comparisons() function (untransformed) difference two adjusted predictions. instance, estimate effect change 1 unit, : can use comparisons() summary() functions obtain results:","code":"library(marginaleffects) library(magrittr)  mod <- glm(vs ~ mpg, data = mtcars, family = binomial)  # construct data  mtcars_minus <- mtcars_plus <- mtcars mtcars_minus$mpg <- mtcars_minus$mpg - 0.5 mtcars_plus$mpg <- mtcars_plus$mpg + 0.5  # adjusted predictions yhat_minus <- predict(mod, newdata = mtcars_minus, type = \"response\") yhat_plus <- predict(mod, newdata = mtcars_plus, type = \"response\")  # unit-level contrasts con <- yhat_plus - yhat_minus  # average contrasts mean(con) #> [1] 0.05540227 con <- comparisons(mod) summary(con) #>   Term Contrast Effect Std. Error z value   Pr(>|z|)   2.5 %  97.5 % #> 1  mpg       +1 0.0554   0.008327   6.653 2.8699e-11 0.03908 0.07172 #>  #> Model type:  glm  #> Prediction type:  response"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/transformation.html","id":"ratios","dir":"Articles","previous_headings":"","what":"Ratios","title":"Transformations and Custom Contrasts","text":"Instead taking simple differences adjusted predictions, can sometimes useful compute forms contrasts. example, adjrr function Stata software package can compute “adjusted risk ratios”, ratios adjusted predictions. R, use transform_pre argument: result average adjusted risk ratio, , adjusted predictions mpg incremented 1, divided adjusted predictions mpg original value. transform_pre accepts different values common types contrasts: ‘difference’, ‘ratio’, ‘lnratio’, ‘ratioavg’, ‘lnratioavg’, ‘lnoravg’, ‘differenceavg’. strings shortcuts functions accept two vectors adjusted predictions returns single vector contrasts. example, two commands yield identical results: mechanism powerful, lets users create fully customized contrasts. non-sensical example: arguments work plotting function plot_cco() well, allows us plot various custom contrasts. comparison Adjusted Risk Ratio Adjusted Risk Difference model probability survival aboard Titanic:","code":"comparisons(mod, transform_pre = \"ratio\") %>% summary() #>   Term Contrast Effect Std. Error z value   Pr(>|z|) 2.5 % 97.5 % #> 1  mpg       +1  1.287     0.1328   9.697 < 2.22e-16 1.027  1.548 #>  #> Model type:  glm  #> Prediction type:  response comparisons(mod, transform_pre = \"ratio\") %>% summary() #>   Term Contrast Effect Std. Error z value   Pr(>|z|) 2.5 % 97.5 % #> 1  mpg       +1  1.287     0.1328   9.697 < 2.22e-16 1.027  1.548 #>  #> Model type:  glm  #> Prediction type:  response  comparisons(mod, transform_pre = function(hi, lo) hi / lo) %>% summary() #>   Term Contrast Effect Std. Error z value   Pr(>|z|) 2.5 % 97.5 % #> 1  mpg       +1  1.287     0.1328   9.697 < 2.22e-16 1.027  1.548 #>  #> Model type:  glm  #> Prediction type:  response  #> Pre-transformation:  function(hi, lo) hi/lo comparisons(mod, transform_pre = function(hi, lo) sqrt(hi) / log(lo + 10)) %>% summary() #>   Term Contrast Effect Std. Error z value   Pr(>|z|)  2.5 % 97.5 % #> 1  mpg       +1 0.2641    0.02614    10.1 < 2.22e-16 0.2128 0.3153 #>  #> Model type:  glm  #> Prediction type:  response  #> Pre-transformation:  function(hi, lo) sqrt(hi)/log(lo + 10) library(ggplot2) library(patchwork) titanic <- \"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Titanic.csv\" titanic <- read.csv(titanic) mod_titanic <- glm(     Survived ~ Sex * PClass + Age + I(Age^2),     family = binomial,     data = titanic)  cmp <- comparisons(mod_titanic) summary(cmp) #>     Term      Contrast    Effect Std. Error z value   Pr(>|z|)     2.5 % #> 1    Sex male - female -0.484676   0.030607 -15.835 < 2.22e-16 -0.544665 #> 2 PClass     2nd - 1st -0.205782   0.039374  -5.226 1.7296e-07 -0.282954 #> 3 PClass     3rd - 1st -0.404283   0.039839 -10.148 < 2.22e-16 -0.482367 #> 4    Age            +1 -0.006504   0.001072  -6.069 1.2904e-09 -0.008605 #>      97.5 % #> 1 -0.424687 #> 2 -0.128609 #> 3 -0.326199 #> 4 -0.004403 #>  #> Model type:  glm  #> Prediction type:  response  p1 <- plot_cco(     mod_titanic,     effect = \"Age\",     condition = \"Age\",     transform_pre = \"ratio\") +     ylab(\"Adjusted Risk Ratio\\nP(Survival | Age + 1) / P(Survival | Age)\")  p2 <- plot_cco(     mod_titanic,     effect = \"Age\",     condition = \"Age\") +     ylab(\"Adjusted Risk Difference\\nP(Survival | Age + 1) - P(Survival | Age)\")  p1 + p2"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/transformation.html","id":"back-transform-ratios","dir":"Articles","previous_headings":"","what":"Back transform: Ratios","title":"Transformations and Custom Contrasts","text":"default, standard errors computed using delta method scale determined type argument (e.g., “link” “response”). analysts may prefer proceed differently. example, Stata, adjrr computes adjusted risk ratios (ARR) two steps: Compute natural log ratio mean adjusted predictions \\(x+1\\) mean adjusted predictions \\(x\\). Exponentiate estimate confidence interval bounds. Step 1 easy achieve transform_pre argument described . Step 2 can achieved transform_post argument: Note can use lnratioavg shortcut instead defining function . order operations previous command : Compute custom unit-level contrasts Exponentiate Take average using summary() function subtle difference procedure code: Since exp function now passed transform_avg argument summary() function, exponentiation now done unit-level contrasts averaged. Stata appears hood, results slightly different. arguments apply plotting functions marginaleffects package well. example can plot Adjusted Risk Ratio model quadratic term:","code":"comparisons(     mod,     transform_pre = function(hi, lo) log(mean(hi) / mean(lo)),     transform_post = exp) %>%     summary() #>   Term Contrast Effect   Pr(>|z|) 2.5 % 97.5 % #> 1  mpg       +1  1.135 2.3808e-10 1.091   1.18 #>  #> Model type:  glm  #> Prediction type:  response  #> Pre-transformation:  function(hi, lo) log(mean(hi)/mean(lo))  #> Post-transformation:  transform_post comparisons(     mod,     transform_pre = \"lnratioavg\") %>%     summary(transform_avg = exp) #>   Term Contrast Effect   Pr(>|z|) 2.5 % 97.5 % #> 1  mpg mean(+1)  1.135 2.3808e-10 1.091   1.18 #>  #> Model type:  glm  #> Prediction type:  response  #> Average-transformation:  exp library(ggplot2)  mod2 <- glm(vs ~ mpg + mpg^2, data = mtcars, family = binomial)  plot_cco(     mod2,     effect = list(\"mpg\" = 10),     condition = \"mpg\",     transformation_pre = \"ratio\") +     ylab(\"Adjusted Risk Ratio\\nP(vs = 1 | mpg + 10) / P(vs = 1 | mpg)\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/articles/transformation.html","id":"back-transform-lognormal-hurdle","dir":"Articles","previous_headings":"","what":"Back transform: lognormal hurdle","title":"Transformations and Custom Contrasts","text":"hurdle models, can fit two separate models simultaneously: model predicts outcome zero zero outcome zero, model predicts value outcome can calculate predictions marginal effects hurdle model processes, requires variable transformation since stages models use different link functions. hurdle_lognormal() family brms uses logistic regression (logit link) hurdle part model lognormal regression (outcome logged getting used model) non-hurdled part. Let’s look example predicting GDP per capita (distributed exponentially) using life expectancy. ’ll add artificial zeros can work hurdle stage model. two different sets coefficients two different processes. hurdle part (hu) uses logit link, non-hurdle part (mu) uses identity link. However, ’s slight misnomer—true identity link show coefficients non-logged dollar value scale. ’re using lognormal family, GDP per capita pre-logged, “original” identity scale actually logged dollars. can get predictions hu part model link (logit) scale: …response (percentage point) scale: can also get slopes hu part model link (logit) response (percentage point) scales: Working mu part model trickier. Switching type = \"link\" type = \"response\" doesn’t change anything, since outcome pre-logged: predictions, need exponentiate results scale back dollar amounts. can post-processing results (e.g. dplyr::mutate(predicted = exp(predicted))), can use transform_post argument predictions() pass results exp() getting calculated: can pass transform_post = exp plot_cap() :  marginal effects, need transform predictions calculating instantaneous slopes. also can’t use marginaleffects() function directly—need use comparisons() compute numerical derivative (.e. predict gdpPercap lifeExp 40 40.001 calculate slope predictions). can use transform_pre argument pass pair predicted values exp() calculating slopes: can visually confirm instantaneous slopes levels life expectancy:","code":"library(dplyr) library(ggplot2) library(patchwork) library(brms) library(marginaleffects) library(gapminder)  # Build some 0s into the GDP column set.seed(1234) gapminder <- gapminder::gapminder %>%    filter(continent != \"Oceania\") %>%    # Make a bunch of GDP values 0   mutate(prob_zero = ifelse(lifeExp < 50, 0.3, 0.02),          will_be_zero = rbinom(n(), 1, prob = prob_zero),          gdpPercap0 = ifelse(will_be_zero, 0, gdpPercap)) %>%    select(-prob_zero, -will_be_zero)  mod <- brm(   bf(gdpPercap0 ~ lifeExp,      hu ~ lifeExp),   data = gapminder,   family = hurdle_lognormal(),   chains = 4, cores = 4, seed = 1234) summary(mod) #>  Family: hurdle_lognormal  #>   Links: mu = identity; sigma = identity; hu = logit  #> Formula: gdpPercap0 ~ lifeExp  #>          hu ~ lifeExp #>    Data: gapminder (Number of observations: 1680)  #>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #>          total post-warmup draws = 4000 #>  #> Population-Level Effects:  #>              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS #> Intercept        3.47      0.09     3.29     3.65 1.00     4757     3378 #> hu_Intercept     3.16      0.40     2.37     3.96 1.00     2773     2679 #> lifeExp          0.08      0.00     0.08     0.08 1.00     5112     3202 #> hu_lifeExp      -0.10      0.01    -0.12    -0.08 1.00     2385     2652 #> ... predictions(mod, dpar = \"hu\", type = \"link\",             newdata = datagrid(lifeExp = seq(40, 80, 20))) #>   rowid type predicted  conf.low  conf.high gdpPercap0 lifeExp #> 1     1 link -0.817487 -1.033982 -0.6043308     6797.2      40 #> 2     2 link -2.805488 -3.062906 -2.5550801     6797.2      60 #> 3     3 link -4.790200 -5.337808 -4.2745563     6797.2      80 predictions(mod, dpar = \"hu\", type = \"response\",             newdata = datagrid(lifeExp = seq(40, 80, 20))) #>   rowid     type   predicted    conf.low  conf.high gdpPercap0 lifeExp #> 1     1 response 0.306297360 0.262312829 0.35335351     6797.2      40 #> 2     2 response 0.057028334 0.044663565 0.07208594     6797.2      60 #> 3     3 response 0.008242295 0.004783404 0.01372716     6797.2      80 marginaleffects(mod, dpar = \"hu\", type = \"link\",                 newdata = datagrid(lifeExp = seq(40, 80, 20))) #>   rowid type    term        dydx   conf.low   conf.high predicted predicted_hi #> 1     1 link lifeExp -0.09930925 -0.1157859 -0.08366088 -0.817487   -0.8180725 #> 2     2 link lifeExp -0.09930925 -0.1157859 -0.08366088 -2.805488   -2.8060666 #> 3     3 link lifeExp -0.09930925 -0.1157859 -0.08366088 -4.790200   -4.7908031 #>   predicted_lo gdpPercap0 lifeExp       eps #> 1    -0.817487     6797.2      40 0.0059004 #> 2    -2.805488     6797.2      60 0.0059004 #> 3    -4.790200     6797.2      80 0.0059004  marginaleffects(mod, dpar = \"hu\", type = \"response\",                 newdata = datagrid(lifeExp = seq(40, 80, 20))) #>   rowid     type    term          dydx     conf.low     conf.high   predicted #> 1     1 response lifeExp -0.0210776902 -0.025913450 -0.0165879119 0.306297360 #> 2     2 response lifeExp -0.0053208087 -0.006148655 -0.0045608559 0.057028334 #> 3     3 response lifeExp -0.0008118892 -0.001154388 -0.0005429417 0.008242295 #>   predicted_hi predicted_lo gdpPercap0 lifeExp       eps #> 1  0.306172973  0.306297360     6797.2      40 0.0059004 #> 2  0.056997229  0.057028334     6797.2      60 0.0059004 #> 3  0.008237367  0.008242295     6797.2      80 0.0059004 predictions(mod, dpar = \"mu\", type = \"link\",             newdata = datagrid(lifeExp = seq(40, 80, 20))) #>   rowid type predicted conf.low conf.high gdpPercap0 lifeExp #> 1     1 link  6.612435 6.542113  6.685787     6797.2      40 #> 2     2 link  8.183520 8.145944  8.220893     6797.2      60 #> 3     3 link  9.753512 9.687209  9.820665     6797.2      80 predictions(mod, dpar = \"mu\", type = \"response\",             newdata = datagrid(lifeExp = seq(40, 80, 20))) #>   rowid     type predicted conf.low conf.high gdpPercap0 lifeExp #> 1     1 response  6.612435 6.542113  6.685787     6797.2      40 #> 2     2 response  8.183520 8.145944  8.220893     6797.2      60 #> 3     3 response  9.753512 9.687209  9.820665     6797.2      80 predictions(mod, dpar = \"mu\",              newdata = datagrid(lifeExp = seq(40, 80, 20)),             transform_post = exp) #>   rowid     type  predicted   conf.low  conf.high gdpPercap0 lifeExp #> 1     1 response   744.2932   693.7513   800.9406     6797.2      40 #> 2     2 response  3581.4392  3449.3600  3717.8204     6797.2      60 #> 3     3 response 17214.5804 16110.2130 18410.2831     6797.2      80 plot_cap(   mod,   dpar = \"hu\",   type = \"link\",   condition = \"lifeExp\") +   labs(y = \"hu\",        title = \"Hurdle part (hu)\",        subtitle = \"Logit-scale predictions\") + plot_cap(   mod,   dpar = \"hu\",   type = \"response\",   condition = \"lifeExp\") +   labs(y = \"hu\",        subtitle = \"Percentage point-scale predictions\") + plot_cap(   mod,   dpar = \"mu\",   condition = \"lifeExp\") +   labs(y = \"mu\",        title = \"Non-hurdle part (mu)\",        subtitle = \"Log-scale predictions\") + plot_cap(   mod,   dpar = \"mu\",   transform_post = exp,   condition = \"lifeExp\") +   labs(y = \"mu\",        subtitle = \"Dollar-scale predictions\") # step size of the numerical derivative eps <- 0.001  comparisons(   mod,   dpar = \"mu\",   variables = list(lifeExp = eps),   newdata = datagrid(lifeExp = seq(40, 80, 20)),   # rescale the elements of the slope   # (exp(40.001) - exp(40)) / exp(0.001)   transform_pre = function(hi, lo) ((exp(hi) - exp(lo)) / exp(eps)) / eps ) #>   rowid     type    term contrast comparison   conf.low  conf.high predicted #> 1     1 response lifeExp   +0.001   58.39448   55.84743   61.02206  6.612435 #> 2     2 response lifeExp   +0.001  280.89410  266.57621  295.50894  8.183520 #> 3     3 response lifeExp   +0.001 1349.40503 1222.58608 1490.38119  9.753512 #>   predicted_hi predicted_lo gdpPercap0 lifeExp       eps #> 1     6.612474     6.612396     6797.2      40 0.0059004 #> 2     8.183559     8.183481     6797.2      60 0.0059004 #> 3     9.753551     9.753473     6797.2      80 0.0059004 predictions_data <- predictions(   mod,   newdata = datagrid(lifeExp = seq(30, 80, 1)),   dpar = \"mu\",   transform_post = exp )  slopes_data <- comparisons(   mod,   dpar = \"mu\",   variables = list(lifeExp = eps),   newdata = datagrid(lifeExp = seq(40, 80, 20)),   transform_pre = function(hi, lo) ((exp(hi) - exp(lo)) / exp(eps)) / eps ) %>%    select(lifeExp, comparison) %>%   left_join(predictions_data, by = \"lifeExp\") %>%   # Point-slope formula: (y - y1) = m(x - x1)   mutate(intercept = comparison * (-lifeExp) + predicted)  ggplot(predictions_data, aes(x = lifeExp, y = predicted)) +   geom_line(size = 1) +    geom_abline(data = slopes_data, aes(slope = comparison, intercept = intercept),                size = 0.5, color = \"red\") +   geom_point(data = slopes_data) +   geom_label(data = slopes_data, aes(label = paste0(\"Slope: \", round(comparison, 1))),              nudge_x = -1, hjust = 1) +   theme_minimal()"},{"path":"https://vincentarelbundock.github.io/marginaleffects/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Vincent Arel-Bundock. Author, maintainer, copyright holder. Marcio Augusto Diniz. Contributor. Noah Greifer. Contributor.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Arel-Bundock V (2022). marginaleffects: Marginal Effects, Marginal Means, Predictions, Contrasts. R package version 0.8.1.9004, https://vincentarelbundock.github.io/marginaleffects/.","code":"@Manual{,   title = {marginaleffects: Marginal Effects, Marginal Means, Predictions, and Contrasts},   author = {Vincent Arel-Bundock},   year = {2022},   note = {R package version 0.8.1.9004},   url = {https://vincentarelbundock.github.io/marginaleffects/}, }"},{"path":"https://vincentarelbundock.github.io/marginaleffects/index.html","id":"the-marginaleffects-package-for-r-","dir":"","previous_headings":"","what":"Marginal Effects, Marginal Means, Predictions, and Contrasts","title":"Marginal Effects, Marginal Means, Predictions, and Contrasts","text":"Compute plot adjusted predictions, contrasts, marginal effects, marginal means 71 classes statistical models R. Conduct linear non-linear hypothesis tests using delta method.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/index.html","id":"table-of-contents","dir":"","previous_headings":"","what":"Table of contents","title":"Marginal Effects, Marginal Means, Predictions, and Contrasts","text":"Introduction: Definitions Motivation Installation Getting started Vignettes: Adjusted Predictions Contrasts Marginal Effects Marginal Means Hypothesis Tests Custom Contrasts using Delta Method Case studies: Bayesian Analyses brms Causal Inference g-Formula Elasticity Experiments Generalized Additive Models Mixed effects models Multinomial Logit Discrete Choice Models Multiple Imputation Plots: interactions, predictions, contrasts, slopes Python NumPyro models marginaleffects Unit-level contrasts logistic regressions Tips technical notes: 71 Supported Classes Models Index Functions Documentation Extending marginaleffects: add new models modify existing ones Standard Errors Confidence Intervals Tables Plots Performance Alternative Software Frequently Asked Questions External links: Matching Noah Greifer Bayesian model averaging . Jordan Nafa Marginalia: guide figuring heck marginal effects, marginal slopes, average marginal effects, marginal effects mean, marginal things Andrew Heiss Double propensity score adjustment using g-computation Noah Greifer Subgroup Analysis Propensity Score Matching Using R Noah Greifer","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/index.html","id":"definitions","dir":"","previous_headings":"","what":"Definitions","title":"Marginal Effects, Marginal Means, Predictions, and Contrasts","text":"marginaleffects package allows R users compute plot four principal quantities interest 71 different classes models: outcome predicted fitted model specified scale given combination values predictor variables, observed values, means, factor levels (.k.. “reference grid”). predictions(), plot_cap() partial derivative (slope) regression equation respect regressor interest. marginaleffects(), plot(), plot_cme() difference, ratio, function adjusted predictions, calculated meaningfully different predictor values (e.g., College graduates vs. Others). comparisons(), plot_cco() Adjusted predictions model, averaged across “reference grid” categorical predictors. marginalmeans()","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/index.html","id":"what-does-marginal-mean","dir":"","previous_headings":"Definitions","what":"What does “marginal” mean?","title":"Marginal Effects, Marginal Means, Predictions, and Contrasts","text":"One confusing aspect definitions use word “marginal” two different opposite ways: “marginal effects,” refer effect tiny (marginal) change regressor outcome. slope, derivative. “marginal means,” refer process marginalizing across rows prediction grid. average, integral. Another potential confusion arises analysts use “marginal” distinguish estimates “conditional” ones. noted marginal effects contrasts vignettes, slopes contrasts often vary individual individual, based values regressors model. estimate slope contrast specific combination predictors – one (possibly representative) individual – people call “conditional” estimate. compute average several individual-level estimates, people call “marginal” estimate. website package, reserve expression “marginal effect” mean “slope” “derivative”. take average unit-level estimates, call “average marginal effect.” confusing, terminology widespread inconsistent must press …","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/index.html","id":"motivation","dir":"","previous_headings":"","what":"Motivation","title":"Marginal Effects, Marginal Means, Predictions, and Contrasts","text":"calculate marginal effects (slopes) need take derivatives regression equation. compute standard errors around slopes, predictions, contrasts, marginal means, need apply delta method. operations can challenging manually, especially models non-linear, regressors transformed interacted. Computing variance marginal effect even difficult. marginaleffects package hopes hard work . main packages R ecosystem compute marginal effects trailblazing powerful margins Thomas J. Leeper, emmeans Russell V. Lenth contributors. marginaleffects package essentially clone margins, additional features emmeans. write clone? Powerful: Marginal effects contrasts can computed 71 different classes models. Adjusted predictions marginal means can computed 100 model types. Customizable: Extremely flexible functions compute custom contrasts transformations. Extensible: Adding support new models easy, often requiring less 10 lines new code. Please submit feature requests Github. Fast: Computing unit-level standard errors can orders magnitude faster margins large datasets. Efficient: Much smaller memory footprint. Valid: possible, numerical results checked alternative software like Stata, R packages. Beautiful: ggplot2 support plotting (conditional) marginal effects adjusted predictions. Tidy: results produced marginaleffects follow “tidy” principles. easy program feed packages like modelsummary. Simple: functions share simple, unified, well-documented interface. Thin: package requires relatively dependencies. Safe: User input checked extensively computation. needed, functions fail gracefully informative error messages. Active development Downsides marginaleffects include: multiplicity adjustments. (Use p.adjust() instead.) Marginal means often slower compute emmeans. omnibus test","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Marginal Effects, Marginal Means, Predictions, and Contrasts","text":"can install released version marginaleffects CRAN: can install development version marginaleffects (dependency insight) R-Universe: Restart R completely moving .","code":"install.packages(\"marginaleffects\") install.packages(     c(\"marginaleffects\", \"insight\"),     repos = c(         \"https://vincentarelbundock.r-universe.dev\",         \"https://easystats.r-universe.dev\"))"},{"path":[]},{"path":"https://vincentarelbundock.github.io/marginaleffects/index.html","id":"adjusted-predictions","dir":"","previous_headings":"Getting started","what":"Adjusted predictions","title":"Marginal Effects, Marginal Means, Predictions, and Contrasts","text":"begin, estimate linear regression model multiplicative interactions: “adjusted prediction” outcome predicted model combination regressors’ values, observed values, means, factor levels (.k.. “reference grid”). default, predictions() function returns adjusted predictions every value original dataset: datagrid function gives us powerful way define grid predictors. variables mentioned explicitly datagrid() fixed mean mode: can plot predictions change different values one variables – Conditional Adjusted Predictions – using plot_cap function:   Adjusted Predictions vignette shows use predictions() plot_cap() functions compute wide variety quantities interest: Adjusted Predictions User-Specified Values (aka Predictions Representative Values) Adjusted Predictions Mean Average Predictions Mean Conditional Predictions Adjusted Predictions different scales (e.g., link response)","code":"library(marginaleffects)  mod <- lm(mpg ~ hp * wt * am, data = mtcars) predictions(mod) |> head() #>   rowid     type predicted std.error statistic #> 1     1 response  22.48857 0.8841487  25.43528 #> 2     2 response  20.80186 1.1942050  17.41900 #> 3     3 response  25.26465 0.7085307  35.65781 #> 4     4 response  20.25549 0.7044641  28.75305 #> 5     5 response  16.99782 0.7118658  23.87784 #> 6     6 response  19.66353 0.8753226  22.46433 #>         p.value conf.low conf.high  mpg  hp    wt #> 1 1.027254e-142 20.66378  24.31336 21.0 110 2.620 #> 2  5.920119e-68 18.33714  23.26658 21.0 110 2.875 #> 3 1.783452e-278 23.80232  26.72699 22.8  93 2.320 #> 4 8.296026e-182 18.80155  21.70943 21.4 110 3.215 #> 5 5.205109e-126 15.52860  18.46704 18.7 175 3.440 #> 6 9.270636e-112 17.85696  21.47011 18.1 105 3.460 #>   am #> 1  1 #> 2  1 #> 3  1 #> 4  0 #> 5  0 #> 6  0 predictions(mod, newdata = datagrid(am = 0, wt = seq(2, 3, .2))) #>   rowid     type predicted std.error statistic #> 1     1 response  21.95621 2.0386301  10.77008 #> 2     2 response  21.42097 1.7699036  12.10290 #> 3     3 response  20.88574 1.5067373  13.86157 #> 4     4 response  20.35051 1.2526403  16.24609 #> 5     5 response  19.81527 1.0144509  19.53301 #> 6     6 response  19.28004 0.8063905  23.90906 #>         p.value conf.low conf.high      mpg #> 1  4.765935e-27 17.74868  26.16373 20.09062 #> 2  1.019401e-33 17.76807  25.07388 20.09062 #> 3  1.082834e-43 17.77599  23.99549 20.09062 #> 4  2.380723e-59 17.76518  22.93583 20.09062 #> 5  5.755097e-85 17.72155  21.90900 20.09062 #> 6 2.465206e-126 17.61573  20.94435 20.09062 #>         hp am  wt #> 1 146.6875  0 2.0 #> 2 146.6875  0 2.2 #> 3 146.6875  0 2.4 #> 4 146.6875  0 2.6 #> 5 146.6875  0 2.8 #> 6 146.6875  0 3.0 plot_cap(mod, condition = c(\"hp\", \"wt\")) mod2 <- lm(mpg ~ factor(cyl), data = mtcars) plot_cap(mod2, condition = \"cyl\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/index.html","id":"contrasts","dir":"","previous_headings":"Getting started","what":"Contrasts","title":"Marginal Effects, Marginal Means, Predictions, and Contrasts","text":"contrast difference two adjusted predictions, calculated meaningfully different predictor values (e.g., College graduates vs. Others). happens predicted outcome numeric predictor increases one unit, logical variable flips FALSE TRUE, factor variable shifts baseline? contrast used simple difference adjusted predictions. can also used different functions combine contrast predictions different ways. instance, researchers often compute Adjusted Risk Ratios, ratios predicted probabilities. can compute ratios applying transformation using transform_pre argument. can also present results “interactions” contrasts. happens ratio predicted probabilities survival PClass changes pair factor levels (“pairwise”) Age changes 2 standard deviations simultaneously: code explained detail vignette Transformations Custom Contrasts. Contrasts vignette shows use comparisons() function compute wide variety quantities interest: Numeric variables (e.g., 1 standard deviation, interquartile range, custom values) Factor character Logical Contrast interactions Unit-level Contrasts Average Contrasts Group-Average Contrasts Contrasts Mean Contrasts Marginal Means Adjusted Risk Ratios","code":"titanic <- read.csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Titanic.csv\") titanic$Woman <- titanic$Sex == \"female\" mod3 <- glm(Survived ~ Woman + Age * PClass, data = titanic, family = binomial)  cmp <- comparisons(mod3) summary(cmp) #>     Term     Contrast   Effect Std. Error z value #> 1  Woman TRUE - FALSE  0.50329   0.031654  15.899 #> 2    Age           +1 -0.00558   0.001084  -5.147 #> 3 PClass    2nd - 1st -0.22603   0.043546  -5.191 #> 4 PClass    3rd - 1st -0.38397   0.041845  -9.176 #>     Pr(>|z|)     2.5 %    97.5 % #> 1 < 2.22e-16  0.441244  0.565327 #> 2 2.6471e-07 -0.007705 -0.003455 #> 3 2.0950e-07 -0.311383 -0.140686 #> 4 < 2.22e-16 -0.465985 -0.301957 #>  #> Model type:  glm  #> Prediction type:  response cmp <- comparisons(     mod3,     transform_pre = \"ratio\",     variables = list(Age = \"2sd\", PClass = \"pairwise\")) summary(cmp) #>     Term            Contrast Effect Std. Error #> 1    Age (x - sd) / (x + sd) 0.6225    0.09166 #> 2 PClass           2nd / 1st 0.5636    0.05497 #> 3 PClass           3rd / 1st 0.3351    0.03932 #> 4 PClass           3rd / 2nd 0.6155    0.14373 #>   z value   Pr(>|z|)  2.5 % 97.5 % #> 1   6.791 1.1126e-11 0.4428 0.8021 #> 2  10.253 < 2.22e-16 0.4559 0.6713 #> 3   8.523 < 2.22e-16 0.2580 0.4122 #> 4   4.282 1.8484e-05 0.3338 0.8972 #>  #> Model type:  glm  #> Prediction type:  response"},{"path":"https://vincentarelbundock.github.io/marginaleffects/index.html","id":"marginal-effects","dir":"","previous_headings":"Getting started","what":"Marginal effects","title":"Marginal Effects, Marginal Means, Predictions, and Contrasts","text":"“marginal effect” partial derivative (slope) regression equation respect regressor interest. unit-specific measure association change regressor change regressand. marginaleffects() function uses numerical derivatives estimate slope regression equation respect variables model (contrasts categorical variables). default, marginaleffects() estimates slope row original dataset used fit model: function summary calculates “Average Marginal Effect,” , average unit-specific marginal effects: plot_cme plots “Conditional Marginal Effects,” , marginal effects estimated different values regressor (often interaction):  Marginal Effects vignette shows use marginaleffects() function compute wide variety quantities interest: Unit-level Marginal Effects Average Marginal Effects Group-Average Marginal Effects Marginal Effects Mean Marginal Effects Marginal Means Conditional Marginal Effects Tables Plots","code":"mfx <- marginaleffects(mod)  head(mfx, 4) #>   rowid     type term        dydx  std.error #> 1     1 response   hp -0.03690556 0.01850172 #> 2     2 response   hp -0.02868936 0.01562861 #> 3     3 response   hp -0.04657166 0.02258715 #> 4     4 response   hp -0.04227128 0.01328278 #>   statistic     p.value    conf.low     conf.high #> 1 -1.994710 0.046074551 -0.07316825 -0.0006428553 #> 2 -1.835695 0.066402771 -0.05932087  0.0019421508 #> 3 -2.061866 0.039220507 -0.09084166 -0.0023016728 #> 4 -3.182412 0.001460541 -0.06830506 -0.0162375066 #>   predicted predicted_hi predicted_lo  mpg  hp #> 1  22.48857     22.48752     22.48857 21.0 110 #> 2  20.80186     20.80105     20.80186 21.0 110 #> 3  25.26465     25.26333     25.26465 22.8  93 #> 4  20.25549     20.25430     20.25549 21.4 110 #>      wt am    eps #> 1 2.620  1 0.0283 #> 2 2.875  1 0.0283 #> 3 2.320  1 0.0283 #> 4 3.215  0 0.0283 summary(mfx) #>   Term   Effect Std. Error  z value   Pr(>|z|) #> 1   hp -0.03807    0.01279 -2.97725 0.00290848 #> 2   wt -3.93909    1.08596 -3.62728 0.00028642 #> 3   am -0.04811    1.85260 -0.02597 0.97928234 #>      2.5 %   97.5 % #> 1 -0.06314 -0.01301 #> 2 -6.06754 -1.81065 #> 3 -3.67913  3.58292 #>  #> Model type:  lm  #> Prediction type:  response plot_cme(mod, effect = \"hp\", condition = c(\"wt\", \"am\"))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/index.html","id":"marginal-means","dir":"","previous_headings":"Getting started","what":"Marginal means","title":"Marginal Effects, Marginal Means, Predictions, and Contrasts","text":"Marginal Means adjusted predictions model, averaged across “reference grid” categorical predictors. compute marginal means, first need make sure categorical variables model coded dataset: , estimate model call marginalmeans function: Marginal Means vignette offers detail.","code":"dat <- mtcars dat$am <- as.logical(dat$am) dat$cyl <- as.factor(dat$cyl) mod <- lm(mpg ~ am + cyl + hp, data = dat) mm <- marginalmeans(mod) summary(mm) #>   Term Value  Mean Std. Error z value   Pr(>|z|) #> 1   am FALSE 18.32     0.7854   23.33 < 2.22e-16 #> 2   am  TRUE 22.48     0.8343   26.94 < 2.22e-16 #> 3  cyl     4 22.88     1.3566   16.87 < 2.22e-16 #> 4  cyl     6 18.96     1.0729   17.67 < 2.22e-16 #> 5  cyl     8 19.35     1.3771   14.05 < 2.22e-16 #>   2.5 % 97.5 % #> 1 16.78  19.86 #> 2 20.84  24.11 #> 3 20.23  25.54 #> 4 16.86  21.06 #> 5 16.65  22.05 #>  #> Model type:  lm  #> Prediction type:  response  #> Results averaged over levels of: am, cyl"},{"path":"https://vincentarelbundock.github.io/marginaleffects/index.html","id":"more","dir":"","previous_headings":"Getting started","what":"More","title":"Marginal Effects, Marginal Means, Predictions, and Contrasts","text":"much can marginaleffects. Return Table Contents read vignettes, learn report marginal effects means nice tables modelsummary package, define prediction “grid”, much .","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/cjdt.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross join a list of data tables — cjdt","title":"Cross join a list of data tables — cjdt","text":"Source: https://github.com/Rdatatable/data.table/issues/1717#issuecomment-545758165","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/cjdt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross join a list of data tables — cjdt","text":"","code":"cjdt(dtlist)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/comparisons.html","id":null,"dir":"Reference","previous_headings":"","what":"Contrasts Between Adjusted Predictions — comparisons","title":"Contrasts Between Adjusted Predictions — comparisons","text":"Difference, ratio, function adjusted predictions, calculated meaningfully different predictor values. tidy() summary() functions can used aggregate summarize output comparisons(). learn , read contrasts vignette, visit package website, scroll page full list vignettes: https://vincentarelbundock.github.io/marginaleffects/articles/contrasts.html https://vincentarelbundock.github.io/marginaleffects/","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/comparisons.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Contrasts Between Adjusted Predictions — comparisons","text":"","code":"comparisons(   model,   newdata = NULL,   variables = NULL,   type = NULL,   vcov = TRUE,   conf_level = 0.95,   transform_pre = \"difference\",   transform_post = NULL,   cross = FALSE,   by = NULL,   wts = NULL,   hypothesis = NULL,   eps = NULL,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/comparisons.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Contrasts Between Adjusted Predictions — comparisons","text":"model Model object newdata NULL, data frame, string, datagrid() call. Determines predictor values compute contrasts. NULL (default): Unit-level contrasts observed value original dataset. data frame: Unit-level contrasts row newdata data frame. string: \"mean\": Contrasts Mean. Contrasts predictor held mean mode. \"median\": Contrasts Median. Contrasts predictor held median mode. \"marginalmeans\": Contrasts Marginal Means. \"tukey\": Contrasts Tukey's 5 numbers. \"grid\": Contrasts grid representative numbers (Tukey's 5 numbers unique values categorical predictors). datagrid() call specify custom grid regressors. example: newdata = datagrid(cyl = c(4, 6)): cyl variable equal 4 6 regressors fixed means modes. newdata = datagrid(mpg = fivenum): mpg variable held Tukey's five numbers (using fivenum function), regressors fixed means modes. See Examples section datagrid documentation. variables NULL, character vector, named list. subset variables compute contrasts. NULL: compute contrasts variables model object (can slow). Character vector: subset variables (usually faster). Named list: names identify subset variables interest, values define type contrast compute. Acceptable values depend variable type: Factor character variables: \"reference\": factor level compared factor reference (base) level \"\": combinations observed levels \"sequential\": factor level compared previous factor level \"pairwise\": factor level compared levels Vector length 2 two values compare. Logical variables: NULL: contrast TRUE FALSE Numeric variables: Numeric length 1: Contrast gap x, computed observed value plus minus x / 2. example, estimating +1 contrast compares adjusted predictions regressor equal observed value minus 0.5 observed value plus 0.5. Numeric vector length 2: Contrast 2nd element 1st element x vector. Function accepts numeric vector returns data frame two columns \"low\" \"high\" values compare. See examples . \"iqr\": Contrast across interquartile range regressor. \"sd\": Contrast across one standard deviation around regressor mean. \"2sd\": Contrast across two standard deviations around regressor mean. \"minmax\": Contrast maximum minimum values regressor. Examples: variables = list(gear = \"pairwise\", hp = 10) variables = list(gear = \"sequential\", hp = c(100, 120)) See Examples section . type string indicates type (scale) predictions used compute marginal effects contrasts. can differ based model type, typically string : \"response\", \"link\", \"probs\", \"zero\". unsupported string entered, model-specific list acceptable values returned error message. type NULL, default value used. default first model-related row marginaleffects:::type_dictionary dataframe. vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) conf_level numeric value 0 1. Confidence level use build confidence interval. transform_pre string function. pairs adjusted predictions contrasted? string: shortcuts common contrast functions. Supported shortcuts strings: difference, differenceavg, differenceavgwts, dydx, eyex, eydx, dyex, dydxavg, eyexavg, eydxavg, dyexavg, dydxavgwts, eyexavgwts, eydxavgwts, dyexavgwts, ratio, ratioavg, ratioavgwts, lnratio, lnratioavg, lnratioavgwts, lnor, lnoravg, lnoravgwts, expdydx, expdydxavg, expdydxavgwts See Transformations section definitions transformation. function: accept two equal-length numeric vectors adjusted predictions (hi lo) returns vector contrasts length, unique numeric value. See Transformations section examples valid functions. transform_post string function. Transformation applied unit-level estimates confidence intervals just function returns results. Functions must accept vector return vector length. Support string shortcuts: \"exp\", \"ln\" cross TRUE FALSE FALSE: Contrasts represent change adjusted predictions one predictor changes variables held constant. TRUE: Contrasts represent changes adjusted predictions predictors specified variables argument manipulated simultaneously (\"cross-contrast\"). Compute group-wise average estimates. Valid inputs: Character vector column names newdata data frame produced calling function without argument. Data frame column group labels, merging columns shared newdata data frame produced calling function without argument. See examples . wts string numeric: weights use computing average contrasts marginaleffects. weights affect averaging tidy() summary(), unit-level estimates . string: column name weights variable newdata. supplying column name wts, recommended supply original data (including weights variable) explicitly newdata. numeric: vector length equal number rows original data newdata (supplied). hypothesis specify hypothesis test custom contrast using vector, matrix, string, string formula. String: \"pairwise\": pairwise differences estimates row. \"reference\": differences estimates row estimate first row. \"sequential\": difference estimate estimate next row. \"revpairwise\", \"revreference\", \"revsequential\": inverse corresponding hypotheses, described . String formula specify linear non-linear hypothesis tests. term column uniquely identifies rows, terms can used formula. Otherwise, use b1, b2, etc. identify position parameter. Examples: hp = drat hp + drat = 12 b1 + b2 + b3 = 0 Numeric vector: Weights compute linear combination (custom contrast ) estimates. Length equal number rows generated function call, without hypothesis argument. Numeric matrix: column vector weights, describe , used compute distinct linear combination (contrast ) estimates. column names matrix used labels output. See Examples section vignette: https://vincentarelbundock.github.io/marginaleffects/articles/hypothesis.html eps NULL numeric value determines step size use calculating numerical derivatives: (f(x+eps)-f(x))/eps. eps NULL, step size 0.0001 multiplied difference maximum minimum values variable respect taking derivative. Changing eps may necessary avoid numerical problems certain models. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/comparisons.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Contrasts Between Adjusted Predictions — comparisons","text":"\"contrast\" difference, ratio function adjusted predictions, calculated meaningfully different predictor values (e.g., College graduates vs. Others). Uncertainty estimates computed using delta method. newdata argument can used control kind contrasts report: Average Contrasts Adjusted Risk Ratios Adjusted Risk Differences Group-Average Contrasts Contrasts Mean Contrasts User-Specified values (aka Contrasts Representative values, MER). Custom contrasts using arbitrary functions","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/comparisons.html","id":"vignettes-and-documentation","dir":"Reference","previous_headings":"","what":"Vignettes and documentation","title":"Contrasts Between Adjusted Predictions — comparisons","text":"Vignettes: Adjusted Predictions Contrasts Marginal Effects Marginal Means Hypothesis Tests Custom Contrasts using Delta Method Case studies: Bayesian Analyses brms Causal Inference g-Formula Elasticity Experiments Generalized Additive Models Mixed effects models Multinomial Logit Discrete Choice Models Multiple Imputation Plots: interactions, predictions, contrasts, slopes Python NumPyro models marginaleffects Unit-level contrasts logistic regressions Tips technical notes: 71 Supported Classes Models Index Functions Documentation Extending marginaleffects: add new models modify existing ones Standard Errors Confidence Intervals Tables Plots Performance Alternative Software Frequently Asked Questions","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/comparisons.html","id":"model-specific-arguments","dir":"Reference","previous_headings":"","what":"Model-Specific Arguments","title":"Contrasts Between Adjusted Predictions — comparisons","text":"model types allow model-specific arguments modify nature marginal effects, predictions, marginal means, contrasts.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/comparisons.html","id":"transformations","dir":"Reference","previous_headings":"","what":"Transformations","title":"Contrasts Between Adjusted Predictions — comparisons","text":"following transformations can applied supplying one shortcut strings transform_pre argument. hi vector adjusted predictions \"high\" side contrast. lo vector adjusted predictions \"low\" side contrast. y vector adjusted predictions original data. x predictor original data. eps step size use compute derivatives elasticities.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/comparisons.html","id":"bayesian-posterior-summaries","dir":"Reference","previous_headings":"","what":"Bayesian posterior summaries","title":"Contrasts Between Adjusted Predictions — comparisons","text":"default, credible intervals bayesian models built equal-tailed intervals. can changed highest density interval setting global option: options(\"marginaleffects_posterior_interval\" = \"eti\") options(\"marginaleffects_posterior_interval\" = \"hdi\") default, center posterior distribution bayesian models identified median. Users can use different summary function setting global option: options(\"marginaleffects_posterior_center\" = mean) options(\"marginaleffects_posterior_center\" = median) estimates averaged using argument, tidy() function, summary() function, posterior distribution marginalized twice . First, take average across units within iteration MCMC chain, according user requested argument tidy()/summary() functions. , identify center resulting posterior using function supplied \"marginaleffects_posterior_center\" option (median default).","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/comparisons.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Contrasts Between Adjusted Predictions — comparisons","text":"","code":"library(marginaleffects) library(magrittr)  # Linear model tmp <- mtcars tmp$am <- as.logical(tmp$am) mod <- lm(mpg ~ am + factor(cyl), tmp) comparisons(mod, variables = list(cyl = \"reference\")) %>% tidy() #> Warning: The `cyl` variable is treated as a categorical (factor) variable, but #>   the original data is of class numeric. It is safer and faster to convert #>   such variables to factor before fitting the model and calling #>   `marginaleffects` functions. #>    #>   This warning appears once per session. #>       type term contrast   estimate std.error statistic      p.value   conf.low #> 1 response  cyl    6 - 4  -6.156118  1.535723 -4.008612 6.107658e-05  -9.166079 #> 2 response  cyl    8 - 4 -10.067560  1.452082 -6.933187 4.114626e-12 -12.913589 #>   conf.high #> 1 -3.146156 #> 2 -7.221530 comparisons(mod, variables = list(cyl = \"sequential\")) %>% tidy() #>       type term contrast  estimate std.error statistic      p.value  conf.low #> 1 response  cyl    6 - 4 -6.156118  1.535723 -4.008612 6.107658e-05 -9.166079 #> 2 response  cyl    8 - 6 -3.911442  1.470254 -2.660385 7.805144e-03 -6.793087 #>   conf.high #> 1 -3.146156 #> 2 -1.029797 comparisons(mod, variables = list(cyl = \"pairwise\")) %>% tidy() #>       type term contrast   estimate std.error statistic      p.value   conf.low #> 1 response  cyl    6 - 4  -6.156118  1.535723 -4.008612 6.107658e-05  -9.166079 #> 2 response  cyl    8 - 4 -10.067560  1.452082 -6.933187 4.114626e-12 -12.913589 #> 3 response  cyl    8 - 6  -3.911442  1.470254 -2.660385 7.805144e-03  -6.793087 #>   conf.high #> 1 -3.146156 #> 2 -7.221530 #> 3 -1.029797  # GLM with different scale types mod <- glm(am ~ factor(gear), data = mtcars) comparisons(mod, type = \"response\") %>% tidy() #>       type term contrast  estimate std.error statistic      p.value  conf.low #> 1 response gear    4 - 3 0.6666667 0.1174440  5.676462 1.375090e-08 0.4364806 #> 2 response gear    5 - 3 1.0000000 0.1565921  6.386020 1.702589e-10 0.6930852 #>   conf.high #> 1 0.8968528 #> 2 1.3069148 comparisons(mod, type = \"link\") %>% tidy() #>   type term contrast  estimate std.error statistic      p.value  conf.low #> 1 link gear    4 - 3 0.6666667 0.1174440  5.676462 1.375090e-08 0.4364806 #> 2 link gear    5 - 3 1.0000000 0.1565921  6.386020 1.702589e-10 0.6930852 #>   conf.high #> 1 0.8968528 #> 2 1.3069148  # Contrasts at the mean comparisons(mod, newdata = \"mean\") #>   rowid     type term contrast comparison std.error statistic      p.value #> 1     1 response gear    4 - 3  0.6666667 0.1174440  5.676462 1.375090e-08 #> 2     1 response gear    5 - 3  1.0000000 0.1565921  6.386020 1.702589e-10 #>    conf.low conf.high     predicted predicted_hi  predicted_lo      am gear #> 1 0.4364806 0.8968528 -2.355139e-16    0.6666667 -2.355139e-16 0.40625    3 #> 2 0.6930852 1.3069148 -2.355139e-16    1.0000000 -2.355139e-16 0.40625    3  # Contrasts between marginal means comparisons(mod, newdata = \"marginalmeans\") #>       type term contrast comparison std.error statistic      p.value  conf.low #> 1 response gear    4 - 3  0.6666667 0.1174440  5.676462 1.375090e-08 0.4364806 #> 2 response gear    5 - 3  1.0000000 0.1565921  6.386020 1.702589e-10 0.6930852 #>   conf.high predicted predicted_hi  predicted_lo #> 1 0.8968528 0.5555556    0.6666667 -2.355139e-16 #> 2 1.3069148 0.5555556    1.0000000 -2.355139e-16  # Contrasts at user-specified values comparisons(mod, newdata = datagrid(am = 0, gear = tmp$gear)) #>   rowid     type term contrast comparison std.error statistic      p.value #> 1     1 response gear    4 - 3  0.6666667 0.1174440  5.676462 1.375090e-08 #> 2     2 response gear    4 - 3  0.6666667 0.1174440  5.676462 1.375090e-08 #> 3     3 response gear    4 - 3  0.6666667 0.1174440  5.676462 1.375090e-08 #> 4     1 response gear    5 - 3  1.0000000 0.1565921  6.386020 1.702589e-10 #> 5     2 response gear    5 - 3  1.0000000 0.1565921  6.386020 1.702589e-10 #> 6     3 response gear    5 - 3  1.0000000 0.1565921  6.386020 1.702589e-10 #>    conf.low conf.high     predicted predicted_hi  predicted_lo am gear #> 1 0.4364806 0.8968528  6.666667e-01    0.6666667 -2.355139e-16  0    4 #> 2 0.4364806 0.8968528 -2.355139e-16    0.6666667 -2.355139e-16  0    3 #> 3 0.4364806 0.8968528  1.000000e+00    0.6666667 -2.355139e-16  0    5 #> 4 0.6930852 1.3069148  6.666667e-01    1.0000000 -2.355139e-16  0    4 #> 5 0.6930852 1.3069148 -2.355139e-16    1.0000000 -2.355139e-16  0    3 #> 6 0.6930852 1.3069148  1.000000e+00    1.0000000 -2.355139e-16  0    5 comparisons(mod, newdata = datagrid(am = unique, gear = max)) #>   rowid     type term contrast comparison std.error statistic      p.value #> 1     1 response gear    4 - 3  0.6666667 0.1174440  5.676462 1.375090e-08 #> 2     2 response gear    4 - 3  0.6666667 0.1174440  5.676462 1.375090e-08 #> 3     1 response gear    5 - 3  1.0000000 0.1565921  6.386020 1.702589e-10 #> 4     2 response gear    5 - 3  1.0000000 0.1565921  6.386020 1.702589e-10 #>    conf.low conf.high predicted predicted_hi  predicted_lo am gear #> 1 0.4364806 0.8968528         1    0.6666667 -2.355139e-16  1    5 #> 2 0.4364806 0.8968528         1    0.6666667 -2.355139e-16  0    5 #> 3 0.6930852 1.3069148         1    1.0000000 -2.355139e-16  1    5 #> 4 0.6930852 1.3069148         1    1.0000000 -2.355139e-16  0    5  m <- lm(mpg ~ hp + drat + factor(cyl) + factor(am), data = mtcars) comparisons(m, variables = \"hp\", newdata = datagrid(FUN_factor = unique, FUN_numeric = median)) #>   rowid     type term contrast  comparison  std.error statistic     p.value #> 1     1 response   hp       +1 -0.04522926 0.01489036 -3.037487 0.002385599 #> 2     2 response   hp       +1 -0.04522926 0.01489036 -3.037487 0.002385599 #> 3     3 response   hp       +1 -0.04522926 0.01489036 -3.037487 0.002385599 #> 4     4 response   hp       +1 -0.04522926 0.01489036 -3.037487 0.002385599 #> 5     5 response   hp       +1 -0.04522926 0.01489036 -3.037487 0.002385599 #> 6     6 response   hp       +1 -0.04522926 0.01489036 -3.037487 0.002385599 #>      conf.low  conf.high predicted predicted_hi predicted_lo  mpg  hp  drat cyl #> 1 -0.07441382 -0.0160447  21.95333     21.93072     21.97595 19.2 123 3.695   6 #> 2 -0.07441382 -0.0160447  18.18910     18.16648     18.21171 19.2 123 3.695   6 #> 3 -0.07441382 -0.0160447  25.54890     25.52628     25.57151 19.2 123 3.695   4 #> 4 -0.07441382 -0.0160447  21.78467     21.76205     21.80728 19.2 123 3.695   4 #> 5 -0.07441382 -0.0160447  22.61705     22.59444     22.63967 19.2 123 3.695   8 #> 6 -0.07441382 -0.0160447  18.85282     18.83020     18.87543 19.2 123 3.695   8 #>   am    eps #> 1  1 0.0283 #> 2  0 0.0283 #> 3  1 0.0283 #> 4  0 0.0283 #> 5  1 0.0283 #> 6  0 0.0283   # Numeric contrasts mod <- lm(mpg ~ hp, data = mtcars) comparisons(mod, variables = list(hp = 1)) %>% tidy() #>       type term contrast    estimate std.error statistic      p.value #> 1 response   hp       +1 -0.06822828 0.0101193 -6.742389 1.558037e-11 #>      conf.low   conf.high #> 1 -0.08806175 -0.04839481 comparisons(mod, variables = list(hp = 5)) %>% tidy() #>       type term contrast   estimate  std.error statistic      p.value #> 1 response   hp       +5 -0.3411414 0.05059652 -6.742389 1.558038e-11 #>     conf.low conf.high #> 1 -0.4403087 -0.241974 comparisons(mod, variables = list(hp = c(90, 100))) %>% tidy() #>       type term contrast   estimate std.error statistic      p.value   conf.low #> 1 response   hp 100 - 90 -0.6822828  0.101193 -6.742389 1.558038e-11 -0.8806175 #>    conf.high #> 1 -0.4839481 comparisons(mod, variables = list(hp = \"iqr\")) %>% tidy() #>       type term contrast  estimate std.error statistic      p.value  conf.low #> 1 response   hp  Q3 - Q1 -5.697061 0.8449619 -6.742389 1.558038e-11 -7.353156 #>   conf.high #> 1 -4.040966 comparisons(mod, variables = list(hp = \"sd\")) %>% tidy() #>       type term                contrast  estimate std.error statistic #> 1 response   hp (x + sd/2) - (x - sd/2) -4.677926 0.6938085 -6.742389 #>        p.value  conf.low conf.high #> 1 1.558038e-11 -6.037766 -3.318087 comparisons(mod, variables = list(hp = \"minmax\")) %>% tidy() #>       type term  contrast estimate std.error statistic      p.value  conf.low #> 1 response   hp Max - Min -19.3086  2.863763 -6.742389 1.558038e-11 -24.92147 #>   conf.high #> 1 -13.69573  # using a function to specify a custom difference in one regressor dat <- mtcars dat$new_hp <- 49 * (dat$hp - min(dat$hp)) / (max(dat$hp) - min(dat$hp)) + 1 modlog <- lm(mpg ~ log(new_hp) + factor(cyl), data = dat) fdiff <- \\(x) data.frame(x, x + 10) comparisons(modlog, variables = list(new_hp = fdiff)) %>% summary() #>     Term Contrast Effect Std. Error z value  Pr(>|z|)  2.5 %  97.5 % #> 1 new_hp   custom -1.974     0.7105  -2.778 0.0054696 -3.366 -0.5812 #>  #> Model type:  lm  #> Prediction type:  response   # Adjusted Risk Ratio: see the contrasts vignette mod <- glm(vs ~ mpg, data = mtcars, family = binomial) cmp <- comparisons(mod, transform_pre = \"lnratioavg\") summary(cmp, transform_avg = exp) #>   Term Contrast Effect   Pr(>|z|) 2.5 % 97.5 % #> 1  mpg mean(+1)  1.135 2.3808e-10 1.091   1.18 #>  #> Model type:  glm  #> Prediction type:  response  #> Average-transformation:  exp   # Adjusted Risk Ratio: Manual specification of the `transform_pre` cmp <- comparisons(mod, transform_pre = function(hi, lo) log(mean(hi) / mean(lo))) summary(cmp, transform_avg = exp) #>   Term Contrast Effect   Pr(>|z|) 2.5 % 97.5 % #> 1  mpg       +1  1.135 2.3808e-10 1.091   1.18 #>  #> Model type:  glm  #> Prediction type:  response  #> Pre-transformation:  function(hi, lo) log(mean(hi)/mean(lo))  #> Average-transformation:  exp  # cross contrasts mod <- lm(mpg ~ factor(cyl) * factor(gear) + hp, data = mtcars) cmp <- comparisons(mod, variables = c(\"cyl\", \"gear\"), cross = TRUE) #> Warning: Model matrix is rank deficient. Some variance-covariance parameters are #>   missing. summary(cmp) #>    Term contrast_cyl contrast_gear  Effect Std. Error z value Pr(>|z|)  2.5 % #> 1 cross        6 - 4         4 - 3 -0.6306      3.405 -0.1852  0.85307 -7.303 #> 2 cross        6 - 4         5 - 3  2.6778      4.617  0.5800  0.56193 -6.372 #> 3 cross        8 - 4         4 - 3  3.3475      6.427  0.5208  0.60249 -9.250 #> 4 cross        8 - 4         5 - 3  5.5250      5.868  0.9416  0.34642 -5.976 #>   97.5 % #> 1  6.042 #> 2 11.727 #> 3 15.945 #> 4 17.026 #>  #> Model type:  lm  #> Prediction type:  response   # variable-specific contrasts cmp <- comparisons(mod, variables = list(gear = \"sequential\", hp = 10)) #> Warning: Model matrix is rank deficient. Some variance-covariance parameters are #>   missing. summary(cmp) #>   Term Contrast  Effect Std. Error z value Pr(>|z|)  2.5 %  97.5 % #> 1 gear    4 - 3  3.4095      2.587  1.3177 0.187591 -1.662  8.4806 #> 2 gear    5 - 4  2.6277      2.747  0.9566 0.338744 -2.756  8.0113 #> 3   hp      +10 -0.5741      0.225 -2.5518 0.010718 -1.015 -0.1331 #>  #> Model type:  lm  #> Prediction type:  response   # hypothesis test: is the `hp` marginal effect at the mean equal to the `drat` marginal effect mod <- lm(mpg ~ wt + drat, data = mtcars)  comparisons(     mod,     newdata = \"mean\",     hypothesis = \"wt = drat\") #>       type    term comparison std.error statistic      p.value conf.low #> 1 response wt=drat  -6.225381  1.051769 -5.918963 3.239776e-09 -8.28681 #>   conf.high #> 1 -4.163952  # same hypothesis test using row indices comparisons(     mod,     newdata = \"mean\",     hypothesis = \"b1 - b2 = 0\") #>       type    term comparison std.error statistic      p.value conf.low #> 1 response b1-b2=0  -6.225381  1.051769 -5.918963 3.239776e-09 -8.28681 #>   conf.high #> 1 -4.163952  # same hypothesis test using numeric vector of weights comparisons(     mod,     newdata = \"mean\",     hypothesis = c(1, -1)) #>       type   term comparison std.error statistic      p.value conf.low #> 1 response custom  -6.225381  1.051769 -5.918963 3.239776e-09 -8.28681 #>   conf.high #> 1 -4.163952  # two custom contrasts using a matrix of weights lc <- matrix(c(     1, -1,     2, 3),     ncol = 2) comparisons(     mod,     newdata = \"mean\",     hypothesis = lc) #>       type   term comparison std.error  statistic      p.value  conf.low #> 1 response custom  -6.225381  1.051769 -5.9189631 3.239776e-09  -8.28681 #> 2 response custom  -5.238308  5.623757 -0.9314607 3.516153e-01 -16.26067 #>   conf.high #> 1 -4.163952 #> 2  5.784052   # `by` argument mod <- lm(mpg ~ hp * am * vs, data = mtcars) cmp <- comparisons(mod, variables = \"hp\", by = c(\"vs\", \"am\")) summary(cmp) #>   Term Contrast vs am   Effect Std. Error z value  Pr(>|z|)    2.5 %    97.5 % #> 1   hp mean(+1)  0  1 -0.03685    0.01240  -2.971 0.0029676 -0.06116 -0.012540 #> 2   hp mean(+1)  1  1 -0.11115    0.04634  -2.399 0.0164473 -0.20197 -0.020336 #> 3   hp mean(+1)  1  0 -0.09941    0.05345  -1.860 0.0628876 -0.20417  0.005344 #> 4   hp mean(+1)  0  0 -0.04215    0.02477  -1.702 0.0887904 -0.09070  0.006394 #>  #> Model type:  lm  #> Prediction type:  response   library(nnet) mod <- multinom(factor(gear) ~ mpg + am * vs, data = mtcars, trace = FALSE) by <- data.frame(     group = c(\"3\", \"4\", \"5\"),     by = c(\"3,4\", \"3,4\", \"5\")) comparisons(mod, type = \"probs\", by = by) #>    type term    comparison   std.error   statistic     p.value    conf.low #> 1 probs  mpg  0.0004634916 0.005796055  0.07996674 0.936263711 -0.01089657 #> 2 probs   am -0.2227925482 0.079557885 -2.80038299 0.005104201 -0.37872314 #> 3 probs   vs  0.1021020743 0.073235805  1.39415514 0.163270760 -0.04143747 #> 4 probs  mpg -0.0009269832 0.011592109 -0.07996674 0.936263711 -0.02364710 #> 5 probs   am  0.4455850963 0.159115770  2.80038299 0.005104201  0.13372392 #> 6 probs   vs -0.2042041486 0.146471610 -1.39415514 0.163270760 -0.49128323 #>     conf.high  by #> 1  0.01182355 3,4 #> 2 -0.06686196 3,4 #> 3  0.24564161 3,4 #> 4  0.02179313   5 #> 5  0.75744628   5 #> 6  0.08287493   5"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/complete_levels.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a data.frame with all factor or character levels — complete_levels","title":"Create a data.frame with all factor or character levels — complete_levels","text":"model.matrix get_predicted break newdata includes factor variable, levels present data. bad us often want get predictions one () rows, factor levels inevitably missing.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/complete_levels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a data.frame with all factor or character levels — complete_levels","text":"","code":"complete_levels(x, character_levels = NULL)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/counterfactual.html","id":null,"dir":"Reference","previous_headings":"","what":"Superseded by datagridcf — counterfactual","title":"Superseded by datagridcf — counterfactual","text":"Superseded datagridcf","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/counterfactual.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Superseded by datagridcf — counterfactual","text":"","code":"counterfactual(..., model = NULL, newdata = NULL)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/datagrid.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a data grid of ","title":"Generate a data grid of ","text":"Generate data grid \"typical,\" \"counterfactual,\" user-specified values use newdata argument marginaleffects predictions functions.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/datagrid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a data grid of ","text":"","code":"datagrid(   ...,   model = NULL,   newdata = NULL,   grid_type = \"typical\",   FUN_character = Mode,   FUN_factor = Mode,   FUN_logical = Mode,   FUN_numeric = function(x) mean(x, na.rm = TRUE),   FUN_integer = function(x) round(mean(x, na.rm = TRUE)),   FUN_other = function(x) mean(x, na.rm = TRUE) )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/datagrid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a data grid of ","text":"... named arguments vectors values functions user-specified variables. Functions applied variable model dataset newdata, must return vector appropriate type. Character vectors automatically transformed factors necessary. +output include combinations variables (see Examples .) model Model object newdata data.frame (one one model newdata arguments grid_type character \"typical\": variables whose values explicitly specified user ... set mean mode, output functions supplied FUN_type arguments. \"counterfactual\": entire dataset duplicated combination variable values specified .... Variables explicitly supplied datagrid() set observed values original dataset. FUN_character function applied character variables. FUN_factor function applied factor variables. FUN_logical function applied factor variables. FUN_numeric function applied numeric variables. FUN_integer function applied integer variables. FUN_other function applied variable types.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/datagrid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a data grid of ","text":"data.frame row corresponds one combination named predictors supplied user via ... dots. Variables explicitly defined held mean mode.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/datagrid.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate a data grid of ","text":"datagrid used marginaleffects predictions call newdata argument, model automatically inserted function call, users need specify either model newdata arguments. Note variables used fit models attached results. user wants attach variables well (e.g., weights grouping variables), can supply data.frame explicitly newdata argument inside datagrid(). users supply model, data used fit model retrieved using insight::get_data function.","code":""},{"path":[]},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/datagrid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a data grid of ","text":"","code":"# The output only has 2 rows, and all the variables except `hp` are at their # mean or mode. datagrid(newdata = mtcars, hp = c(100, 110)) #>        mpg    cyl     disp     drat      wt     qsec     vs      am   gear #> 1 20.09062 6.1875 230.7219 3.596563 3.21725 17.84875 0.4375 0.40625 3.6875 #> 2 20.09062 6.1875 230.7219 3.596563 3.21725 17.84875 0.4375 0.40625 3.6875 #>     carb  hp #> 1 2.8125 100 #> 2 2.8125 110  # We get the same result by feeding a model instead of a data.frame mod <- lm(mpg ~ hp, mtcars) datagrid(model = mod, hp = c(100, 110)) #>        mpg  hp #> 1 20.09062 100 #> 2 20.09062 110  # Use in `marginaleffects` to compute \"Typical Marginal Effects\". When used # in `marginaleffects()` or `predictions()` we do not need to specify the #`model` or `newdata` arguments. marginaleffects(mod, newdata = datagrid(hp = c(100, 110))) #>   rowid     type term        dydx std.error statistic      p.value    conf.low #> 1     1 response   hp -0.06822828 0.0101193 -6.742389 1.558038e-11 -0.08806175 #> 2     2 response   hp -0.06822828 0.0101193 -6.742389 1.558038e-11 -0.08806175 #>     conf.high predicted predicted_hi predicted_lo      mpg  hp    eps #> 1 -0.04839481  23.27603     23.27410     23.27603 20.09062 100 0.0283 #> 2 -0.04839481  22.59375     22.59182     22.59375 20.09062 110 0.0283  # datagrid accepts functions datagrid(hp = range, cyl = unique, newdata = mtcars) #>        mpg     disp     drat      wt     qsec     vs      am   gear   carb  hp #> 1 20.09062 230.7219 3.596563 3.21725 17.84875 0.4375 0.40625 3.6875 2.8125  52 #> 2 20.09062 230.7219 3.596563 3.21725 17.84875 0.4375 0.40625 3.6875 2.8125  52 #> 3 20.09062 230.7219 3.596563 3.21725 17.84875 0.4375 0.40625 3.6875 2.8125  52 #> 4 20.09062 230.7219 3.596563 3.21725 17.84875 0.4375 0.40625 3.6875 2.8125 335 #> 5 20.09062 230.7219 3.596563 3.21725 17.84875 0.4375 0.40625 3.6875 2.8125 335 #> 6 20.09062 230.7219 3.596563 3.21725 17.84875 0.4375 0.40625 3.6875 2.8125 335 #>   cyl #> 1   6 #> 2   4 #> 3   8 #> 4   6 #> 5   4 #> 6   8 comparisons(mod, newdata = datagrid(hp = fivenum)) #>   rowid     type term contrast  comparison std.error statistic      p.value #> 1     1 response   hp       +1 -0.06822828 0.0101193 -6.742389 1.558038e-11 #> 2     2 response   hp       +1 -0.06822828 0.0101193 -6.742389 1.558038e-11 #> 3     3 response   hp       +1 -0.06822828 0.0101193 -6.742389 1.558037e-11 #> 4     4 response   hp       +1 -0.06822828 0.0101193 -6.742389 1.558037e-11 #> 5     5 response   hp       +1 -0.06822828 0.0101193 -6.742389 1.558038e-11 #>      conf.low   conf.high predicted predicted_hi predicted_lo      mpg  hp #> 1 -0.08806175 -0.04839481 26.550990    26.516876    26.585104 20.09062  52 #> 2 -0.08806175 -0.04839481 23.548946    23.514832    23.583060 20.09062  96 #> 3 -0.08806175 -0.04839481 21.706782    21.672668    21.740896 20.09062 123 #> 4 -0.08806175 -0.04839481 17.817770    17.783656    17.851885 20.09062 180 #> 5 -0.08806175 -0.04839481  7.242387     7.208273     7.276502 20.09062 335 #>      eps #> 1 0.0283 #> 2 0.0283 #> 3 0.0283 #> 4 0.0283 #> 5 0.0283  # The full dataset is duplicated with each observation given counterfactual # values of 100 and 110 for the `hp` variable. The original `mtcars` includes # 32 rows, so the resulting dataset includes 64 rows. dg <- datagrid(newdata = mtcars, hp = c(100, 110), grid_type = \"counterfactual\") nrow(dg) #> [1] 64  # We get the same result by feeding a model instead of a data.frame mod <- lm(mpg ~ hp, mtcars) dg <- datagrid(model = mod, hp = c(100, 110), grid_type = \"counterfactual\") nrow(dg) #> [1] 64"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/datagridcf.html","id":null,"dir":"Reference","previous_headings":"","what":"A ","title":"A ","text":"combination variable values specified, function duplicates entire data frame supplied newdata, entire dataset used fit model. convenience shortcut call datagrid() function argument grid_type=\"counterfactual\".","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/datagridcf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A ","text":"","code":"datagridcf(..., model = NULL, newdata = NULL)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/datagridcf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A ","text":"... named arguments vectors values functions user-specified variables. Functions applied variable model dataset newdata, must return vector appropriate type. Character vectors automatically transformed factors necessary. +output include combinations variables (see Examples .) model Model object newdata data.frame (one one model newdata arguments","code":""},{"path":[]},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/datagridcf.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A ","text":"","code":"# Fit a model with 32 observations from the `mtcars` dataset. nrow(mtcars) #> [1] 32  mod <- lm(mpg ~ hp + am, data = mtcars)  # We specify two values for the `am` variable and obtain a counterfactual # dataset with 64 observations (32 x 2). dat <- datagridcf(model = mod, am = 0:1) head(dat) #>   rowidcf  mpg  hp am #> 1       1 21.0 110  0 #> 2       2 21.0 110  0 #> 3       3 22.8  93  0 #> 4       4 21.4 110  0 #> 5       5 18.7 175  0 #> 6       6 18.1 105  0 nrow(dat) #> [1] 64  # We specify 2 values for the `am` variable and 3 values for the `hp` variable # and obtained a dataset with 192 observations (2x3x32), corresponding to the # full original data, with each possible combination of `hp` and `am`. dat <- datagridcf(am = 0:1, hp = c(100, 110, 120), newdata = mtcars) head(dat) #>   rowidcf  mpg cyl disp drat    wt  qsec vs gear carb am  hp #> 1       1 21.0   6  160 3.90 2.620 16.46  0    4    4  0 100 #> 2       2 21.0   6  160 3.90 2.875 17.02  0    4    4  0 100 #> 3       3 22.8   4  108 3.85 2.320 18.61  1    4    1  0 100 #> 4       4 21.4   6  258 3.08 3.215 19.44  1    3    1  0 100 #> 5       5 18.7   8  360 3.15 3.440 17.02  0    3    2  0 100 #> 6       6 18.1   6  225 2.76 3.460 20.22  1    3    1  0 100 dim(dat) #> [1] 192  12"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/deltamethod.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate and Standard Error of a Non-Linear Function of Estimated Model Parameters — deltamethod","title":"Estimate and Standard Error of a Non-Linear Function of Estimated Model Parameters — deltamethod","text":"deltamethod function get first-order approximate standard error nonlinear function vector random variables known estimated covariance matrix. deltamethod emulates behavior excellent well-established car::deltaMethod car::linearHypothesis functions, supports models, requires fewer dependencies, offers convenience features like shortcuts robust standard errors.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/deltamethod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate and Standard Error of a Non-Linear Function of Estimated Model Parameters — deltamethod","text":"","code":"deltamethod(   model,   hypothesis = NULL,   FUN = NULL,   vcov = NULL,   conf_level = 0.95,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/deltamethod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate and Standard Error of a Non-Linear Function of Estimated Model Parameters — deltamethod","text":"model Model object object generated comparisons(), marginaleffects(), predictions(), marginalmeans() functions. hypothesis specify hypothesis test custom contrast using vector, matrix, string, string formula. String: \"pairwise\": pairwise differences estimates row. \"reference\": differences estimates row estimate first row. \"sequential\": difference estimate estimate next row. \"revpairwise\", \"revreference\", \"revsequential\": inverse corresponding hypotheses, described . String formula specify linear non-linear hypothesis tests. term column uniquely identifies rows, terms can used formula. Otherwise, use b1, b2, etc. identify position parameter. Examples: hp = drat hp + drat = 12 b1 + b2 + b3 = 0 Numeric vector: Weights compute linear combination (custom contrast ) estimates. Length equal number rows generated function call, without hypothesis argument. Numeric matrix: column vector weights, describe , used compute distinct linear combination (contrast ) estimates. column names matrix used labels output. See Examples section vignette: https://vincentarelbundock.github.io/marginaleffects/articles/hypothesis.html FUN NULL function. NULL (default): hypothesis test model's coefficients. Function accepts model object returns numeric vector data.frame two columns called term estimate. argument can useful users want conduct hypothesis test arbitrary function quantities held model object. vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) conf_level numeric value 0 1. Confidence level use build confidence interval. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/deltamethod.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate and Standard Error of a Non-Linear Function of Estimated Model Parameters — deltamethod","text":"Warning: hypothesis tests objects produced marginaleffects package, safer use hypothesis argument original function. Using deltamethod() may work certain environments, called programmatically.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/deltamethod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate and Standard Error of a Non-Linear Function of Estimated Model Parameters — deltamethod","text":"","code":"library(marginaleffects) mod <- lm(mpg ~ hp + wt + factor(cyl), data = mtcars)  # When `FUN` and `hypothesis` are `NULL`, `deltamethod()` returns a data.frame of parameters deltamethod(mod) #>           term    estimate #> 1  (Intercept) 35.84599532 #> 2           hp -0.02311981 #> 3           wt -3.18140405 #> 4 factor(cyl)6 -3.35902490 #> 5 factor(cyl)8 -3.18588444  # Test of equality between coefficients deltamethod(mod, hypothesis = \"hp = wt\") #>      term estimate std.error statistic      p.value conf.low conf.high #> 1 hp = wt 3.158284 0.7199081  4.387066 1.148899e-05  1.74729  4.569278  # Non-linear function deltamethod(mod, hypothesis = \"exp(hp + wt) = 0.1\") #>                 term    estimate  std.error statistic    p.value   conf.low #> 1 exp(hp + wt) = 0.1 -0.05942178 0.02919718 -2.035189 0.04183184 -0.1166472 #>      conf.high #> 1 -0.002196363  # Robust standard errors deltamethod(mod, hypothesis = \"hp = wt\", vcov = \"HC3\") #>      term estimate std.error statistic      p.value conf.low conf.high #> 1 hp = wt 3.158284 0.8051929  3.922394 8.767334e-05 1.580135  4.736433  # b1, b2, ... shortcuts can be used to identify the position of the # parameters of interest in the output of FUN deltamethod(mod, hypothesis = \"b2 = b3\") #>      term estimate std.error statistic      p.value conf.low conf.high #> 1 b2 = b3 3.158284 0.7199081  4.387066 1.148899e-05  1.74729  4.569278  # term names with special characters have to be enclosed in backticks deltamethod(mod, hypothesis = \"`factor(cyl)6` = `factor(cyl)8`\") #>                              term   estimate std.error  statistic  p.value #> 1 `factor(cyl)6` = `factor(cyl)8` -0.1731405  1.653923 -0.1046847 0.916626 #>   conf.low conf.high #> 1 -3.41477   3.06849  mod2 <- lm(mpg ~ hp * drat, data = mtcars) deltamethod(mod2, hypothesis = \"`hp:drat` = drat\") #>               term  estimate std.error statistic    p.value  conf.low conf.high #> 1 `hp:drat` = drat -6.079059  2.894846 -2.099959 0.03573245 -11.75285 -0.405264  # predictions(), comparisons(), and marginaleffects() mod <- glm(am ~ hp + mpg, data = mtcars, family = binomial) cmp <- comparisons(mod, newdata = \"mean\") deltamethod(cmp, hypothesis = \"b1 = b2\") #> Error: Models of class \"function\" are not supported. Supported model classes #>   include: #>    #>   Gam, afex_aov, betareg, bife, bigglm, biglm, bracl, brglmFit, brmsfit, #>   brnb, clm, clogit, coxph, crch, fixest, gam, gamlss, geeglm, glimML, #>   glm, glmerMod, glmmPQL, glmmTMB, glmrob, glmx, gls, hurdle, hxlr, #>   iv_robust, ivreg, lm, lmRob, lm_robust, lmerMod, lmerModLmerTest, lmrob, #>   loess, lrm, mblogit, mclogit, mhurdle, mlogit, multinom, negbin, ols, #>   orm, plm, polr, rlmerMod, rq, scam, selection, speedglm, speedlm, #>   stanreg, tobit, tobit1, truncreg, zeroinfl #>    #>   New modeling packages can usually be supported by `marginaleffects` if #>   they include a working `predict()` method. If you believe that this is #>   the case, please file a feature request on Github: #>   https://github.com/vincentarelbundock/marginaleffects/issues  mfx <- marginaleffects(mod, newdata = \"mean\") deltamethod(cmp, hypothesis = \"b2 = 0.2\") #> Error: Models of class \"function\" are not supported. Supported model classes #>   include: #>    #>   Gam, afex_aov, betareg, bife, bigglm, biglm, bracl, brglmFit, brmsfit, #>   brnb, clm, clogit, coxph, crch, fixest, gam, gamlss, geeglm, glimML, #>   glm, glmerMod, glmmPQL, glmmTMB, glmrob, glmx, gls, hurdle, hxlr, #>   iv_robust, ivreg, lm, lmRob, lm_robust, lmerMod, lmerModLmerTest, lmrob, #>   loess, lrm, mblogit, mclogit, mhurdle, mlogit, multinom, negbin, ols, #>   orm, plm, polr, rlmerMod, rq, scam, selection, speedglm, speedlm, #>   stanreg, tobit, tobit1, truncreg, zeroinfl #>    #>   New modeling packages can usually be supported by `marginaleffects` if #>   they include a working `predict()` method. If you believe that this is #>   the case, please file a feature request on Github: #>   https://github.com/vincentarelbundock/marginaleffects/issues  pre <- predictions(mod, newdata = datagrid(hp = 110, mpg = c(30, 35))) deltamethod(pre, hypothesis = \"b1 = b2\") #> Warning: Some of the variable names are missing from the model data: hp, mpg #> Error: Unable to compute predicted values with this model. You can try to #>   supply a different dataset to the `newdata` argument. If this does not #>   work, you can file a report on the Github Issue Tracker: #>   https://github.com/vincentarelbundock/marginaleffects/issues #>   This error was also raised: no applicable method for 'predict' applied #>   to an object of class \"function\"  # The `FUN` argument can be used to compute standard errors for fitted values mod <- glm(am ~ hp + mpg, data = mtcars, family = binomial)  f <- function(x) predict(x, type = \"link\", newdata = mtcars) p <- deltamethod(mod, FUN = f) head(p) #>   term   estimate std.error  statistic    p.value  conf.low  conf.high #> 1   b1 -1.0983601 0.7160423 -1.5339319 0.12504640 -2.501777  0.3050570 #> 2   b2 -1.0983601 0.7160423 -1.5339319 0.12504640 -2.501777  0.3050570 #> 3   b3  0.2331884 0.7808207  0.2986452 0.76521076 -1.297192  1.7635688 #> 4   b4 -0.5945143 0.6471012 -0.9187346 0.35823441 -1.862809  0.6737808 #> 5   b5 -0.4175761 0.6474633 -0.6449417 0.51896494 -1.686581  0.8514287 #> 6   b6 -5.0264654 2.1949096 -2.2900558 0.02201808 -9.328409 -0.7245217  f <- function(x) predict(x, type = \"response\", newdata = mtcars) p <- deltamethod(mod, FUN = f) head(p) #>   term    estimate  std.error statistic     p.value    conf.low  conf.high #> 1   b1 0.250047286 0.13293667 1.8809504 0.059978669 -0.01050381 0.51059838 #> 2   b2 0.250047286 0.13293667 1.8809504 0.059978669 -0.01050381 0.51059838 #> 3   b3 0.558034354 0.19239540 2.9004558 0.003726204  0.18094630 0.93512241 #> 4   b4 0.355599745 0.14785649 2.4050330 0.016171004  0.06580635 0.64539314 #> 5   b5 0.397096909 0.15541311 2.5551057 0.010615556  0.09249282 0.70170100 #> 6   b6 0.006519185 0.01407361 0.4632204 0.643206374 -0.02106459 0.03410296"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/get_coef.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a named vector of coefficients from a model object (internal function) — get_coef","title":"Get a named vector of coefficients from a model object (internal function) — get_coef","text":"Get named vector coefficients model object (internal function)","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/get_coef.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a named vector of coefficients from a model object (internal function) — get_coef","text":"","code":"get_coef(model, ...)  # S3 method for default get_coef(model, ...)  # S3 method for polr get_coef(model, ...)  # S3 method for afex_aov get_coef(model, ...)  # S3 method for betareg get_coef(model, ...)  # S3 method for multinom get_coef(model, ...)  # S3 method for brmultinom get_coef(model, ...)  # S3 method for bracl get_coef(model, ...)  # S3 method for brmsfit get_coef(model, ...)  # S3 method for gamlss get_coef(model, ...)  # S3 method for glmmTMB get_coef(model, ...)  # S3 method for merMod get_coef(model, ...)  # S3 method for lmerModLmerTest get_coef(model, ...)  # S3 method for lmerMod get_coef(model, ...)  # S3 method for mblogit get_coef(model, ...)  # S3 method for gam get_coef(model, ...)  # S3 method for mlm get_coef(model, ...)  # S3 method for selection get_coef(model, ...)  # S3 method for scam get_coef(model, ...)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/get_coef.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a named vector of coefficients from a model object (internal function) — get_coef","text":"model Model object ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/get_coef.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get a named vector of coefficients from a model object (internal function) — get_coef","text":"named vector coefficients. names must match variance matrix.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/get_group_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Get levels of the outcome variable in grouped or multivariate models — get_group_names","title":"Get levels of the outcome variable in grouped or multivariate models — get_group_names","text":"Get levels outcome variable grouped multivariate models","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/get_group_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get levels of the outcome variable in grouped or multivariate models — get_group_names","text":"","code":"get_group_names(model, ...)  # S3 method for default get_group_names(model, ...)  # S3 method for polr get_group_names(model, ...)  # S3 method for multinom get_group_names(model, ...)  # S3 method for bracl get_group_names(model, ...)  # S3 method for brmsfit get_group_names(model, ...)  # S3 method for mblogit get_group_names(model, type, ...)  # S3 method for mlm get_group_names(model, ...)  # S3 method for clm get_group_names(model, ...)  # S3 method for hurdle get_group_names(model, type = \"count\", ...)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/get_group_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get levels of the outcome variable in grouped or multivariate models — get_group_names","text":"model Model object ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments. type string indicates type (scale) predictions used compute marginal effects contrasts. can differ based model type, typically string : \"response\", \"link\", \"probs\", \"zero\". unsupported string entered, model-specific list acceptable values returned error message. type NULL, default value used. default first model-related row marginaleffects:::type_dictionary dataframe.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/get_group_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get levels of the outcome variable in grouped or multivariate models — get_group_names","text":"character vector","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/get_predict.html","id":null,"dir":"Reference","previous_headings":"","what":"Get predicted values from a model object (internal function) — get_predict","title":"Get predicted values from a model object (internal function) — get_predict","text":"Get predicted values model object (internal function)","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/get_predict.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get predicted values from a model object (internal function) — get_predict","text":"","code":"get_predict(model, newdata, vcov, conf_level, type, ...)  # S3 method for default get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"response\",   ... )  # S3 method for polr get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"probs\",   ... )  # S3 method for glmmPQL get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"response\",   ... )  # S3 method for afex_aov get_predict(model, newdata = NULL, ...)  # S3 method for glimML get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"response\",   ... )  # S3 method for betareg get_predict(model, newdata, ...)  # S3 method for bife get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"response\",   ... )  # S3 method for biglm get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"response\",   ... )  # S3 method for multinom get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"probs\",   ... )  # S3 method for brmultinom get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"probs\",   ... )  # S3 method for brmsfit get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"response\",   ... )  # S3 method for crch get_predict(   model,   newdata = NULL,   vcov = FALSE,   conf_level = 0.95,   type = \"location\",   ... )  # S3 method for fixest get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"response\",   ... )  # S3 method for gamlss get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"response\",   ... )  # S3 method for glmmTMB get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"response\",   ... )  # S3 method for merMod get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"response\",   ... )  # S3 method for lmerModLmerTest get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"response\",   ... )  # S3 method for lmerMod get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"response\",   ... )  # S3 method for mblogit get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"response\",   ... )  # S3 method for mhurdle get_predict(   model,   newdata = insight::get_data(model),   vcov = NULL,   conf_level = 0.95,   type = \"response\",   ... )  # S3 method for mlogit get_predict(model, newdata, ...)  # S3 method for clm get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"response\",   ... )  # S3 method for rq get_predict(   model,   newdata = insight::get_data(model),   vcov = NULL,   conf_level = 0.95,   type = NULL,   ... )  # S3 method for rlmerMod get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"response\",   ... )  # S3 method for stanreg get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"response\",   ... )  # S3 method for coxph get_predict(   model,   newdata = insight::get_data(model),   vcov = FALSE,   conf_level = 0.95,   type = \"lp\",   ... )  # S3 method for tobit1 get_predict(   model,   newdata = insight::get_data(model),   vcov = NULL,   conf_level = 0.95,   type = \"response\",   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/get_predict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get predicted values from a model object (internal function) — get_predict","text":"model Model object newdata NULL, data frame, string, datagrid() call. Determines predictor values compute marginal effects. NULL (default): Unit-level marginal effects observed value original dataset. data frame: Unit-level marginal effects row newdata data frame. string: \"mean\": Marginal Effects Mean. Marginal effects predictor held mean mode. \"median\": Marginal Effects Median. Marginal effects predictor held median mode. \"marginalmeans\": Marginal Effects Marginal Means. See Details section . \"tukey\": Marginal Effects Tukey's 5 numbers. \"grid\": Marginal Effects grid representative numbers (Tukey's 5 numbers unique values categorical predictors). datagrid() call specify custom grid regressors. example: newdata = datagrid(cyl = c(4, 6)): cyl variable equal 4 6 regressors fixed means modes. See Examples section datagrid() documentation. vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) conf_level numeric value 0 1. Confidence level use build confidence interval. type string indicates type (scale) predictions used compute marginal effects contrasts. can differ based model type, typically string : \"response\", \"link\", \"probs\", \"zero\". unsupported string entered, model-specific list acceptable values returned error message. type NULL, default value used. default first model-related row marginaleffects:::type_dictionary dataframe. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/get_predict.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get predicted values from a model object (internal function) — get_predict","text":"data.frame predicted values number rows equal number rows newdata columns \"rowid\" \"predicted\". \"group\" column added multivariate models models categorical outcomes.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/get_varcov_args.html","id":null,"dir":"Reference","previous_headings":"","what":"Take a modelsummary() style vcov argument and convert it to\ninsight::get_varcov() — get_varcov_args","title":"Take a modelsummary() style vcov argument and convert it to\ninsight::get_varcov() — get_varcov_args","text":"Take modelsummary() style vcov argument convert insight::get_varcov()","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/get_varcov_args.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Take a modelsummary() style vcov argument and convert it to\ninsight::get_varcov() — get_varcov_args","text":"","code":"get_varcov_args(model, vcov)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/get_vcov.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a named variance-covariance matrix from a model object (internal function) — get_vcov","title":"Get a named variance-covariance matrix from a model object (internal function) — get_vcov","text":"Get named variance-covariance matrix model object (internal function)","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/get_vcov.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a named variance-covariance matrix from a model object (internal function) — get_vcov","text":"","code":"get_vcov(model, ...)  # S3 method for default get_vcov(model, vcov = NULL, ...)  # S3 method for afex_aov get_vcov(model, vcov = NULL, ...)  # S3 method for glimML get_vcov(model, vcov = NULL, ...)  # S3 method for biglm get_vcov(model, vcov = NULL, ...)  # S3 method for brmsfit get_vcov(model, vcov = NULL, ...)  # S3 method for gamlss get_vcov(model, ...)  # S3 method for mhurdle get_vcov(model, vcov = NULL, ...)  # S3 method for orm get_vcov(model, vcov = NULL, ...)  # S3 method for scam get_vcov(model, vcov = NULL, ...)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/get_vcov.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a named variance-covariance matrix from a model object (internal function) — get_vcov","text":"model Model object ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments. vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model))","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/get_vcov.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get a named variance-covariance matrix from a model object (internal function) — get_vcov","text":"named square matrix variance covariances. names must match coefficient names.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/glance.marginaleffects.html","id":null,"dir":"Reference","previous_headings":"","what":"Glance at key characteristics of an object — glance.marginaleffects","title":"Glance at key characteristics of an object — glance.marginaleffects","text":"Glance key characteristics object","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/glance.marginaleffects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Glance at key characteristics of an object — glance.marginaleffects","text":"","code":"# S3 method for marginaleffects glance(x, ...)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/glance.marginaleffects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Glance at key characteristics of an object — glance.marginaleffects","text":"x object produced marginaleffects function. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":[]},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/hush.html","id":null,"dir":"Reference","previous_headings":"","what":"Execute code silently — hush","title":"Execute code silently — hush","text":"Execute code silently","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/hush.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Execute code silently — hush","text":"","code":"hush(code)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/marginaleffects.html","id":null,"dir":"Reference","previous_headings":"","what":"Marginal Effects (Slopes) — marginaleffects","title":"Marginal Effects (Slopes) — marginaleffects","text":"Partial derivative (slope) regression equation respect regressor interest. tidy() summary() functions can used aggregate summarize output marginaleffects(). learn , read marginal effects vignette, visit package website, scroll page full list vignettes: https://vincentarelbundock.github.io/marginaleffects/articles/marginaleffects.html https://vincentarelbundock.github.io/marginaleffects/","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/marginaleffects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Marginal Effects (Slopes) — marginaleffects","text":"","code":"marginaleffects(   model,   newdata = NULL,   variables = NULL,   vcov = TRUE,   conf_level = 0.95,   type = NULL,   slope = \"dydx\",   by = NULL,   wts = NULL,   hypothesis = NULL,   eps = NULL,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/marginaleffects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Marginal Effects (Slopes) — marginaleffects","text":"model Model object newdata NULL, data frame, string, datagrid() call. Determines predictor values compute marginal effects. NULL (default): Unit-level marginal effects observed value original dataset. data frame: Unit-level marginal effects row newdata data frame. string: \"mean\": Marginal Effects Mean. Marginal effects predictor held mean mode. \"median\": Marginal Effects Median. Marginal effects predictor held median mode. \"marginalmeans\": Marginal Effects Marginal Means. See Details section . \"tukey\": Marginal Effects Tukey's 5 numbers. \"grid\": Marginal Effects grid representative numbers (Tukey's 5 numbers unique values categorical predictors). datagrid() call specify custom grid regressors. example: newdata = datagrid(cyl = c(4, 6)): cyl variable equal 4 6 regressors fixed means modes. See Examples section datagrid() documentation. variables NULL character vector. subset variables compute marginal effects. NULL: compute contrasts variables model object (can slow). Character vector: subset variables (usually faster). vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) conf_level numeric value 0 1. Confidence level use build confidence interval. type string indicates type (scale) predictions used compute marginal effects contrasts. can differ based model type, typically string : \"response\", \"link\", \"probs\", \"zero\". unsupported string entered, model-specific list acceptable values returned error message. type NULL, default value used. default first model-related row marginaleffects:::type_dictionary dataframe. slope string indicates type slope (semi-)elasticity compute: \"dydx\": dY/dX \"eyex\": dY/dX * Y / X \"eydx\": dY/dX * Y \"dyex\": dY/dX / X Character vector variable names compute group-wise estimates. wts string numeric: weights use computing average contrasts marginaleffects. weights affect averaging tidy() summary(), unit-level estimates . string: column name weights variable newdata. supplying column name wts, recommended supply original data (including weights variable) explicitly newdata. numeric: vector length equal number rows original data newdata (supplied). hypothesis specify hypothesis test custom contrast using vector, matrix, string, string formula. String: \"pairwise\": pairwise differences estimates row. \"reference\": differences estimates row estimate first row. \"sequential\": difference estimate estimate next row. \"revpairwise\", \"revreference\", \"revsequential\": inverse corresponding hypotheses, described . String formula specify linear non-linear hypothesis tests. term column uniquely identifies rows, terms can used formula. Otherwise, use b1, b2, etc. identify position parameter. Examples: hp = drat hp + drat = 12 b1 + b2 + b3 = 0 Numeric vector: Weights compute linear combination (custom contrast ) estimates. Length equal number rows generated function call, without hypothesis argument. Numeric matrix: column vector weights, describe , used compute distinct linear combination (contrast ) estimates. column names matrix used labels output. See Examples section vignette: https://vincentarelbundock.github.io/marginaleffects/articles/hypothesis.html eps NULL numeric value determines step size use calculating numerical derivatives: (f(x+eps)-f(x))/eps. eps NULL, step size 0.0001 multiplied difference maximum minimum values variable respect taking derivative. Changing eps may necessary avoid numerical problems certain models. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/marginaleffects.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Marginal Effects (Slopes) — marginaleffects","text":"data.frame one row per observation (per term/group) several columns: rowid: row number newdata data frame type: prediction type, defined type argument group: (optional) value grouped outcome (e.g., categorical outcome models) term: variable whose marginal effect computed dydx: marginal effect term outcome given combination regressor values std.error: standard errors computed via delta method.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/marginaleffects.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Marginal Effects (Slopes) — marginaleffects","text":"\"marginal effect\" partial derivative regression equation respect variable model. function uses automatic differentiation compute marginal effects vast array models, including non-linear models transformations (e.g., polynomials). Uncertainty estimates computed using delta method. newdata argument can used control kind marginal effects report: Average Marginal Effects (AME) Group-Average Marginal Effects (G-AME) Marginal Effects Mean (MEM) Marginal Effects User-Specified values (aka Marginal Effects Representative values, MER). See marginaleffects vignette worked-examples kind marginal effect. Numerical derivatives marginaleffects function calculated using simple epsilon difference approach: \\(\\partial Y / \\partial X = (f(X + \\varepsilon) - f(X)) / \\varepsilon\\), f predict() method associated model class, \\(\\varepsilon\\) determined eps argument. Warning: models particularly sensitive eps, good practice try different values argument. Standard errors marginal effects obtained using Delta method. See \"Standard Errors\" vignette package website details (link ).","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/marginaleffects.html","id":"vignettes-and-documentation","dir":"Reference","previous_headings":"","what":"Vignettes and documentation","title":"Marginal Effects (Slopes) — marginaleffects","text":"Vignettes: Adjusted Predictions Contrasts Marginal Effects Marginal Means Hypothesis Tests Custom Contrasts using Delta Method Case studies: Bayesian Analyses brms Causal Inference g-Formula Elasticity Experiments Generalized Additive Models Mixed effects models Multinomial Logit Discrete Choice Models Multiple Imputation Plots: interactions, predictions, contrasts, slopes Python NumPyro models marginaleffects Unit-level contrasts logistic regressions Tips technical notes: 71 Supported Classes Models Index Functions Documentation Extending marginaleffects: add new models modify existing ones Standard Errors Confidence Intervals Tables Plots Performance Alternative Software Frequently Asked Questions","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/marginaleffects.html","id":"model-specific-arguments","dir":"Reference","previous_headings":"","what":"Model-Specific Arguments","title":"Marginal Effects (Slopes) — marginaleffects","text":"model types allow model-specific arguments modify nature marginal effects, predictions, marginal means, contrasts.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/marginaleffects.html","id":"bayesian-posterior-summaries","dir":"Reference","previous_headings":"","what":"Bayesian posterior summaries","title":"Marginal Effects (Slopes) — marginaleffects","text":"default, credible intervals bayesian models built equal-tailed intervals. can changed highest density interval setting global option: options(\"marginaleffects_posterior_interval\" = \"eti\") options(\"marginaleffects_posterior_interval\" = \"hdi\") default, center posterior distribution bayesian models identified median. Users can use different summary function setting global option: options(\"marginaleffects_posterior_center\" = mean) options(\"marginaleffects_posterior_center\" = median) estimates averaged using argument, tidy() function, summary() function, posterior distribution marginalized twice . First, take average across units within iteration MCMC chain, according user requested argument tidy()/summary() functions. , identify center resulting posterior using function supplied \"marginaleffects_posterior_center\" option (median default).","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/marginaleffects.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Marginal Effects (Slopes) — marginaleffects","text":"","code":"mod <- glm(am ~ hp * wt, data = mtcars, family = binomial) mfx <- marginaleffects(mod) head(mfx) #>   rowid     type term         dydx    std.error statistic   p.value #> 1     1 response   hp 0.0069832251 0.0058793768 1.1877492 0.2349322 #> 2     2 response   hp 0.0164041227 0.0133880594 1.2252801 0.2204697 #> 3     3 response   hp 0.0028284517 0.0037506567 0.7541217 0.4507761 #> 4     4 response   hp 0.0019348755 0.0024508961 0.7894564 0.4298453 #> 5     5 response   hp 0.0029928602 0.0033775105 0.8861142 0.3755560 #> 6     6 response   hp 0.0001476461 0.0003452784 0.4276146 0.6689317 #>        conf.low    conf.high   predicted predicted_hi predicted_lo am  hp    wt #> 1 -0.0045401417 0.0185065919 0.898311019   0.89850864  0.898311019  1 110 2.620 #> 2 -0.0098359916 0.0426442370 0.467644655   0.46810889  0.467644655  1 110 2.875 #> 3 -0.0045227004 0.0101796038 0.967103810   0.96718386  0.967103810  1  93 2.320 #> 4 -0.0028687925 0.0067385435 0.038895584   0.03895034  0.038895584  0 110 3.215 #> 5 -0.0036269388 0.0096126591 0.076483825   0.07656852  0.076483825  0 175 3.440 #> 6 -0.0005290872 0.0008243794 0.003566962   0.00357114  0.003566962  0 105 3.460 #>      eps #> 1 0.0283 #> 2 0.0283 #> 3 0.0283 #> 4 0.0283 #> 5 0.0283 #> 6 0.0283  # Average Marginal Effect (AME) summary(mfx) #>   Term    Effect Std. Error z value   Pr(>|z|)     2.5 %    97.5 % #> 1   hp  0.002653   0.001939   1.368    0.17121 -0.001147  0.006452 #> 2   wt -0.435783   0.102063  -4.270 1.9568e-05 -0.635822 -0.235744 #>  #> Model type:  glm  #> Prediction type:  response  tidy(mfx) #>       type term     estimate   std.error statistic      p.value     conf.low #> 1 response   hp  0.002652526 0.001938531  1.368318 1.712127e-01 -0.001146925 #> 2 response   wt -0.435783199 0.102062710 -4.269759 1.956841e-05 -0.635822435 #>      conf.high #> 1  0.006451977 #> 2 -0.235743963 plot(mfx)    # Marginal Effect at the Mean (MEM) marginaleffects(mod, newdata = datagrid()) #>   rowid     type term         dydx   std.error statistic   p.value     conf.low #> 1     1 response   hp  0.008526944 0.007849817  1.086260 0.2773639 -0.006858415 #> 2     1 response   wt -1.744526869 1.586306474 -1.099741 0.2714448 -4.853630428 #>   conf.high predicted predicted_hi predicted_lo      am       hp      wt #> 1 0.0239123  0.208598    0.2088393     0.208598 0.40625 146.6875 3.21725 #> 2 1.3645767  0.208598    0.2079157     0.208598 0.40625 146.6875 3.21725 #>         eps #> 1 0.0283000 #> 2 0.0003911  # Marginal Effect at User-Specified Values # Variables not explicitly included in `datagrid()` are held at their means marginaleffects(mod,                 newdata = datagrid(hp = c(100, 110))) #>   rowid     type term         dydx   std.error  statistic   p.value #> 1     1 response   hp  0.001166673 0.001754130  0.6651008 0.5059860 #> 2     2 response   hp  0.001895403 0.002416124  0.7844807 0.4327581 #> 3     1 response   wt -0.194677637 0.307227707 -0.6336591 0.5263033 #> 4     2 response   wt -0.331535828 0.436074375 -0.7602736 0.4470911 #>       conf.low   conf.high  predicted predicted_hi predicted_lo      am      wt #> 1 -0.002271359 0.004604705 0.02311544   0.02314846   0.02311544 0.40625 3.21725 #> 2 -0.002840114 0.006630920 0.03814134   0.03819498   0.03814134 0.40625 3.21725 #> 3 -0.796832879 0.407477604 0.02311544   0.02303930   0.02311544 0.40625 3.21725 #> 4 -1.186225897 0.523154240 0.03814134   0.03801168   0.03814134 0.40625 3.21725 #>    hp       eps #> 1 100 0.0283000 #> 2 110 0.0283000 #> 3 100 0.0003911 #> 4 110 0.0003911  # Group-Average Marginal Effects (G-AME) # Calculate marginal effects for each observation, and then take the average # marginal effect within each subset of observations with different observed # values for the `cyl` variable: mod2 <- lm(mpg ~ hp * cyl, data = mtcars) mfx2 <- marginaleffects(mod2, variables = \"hp\", by = \"cyl\") summary(mfx2) #>   Term    Contrast cyl   Effect Std. Error z value  Pr(>|z|)    2.5 %   97.5 % #> 1   hp mean(dY/dX)   6 -0.05226    0.02041 -2.5608 0.0104442 -0.09225 -0.01226 #> 2   hp mean(dY/dX)   4 -0.09173    0.03533 -2.5964 0.0094216 -0.16098 -0.02248 #> 3   hp mean(dY/dX)   8 -0.01278    0.01434 -0.8912 0.3727993 -0.04089  0.01533 #>  #> Model type:  lm  #> Prediction type:  response   # Marginal Effects at User-Specified Values (counterfactual) # Variables not explicitly included in `datagrid()` are held at their # original values, and the whole dataset is duplicated once for each # combination of the values in `datagrid()` mfx <- marginaleffects(mod,                        newdata = datagrid(hp = c(100, 110),                                           grid_type = \"counterfactual\")) head(mfx) #>   rowid     type term         dydx    std.error statistic   p.value #> 1     1 response   hp 0.0120345428 0.0099871557 1.2050020 0.2282025 #> 2     2 response   hp 0.0141605125 0.0108083854 1.3101413 0.1901480 #> 3     3 response   hp 0.0015641805 0.0022024745 0.7101923 0.4775849 #> 4     4 response   hp 0.0011906427 0.0017804554 0.6687293 0.5036682 #> 5     5 response   hp 0.0001454839 0.0003410785 0.4265408 0.6697138 #> 6     6 response   hp 0.0001201299 0.0002911014 0.4126737 0.6798457 #>        conf.low    conf.high rowidcf   predicted predicted_hi predicted_lo am #> 1 -0.0075399227 0.0316090083       1 0.804313722  0.804654300  0.804313722  1 #> 2 -0.0070235336 0.0353445586       2 0.312493620  0.312894363  0.312493620  1 #> 3 -0.0027525902 0.0058809511       3 0.982084695  0.982128961  0.982084695  1 #> 4 -0.0022989857 0.0046802710       4 0.023558258  0.023591954  0.023558258  0 #> 5 -0.0005230176 0.0008139854       5 0.003445112  0.003449229  0.003445112  0 #> 6 -0.0004504183 0.0006906781       6 0.002900259  0.002903658  0.002900259  0 #>      wt  hp    eps #> 1 2.620 100 0.0283 #> 2 2.875 100 0.0283 #> 3 2.320 100 0.0283 #> 4 3.215 100 0.0283 #> 5 3.440 100 0.0283 #> 6 3.460 100 0.0283  # Heteroskedasticity robust standard errors marginaleffects(mod, vcov = sandwich::vcovHC(mod)) #>    rowid     type term          dydx    std.error   statistic     p.value #> 1      1 response   hp  6.983225e-03 9.187144e-03  0.76010842 0.447189783 #> 2      2 response   hp  1.640412e-02 1.340247e-02  1.22396222 0.220966481 #> 3      3 response   hp  2.828452e-03 4.912949e-03  0.57571361 0.564808772 #> 4      4 response   hp  1.934876e-03 1.843501e-03  1.04956553 0.293917911 #> 5      5 response   hp  2.992860e-03 2.782662e-03  1.07553836 0.282133766 #> 6      6 response   hp  1.476461e-04 2.545412e-04  0.58004785 0.561882353 #> 7      7 response   hp  5.740668e-03 8.192346e-03  0.70073547 0.483468119 #> 8      8 response   hp  2.111702e-04 3.886726e-04  0.54331124 0.586915530 #> 9      9 response   hp  1.646976e-03 1.727929e-03  0.95314999 0.340514082 #> 10    10 response   hp  3.809918e-04 5.150443e-04  0.73972622 0.459466136 #> 11    11 response   hp  3.809918e-04 5.150443e-04  0.73972622 0.459466136 #> 12    12 response   hp  8.760463e-07 6.574577e-06  0.13324755 0.893997607 #> 13    13 response   hp  9.575809e-05 3.219972e-04  0.29738799 0.766170309 #> 14    14 response   hp  4.915362e-05 1.903900e-04  0.25817324 0.796273208 #> 15    15 response   hp -5.787254e-13 8.594637e-12 -0.06733565 0.946314499 #> 16    16 response   hp -4.902183e-14 8.735888e-13 -0.05611545 0.955249833 #> 17    17 response   hp -7.463248e-14 1.373213e-12 -0.05434881 0.956657263 #> 18    18 response   hp  1.107615e-02 1.420807e-02  0.77956725 0.435645637 #> 19    19 response   hp  1.403006e-03 4.013438e-03  0.34957719 0.726656031 #> 20    20 response   hp  1.346032e-03 2.931206e-03  0.45920764 0.646085064 #> 21    21 response   hp  5.795830e-03 7.807259e-03  0.74236419 0.457866710 #> 22    22 response   hp  4.644015e-04 6.992967e-04  0.66409789 0.506627662 #> 23    23 response   hp  1.215863e-03 1.227051e-03  0.99088198 0.321743214 #> 24    24 response   hp  1.153492e-04 6.936387e-04  0.16629576 0.867924202 #> 25    25 response   hp  1.800542e-05 8.054465e-05  0.22354577 0.823110765 #> 26    26 response   hp  2.339616e-03 4.551005e-03  0.51408786 0.607190567 #> 27    27 response   hp  8.695693e-04 1.975180e-03  0.44024813 0.659757401 #> 28    28 response   hp  4.267318e-07 2.730750e-06  0.15626907 0.875820938 #> 29    29 response   hp  2.271717e-04 1.130909e-03  0.20087535 0.840796046 #> 30    30 response   hp  3.179746e-04 1.377287e-03  0.23087027 0.817415585 #> 31    31 response   hp  4.210965e-03 7.657335e-03  0.54992568 0.582370347 #> 32    32 response   hp  1.568271e-02 7.580280e-03  2.06888256 0.038557109 #> 33     1 response   wt -8.280303e-01 1.279527e+00 -0.64713787 0.517542720 #> 34     2 response   wt -2.253205e+00 1.362419e+00 -1.65382633 0.098162804 #> 35     3 response   wt -2.658461e-01 5.257923e-01 -0.50561042 0.613130163 #> 36     4 response   wt -3.378277e-01 3.501323e-01 -0.96485732 0.334616280 #> 37     5 response   wt -8.290222e-01 6.811943e-01 -1.21701272 0.223599375 #> 38     6 response   wt -3.137785e-02 5.512417e-02 -0.56922132 0.569205956 #> 39     7 response   wt -2.276351e+00 2.471021e+00 -0.92121870 0.356936257 #> 40     8 response   wt -2.816330e-02 5.696766e-02 -0.49437345 0.621042459 #> 41     9 response   wt -2.543997e-01 2.857380e-01 -0.89032510 0.373291345 #> 42    10 response   wt -8.609526e-02 1.157515e-01 -0.74379421 0.457000986 #> 43    11 response   wt -8.609526e-02 1.157515e-01 -0.74379421 0.457000986 #> 44    12 response   wt -6.494143e-04 3.310778e-03 -0.19615159 0.844491515 #> 45    13 response   wt -3.775892e-02 9.172958e-02 -0.41163299 0.680608450 #> 46    14 response   wt -2.081495e-02 5.862543e-02 -0.35504993 0.722552188 #> 47    15 response   wt -2.272851e-10 3.859969e-09 -0.05888264 0.953045588 #> 48    16 response   wt -1.629596e-11 3.217589e-10 -0.05064649 0.959607218 #> 49    17 response   wt -2.826816e-11 5.795693e-10 -0.04877442 0.961099064 #> 50    18 response   wt -8.521936e-01 8.229549e-01 -1.03552892 0.300421966 #> 51    19 response   wt -7.886841e-02 1.842446e-01 -0.42806372 0.668604733 #> 52    20 response   wt -8.870757e-02 1.769120e-01 -0.50142206 0.616074120 #> 53    21 response   wt -5.959105e-01 9.379795e-01 -0.63531295 0.525224328 #> 54    22 response   wt -1.272450e-01 1.577696e-01 -0.80652389 0.419940837 #> 55    23 response   wt -3.054369e-01 2.813059e-01 -1.08578197 0.277575463 #> 56    24 response   wt -6.569718e-02 2.831304e-01 -0.23203857 0.816508055 #> 57    25 response   wt -8.288936e-03 2.714899e-02 -0.30531290 0.760127851 #> 58    26 response   wt -1.612155e-01 2.841263e-01 -0.56740790 0.570437083 #> 59    27 response   wt -7.464417e-02 1.884619e-01 -0.39607029 0.692053177 #> 60    28 response   wt -3.204617e-05 2.159959e-04 -0.14836470 0.882054955 #> 61    29 response   wt -6.580439e-02 3.321209e-01 -0.19813386 0.842940336 #> 62    30 response   wt -5.339272e-02 2.402385e-01 -0.22224887 0.824120154 #> 63    31 response   wt -2.107162e+00 4.582922e+00 -0.45978567 0.645670073 #> 64    32 response   wt -2.024827e+00 7.486883e-01 -2.70449963 0.006840735 #>         conf.low     conf.high    predicted predicted_hi predicted_lo am  hp #> 1  -1.102325e-02  2.498970e-02 8.983110e-01 8.985086e-01 8.983110e-01  1 110 #> 2  -9.864245e-03  4.267249e-02 4.676447e-01 4.681089e-01 4.676447e-01  1 110 #> 3  -6.800752e-03  1.245766e-02 9.671038e-01 9.671839e-01 9.671038e-01  1  93 #> 4  -1.678321e-03  5.548072e-03 3.889558e-02 3.895034e-02 3.889558e-02  0 110 #> 5  -2.461058e-03  8.446778e-03 7.648382e-02 7.656852e-02 7.648382e-02  0 175 #> 6  -3.512456e-04  6.465378e-04 3.566962e-03 3.571140e-03 3.566962e-03  0 105 #> 7  -1.031604e-02  2.179737e-02 1.923979e-01 1.925604e-01 1.923979e-01  0 245 #> 8  -5.506142e-04  9.729546e-04 4.015235e-03 4.021211e-03 4.015235e-03  0  62 #> 9  -1.739703e-03  5.033655e-03 3.120992e-02 3.125653e-02 3.120992e-02  0  95 #> 10 -6.284766e-04  1.390460e-03 9.073330e-03 9.084112e-03 9.073330e-03  0 123 #> 11 -6.284766e-04  1.390460e-03 9.073330e-03 9.084112e-03 9.073330e-03  0 123 #> 12 -1.200989e-05  1.376198e-05 5.439236e-05 5.441715e-05 5.439236e-05  0 180 #> 13 -5.353448e-04  7.268609e-04 3.172383e-03 3.175093e-03 3.172383e-03  0 180 #> 14 -3.240040e-04  4.223112e-04 1.746319e-03 1.747710e-03 1.746319e-03  0 180 #> 15 -1.742390e-11  1.626645e-11 1.751508e-11 1.749870e-11 1.751508e-11  0 205 #> 16 -1.761224e-12  1.663181e-12 1.216933e-12 1.215546e-12 1.216933e-12  0 215 #> 17 -2.766080e-12  2.616815e-12 2.017342e-12 2.015230e-12 2.017342e-12  0 230 #> 18 -1.677116e-02  3.892346e-02 8.634101e-01 8.637236e-01 8.634101e-01  1  66 #> 19 -6.463187e-03  9.269200e-03 9.879847e-01 9.880244e-01 9.879847e-01  1  52 #> 20 -4.399027e-03  7.091091e-03 9.875007e-01 9.875388e-01 9.875007e-01  1  65 #> 21 -9.506117e-03  2.109778e-02 9.243530e-01 9.245170e-01 9.243530e-01  0  97 #> 22 -9.061949e-04  1.834998e-03 1.204113e-02 1.205428e-02 1.204113e-02  0 150 #> 23 -1.189113e-03  3.620838e-03 2.941871e-02 2.945312e-02 2.941871e-02  0 150 #> 24 -1.244158e-03  1.474856e-03 4.509574e-03 4.512838e-03 4.509574e-03  0 245 #> 25 -1.398592e-04  1.758700e-04 7.069764e-04 7.074860e-04 7.069764e-04  0 175 #> 26 -6.580190e-03  1.125942e-02 9.771760e-01 9.772422e-01 9.771760e-01  1  66 #> 27 -3.001712e-03  4.740851e-03 9.908948e-01 9.909194e-01 9.908948e-01  1  91 #> 28 -4.925440e-06  5.778904e-06 9.999965e-01 9.999965e-01 9.999965e-01  1 113 #> 29 -1.989368e-03  2.443712e-03 9.957403e-01 9.957467e-01 9.957403e-01  1 264 #> 30 -2.381458e-03  3.017407e-03 9.954493e-01 9.954583e-01 9.954493e-01  1 175 #> 31 -1.079714e-02  1.921907e-02 8.687038e-01 8.688229e-01 8.687038e-01  1 335 #> 32  8.256332e-04  3.053978e-02 6.593657e-01 6.598095e-01 6.593657e-01  1 109 #> 33 -3.335857e+00  1.679796e+00 8.983110e-01 8.979872e-01 8.983110e-01  1 110 #> 34 -4.923497e+00  4.170878e-01 4.676447e-01 4.667634e-01 4.676447e-01  1 110 #> 35 -1.296380e+00  7.646879e-01 9.671038e-01 9.669998e-01 9.671038e-01  1  93 #> 36 -1.024074e+00  3.484190e-01 3.889558e-02 3.876346e-02 3.889558e-02  0 110 #> 37 -2.164139e+00  5.060942e-01 7.648382e-02 7.615959e-02 7.648382e-02  0 175 #> 38 -1.394192e-01  7.666354e-02 3.566962e-03 3.554690e-03 3.566962e-03  0 105 #> 39 -7.119463e+00  2.566761e+00 1.923979e-01 1.915076e-01 1.923979e-01  0 245 #> 40 -1.398179e-01  8.349126e-02 4.015235e-03 4.004220e-03 4.015235e-03  0  62 #> 41 -8.144358e-01  3.056364e-01 3.120992e-02 3.111043e-02 3.120992e-02  0  95 #> 42 -3.129639e-01  1.407734e-01 9.073330e-03 9.039658e-03 9.073330e-03  0 123 #> 43 -3.129639e-01  1.407734e-01 9.073330e-03 9.039658e-03 9.073330e-03  0 123 #> 44 -7.138419e-03  5.839590e-03 5.439236e-05 5.413837e-05 5.439236e-05  0 180 #> 45 -2.175456e-01  1.420277e-01 3.172383e-03 3.157615e-03 3.172383e-03  0 180 #> 46 -1.357187e-01  9.408877e-02 1.746319e-03 1.738178e-03 1.746319e-03  0 180 #> 47 -7.792685e-09  7.338115e-09 1.751508e-11 1.742619e-11 1.751508e-11  0 205 #> 48 -6.469318e-10  6.143399e-10 1.216933e-12 1.210560e-12 1.216933e-12  0 215 #> 49 -1.164203e-09  1.107667e-09 2.017342e-12 2.006286e-12 2.017342e-12  0 230 #> 50 -2.465156e+00  7.607684e-01 8.634101e-01 8.630768e-01 8.634101e-01  1  66 #> 51 -4.399811e-01  2.822443e-01 9.879847e-01 9.879538e-01 9.879847e-01  1  52 #> 52 -4.354487e-01  2.580335e-01 9.875007e-01 9.874660e-01 9.875007e-01  1  65 #> 53 -2.434317e+00  1.242495e+00 9.243530e-01 9.241200e-01 9.243530e-01  0  97 #> 54 -4.364678e-01  1.819778e-01 1.204113e-02 1.199137e-02 1.204113e-02  0 150 #> 55 -8.567864e-01  2.459126e-01 2.941871e-02 2.929926e-02 2.941871e-02  0 150 #> 56 -6.206226e-01  4.892282e-01 4.509574e-03 4.483880e-03 4.509574e-03  0 245 #> 57 -6.149997e-02  4.492210e-02 7.069764e-04 7.037346e-04 7.069764e-04  0 175 #> 58 -7.180927e-01  3.956618e-01 9.771760e-01 9.771130e-01 9.771760e-01  1  66 #> 59 -4.440228e-01  2.947344e-01 9.908948e-01 9.908656e-01 9.908948e-01  1  91 #> 60 -4.553905e-04  3.912981e-04 9.999965e-01 9.999965e-01 9.999965e-01  1 113 #> 61 -7.167493e-01  5.851405e-01 9.957403e-01 9.957145e-01 9.957403e-01  1 264 #> 62 -5.242514e-01  4.174660e-01 9.954493e-01 9.954285e-01 9.954493e-01  1 175 #> 63 -1.108952e+01  6.875201e+00 8.687038e-01 8.678796e-01 8.687038e-01  1 335 #> 64 -3.492230e+00 -5.574252e-01 6.593657e-01 6.585738e-01 6.593657e-01  1 109 #>       wt       eps #> 1  2.620 0.0283000 #> 2  2.875 0.0283000 #> 3  2.320 0.0283000 #> 4  3.215 0.0283000 #> 5  3.440 0.0283000 #> 6  3.460 0.0283000 #> 7  3.570 0.0283000 #> 8  3.190 0.0283000 #> 9  3.150 0.0283000 #> 10 3.440 0.0283000 #> 11 3.440 0.0283000 #> 12 4.070 0.0283000 #> 13 3.730 0.0283000 #> 14 3.780 0.0283000 #> 15 5.250 0.0283000 #> 16 5.424 0.0283000 #> 17 5.345 0.0283000 #> 18 2.200 0.0283000 #> 19 1.615 0.0283000 #> 20 1.835 0.0283000 #> 21 2.465 0.0283000 #> 22 3.520 0.0283000 #> 23 3.435 0.0283000 #> 24 3.840 0.0283000 #> 25 3.845 0.0283000 #> 26 1.935 0.0283000 #> 27 2.140 0.0283000 #> 28 1.513 0.0283000 #> 29 3.170 0.0283000 #> 30 2.770 0.0283000 #> 31 3.570 0.0283000 #> 32 2.780 0.0283000 #> 33 2.620 0.0003911 #> 34 2.875 0.0003911 #> 35 2.320 0.0003911 #> 36 3.215 0.0003911 #> 37 3.440 0.0003911 #> 38 3.460 0.0003911 #> 39 3.570 0.0003911 #> 40 3.190 0.0003911 #> 41 3.150 0.0003911 #> 42 3.440 0.0003911 #> 43 3.440 0.0003911 #> 44 4.070 0.0003911 #> 45 3.730 0.0003911 #> 46 3.780 0.0003911 #> 47 5.250 0.0003911 #> 48 5.424 0.0003911 #> 49 5.345 0.0003911 #> 50 2.200 0.0003911 #> 51 1.615 0.0003911 #> 52 1.835 0.0003911 #> 53 2.465 0.0003911 #> 54 3.520 0.0003911 #> 55 3.435 0.0003911 #> 56 3.840 0.0003911 #> 57 3.845 0.0003911 #> 58 1.935 0.0003911 #> 59 2.140 0.0003911 #> 60 1.513 0.0003911 #> 61 3.170 0.0003911 #> 62 2.770 0.0003911 #> 63 3.570 0.0003911 #> 64 2.780 0.0003911  # hypothesis test: is the `hp` marginal effect at the mean equal to the `drat` marginal effect mod <- lm(mpg ~ wt + drat, data = mtcars)  marginaleffects(     mod,     newdata = \"mean\",     hypothesis = \"wt = drat\") #>       type    term      dydx std.error statistic      p.value conf.low #> 1 response wt=drat -6.225381  1.051769 -5.918963 3.239775e-09 -8.28681 #>   conf.high #> 1 -4.163952  # same hypothesis test using row indices marginaleffects(     mod,     newdata = \"mean\",     hypothesis = \"b1 - b2 = 0\") #>       type    term      dydx std.error statistic      p.value conf.low #> 1 response b1-b2=0 -6.225381  1.051769 -5.918963 3.239775e-09 -8.28681 #>   conf.high #> 1 -4.163952  # same hypothesis test using numeric vector of weights marginaleffects(     mod,     newdata = \"mean\",     hypothesis = c(1, -1)) #>       type   term      dydx std.error statistic      p.value conf.low conf.high #> 1 response custom -6.225381  1.051769 -5.918963 3.239775e-09 -8.28681 -4.163952  # two custom contrasts using a matrix of weights lc <- matrix(c(     1, -1,     2, 3),     ncol = 2) colnames(lc) <- c(\"Contrast A\", \"Contrast B\") marginaleffects(     mod,     newdata = \"mean\",     hypothesis = lc) #>       type       term      dydx std.error  statistic      p.value  conf.low #> 1 response Contrast A -6.225381  1.051769 -5.9189632 3.239775e-09  -8.28681 #> 2 response Contrast B -5.238308  5.623757 -0.9314607 3.516153e-01 -16.26067 #>   conf.high #> 1 -4.163952 #> 2  5.784052"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/marginalmeans.html","id":null,"dir":"Reference","previous_headings":"","what":"Marginal Means — marginalmeans","title":"Marginal Means — marginalmeans","text":"Marginal means adjusted predictions, averaged across grid categorical predictors, holding numeric predictors means. learn , read marginal means vignette, visit package website, scroll page full list vignettes: https://vincentarelbundock.github.io/marginaleffects/articles/marginalmeans.html https://vincentarelbundock.github.io/marginaleffects/","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/marginalmeans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Marginal Means — marginalmeans","text":"","code":"marginalmeans(   model,   variables = NULL,   variables_grid = NULL,   vcov = TRUE,   conf_level = 0.95,   type = NULL,   transform_post = NULL,   cross = FALSE,   hypothesis = NULL,   wts = \"equal\",   by = NULL,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/marginalmeans.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Marginal Means — marginalmeans","text":"model Model object variables character vector Categorical predictors compute marginal means. NULL calculates marginal means logical, character, factor variables dataset used fit model. Set cross=TRUE compute marginal means combinations predictors specified variables argument. variables_grid character vector Categorical predictors used construct prediction grid adjusted predictions averaged (character vector). NULL creates grid combinations categorical predictors. grid can large many variables many response levels, advisable select limited number variables variables variables_grid arguments. vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) conf_level numeric value 0 1. Confidence level use build confidence interval. type string indicates type (scale) predictions used compute marginal effects contrasts. can differ based model type, typically string : \"response\", \"link\", \"probs\", \"zero\". unsupported string entered, model-specific list acceptable values returned error message. type NULL, default value used. default first model-related row marginaleffects:::type_dictionary dataframe. type NULL default value \"response\", function tries compute marginal means link scale backtransforming using inverse link function. transform_post (experimental) function applied unit-level adjusted predictions confidence intervals just function returns results. bayesian models, function applied individual draws posterior distribution, computing summaries. cross TRUE FALSE FALSE (default): Marginal means computed predictor individually. TRUE: Marginal means computed combination predictors specified variables argument. hypothesis specify hypothesis test custom contrast using vector, matrix, string, string formula. String: \"pairwise\": pairwise differences estimates row. \"reference\": differences estimates row estimate first row. \"sequential\": difference estimate estimate next row. \"revpairwise\", \"revreference\", \"revsequential\": inverse corresponding hypotheses, described . String formula specify linear non-linear hypothesis tests. term column uniquely identifies rows, terms can used formula. Otherwise, use b1, b2, etc. identify position parameter. Examples: hp = drat hp + drat = 12 b1 + b2 + b3 = 0 Numeric vector: Weights compute linear combination (custom contrast ) estimates. Length equal number rows generated function call, without hypothesis argument. Numeric matrix: column vector weights, describe , used compute distinct linear combination (contrast ) estimates. column names matrix used labels output. See Examples section vignette: https://vincentarelbundock.github.io/marginaleffects/articles/hypothesis.html wts character value. Weights use averaging. \"equal\": combination variables variables_grid gets equal weight. \"cells\": combination values variables variables_grid gets weight proportional frequency original data. \"proportional\": combination values variables variables_grid -- except variables argument -- gets weight proportional frequency original data. Collapse marginal means categories. Data frame column group labels, merging columns shared newdata data frame produced calling function without argument. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/marginalmeans.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Marginal Means — marginalmeans","text":"Data frame marginal means one row per variable-value combination.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/marginalmeans.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Marginal Means — marginalmeans","text":"function begins calling predictions function obtain grid predictors, adjusted predictions cell. grid includes combinations categorical variables listed variables variables_grid arguments, combinations categorical variables used fit model variables_grid NULL. prediction grid, numeric variables held means. constructing grid filling grid adjusted predictions, marginalmeans computes marginal means variables listed variables argument, average across categories grid. marginalmeans can compute standard errors linear models, predictions link scale, , type argument set \"link\". marginaleffects website compares output function popular emmeans package, provides similar advanced functionality: https://vincentarelbundock.github.io/marginaleffects/","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/marginalmeans.html","id":"vignettes-and-documentation","dir":"Reference","previous_headings":"","what":"Vignettes and documentation","title":"Marginal Means — marginalmeans","text":"Vignettes: Adjusted Predictions Contrasts Marginal Effects Marginal Means Hypothesis Tests Custom Contrasts using Delta Method Case studies: Bayesian Analyses brms Causal Inference g-Formula Elasticity Experiments Generalized Additive Models Mixed effects models Multinomial Logit Discrete Choice Models Multiple Imputation Plots: interactions, predictions, contrasts, slopes Python NumPyro models marginaleffects Unit-level contrasts logistic regressions Tips technical notes: 71 Supported Classes Models Index Functions Documentation Extending marginaleffects: add new models modify existing ones Standard Errors Confidence Intervals Tables Plots Performance Alternative Software Frequently Asked Questions","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/marginalmeans.html","id":"model-specific-arguments","dir":"Reference","previous_headings":"","what":"Model-Specific Arguments","title":"Marginal Means — marginalmeans","text":"model types allow model-specific arguments modify nature marginal effects, predictions, marginal means, contrasts.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/marginalmeans.html","id":"bayesian-posterior-summaries","dir":"Reference","previous_headings":"","what":"Bayesian posterior summaries","title":"Marginal Means — marginalmeans","text":"default, credible intervals bayesian models built equal-tailed intervals. can changed highest density interval setting global option: options(\"marginaleffects_posterior_interval\" = \"eti\") options(\"marginaleffects_posterior_interval\" = \"hdi\") default, center posterior distribution bayesian models identified median. Users can use different summary function setting global option: options(\"marginaleffects_posterior_center\" = mean) options(\"marginaleffects_posterior_center\" = median) estimates averaged using argument, tidy() function, summary() function, posterior distribution marginalized twice . First, take average across units within iteration MCMC chain, according user requested argument tidy()/summary() functions. , identify center resulting posterior using function supplied \"marginaleffects_posterior_center\" option (median default).","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/marginalmeans.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Marginal Means — marginalmeans","text":"","code":"library(marginaleffects)  # simple marginal means for each level of `cyl` dat <- mtcars dat$carb <- factor(dat$carb) dat$cyl <- factor(dat$cyl) dat$am <- as.logical(dat$am) mod <- lm(mpg ~ carb + cyl + am, dat)  marginalmeans(   mod,   variables = \"cyl\") #>   term value marginalmean std.error conf.low conf.high      p.value statistic #> 1  cyl     4     23.11334  1.658224 19.86328  26.36340 3.690579e-44  13.93861 #> 2  cyl     6     20.38477  1.337106 17.76409  23.00545 1.765453e-52  15.24544 #> 3  cyl     8     16.21082  1.072551 14.10866  18.31299 1.304150e-51  15.11427  # collapse levels of cyl by averaging by <- data.frame(   cyl = c(4, 6, 8),   by = c(\"4 & 6\", \"4 & 6\", \"8\")) marginalmeans(mod,   variables = \"cyl\",   by = by) #>      by marginalmean std.error conf.low conf.high      p.value statistic #> 1 4 & 6     21.74905  1.132084 19.53021  23.96790 2.964293e-82  19.21152 #> 2     8     16.21082  1.072551 14.10866  18.31299 1.304150e-51  15.11427  # pairwise differences between collapsed levels marginalmeans(mod,   variables = \"cyl\",   by = by,   hypothesis = \"pairwise\") #>        term marginalmean std.error conf.low conf.high      p.value statistic #> 1 4 & 6 - 8     5.538228  1.513052   2.5727  8.503755 0.0002519178  3.660302  # cross marginalmeans(mod,   variables = c(\"cyl\", \"carb\"),   cross = TRUE) #>    cyl carb marginalmean std.error  conf.low conf.high       p.value statistic #> 1    6    4     19.14907  1.338478 16.525705  21.77244  1.990073e-46 14.306600 #> 2    6    1     23.08862  1.765271 19.628756  26.54849  4.320526e-39 13.079362 #> 3    6    2     22.85979  1.867465 19.199624  26.51995  1.875206e-34 12.241080 #> 4    6    3     22.61071  2.365152 17.975102  27.24633  1.178225e-21  9.559942 #> 5    6    6     17.56323  3.003716 11.676053  23.45040  5.000145e-09  5.847167 #> 6    6    8     17.03717  3.481207 10.214129  23.86021  9.878645e-07  4.894041 #> 7    4    4     21.87765  1.901048 18.151659  25.60363  1.199563e-30 11.508200 #> 8    4    1     25.81720  1.263909 23.339980  28.29441  9.729029e-93 20.426468 #> 9    4    2     25.58836  1.166714 23.301643  27.87508 1.286605e-106 21.931995 #> 10   4    3     25.33929  2.365152 20.703673  29.97490  8.787848e-27 10.713598 #> 11   4    6     20.29180  3.766424 12.909744  27.67385  7.142425e-08  5.387551 #> 12   4    8     19.76574  3.814283 12.289884  27.24160  2.194796e-07  5.182034 #> 13   8    4     14.97513  1.195291 12.632406  17.31786  5.217536e-36 12.528445 #> 14   8    1     18.91468  1.942030 15.108373  22.72099  2.042705e-22  9.739643 #> 15   8    2     18.68585  1.570513 15.607698  21.76399  1.213213e-32 11.897929 #> 16   8    3     18.43677  1.830964 14.848149  22.02540  7.540931e-24 10.069436 #> 17   8    6     13.38929  3.356162  6.811330  19.96724  6.622284e-05  3.989464 #> 18   8    8     12.86323  3.003716  6.976053  18.75040  1.848561e-05  4.282439  # collapsed cross by <- expand.grid(   cyl = unique(mtcars$cyl),   carb = unique(mtcars$carb)) by$by <- ifelse(   by$cyl == 4,   paste(\"Control:\", by$carb),   paste(\"Treatment:\", by$carb))   # Convert numeric variables to categorical before fitting the model dat <- mtcars dat$am <- as.logical(dat$am) dat$carb <- as.factor(dat$carb) mod <- lm(mpg ~ hp + am + carb, data = dat)  # Compute and summarize marginal means mm <- marginalmeans(mod) summary(mm) #>   Term Value  Mean Std. Error z value   Pr(>|z|) 2.5 % 97.5 % #> 1   am FALSE 17.87      1.244  14.366 < 2.22e-16 15.43  20.31 #> 2   am  TRUE 23.11      0.974  23.724 < 2.22e-16 21.20  25.02 #> 3 carb     1 21.99      1.345  16.350 < 2.22e-16 19.35  24.63 #> 4 carb     2 21.48      1.025  20.955 < 2.22e-16 19.47  23.49 #> 5 carb     3 20.55      1.780  11.549 < 2.22e-16 17.06  24.04 #> 6 carb     4 18.82      1.042  18.065 < 2.22e-16 16.77  20.86 #> 7 carb     6 18.47      3.019   6.118 9.4743e-10 12.55  24.39 #> 8 carb     8 21.62      4.055   5.332 9.6936e-08 13.68  29.57 #>  #> Model type:  lm  #> Prediction type:  response  #> Results averaged over levels of: am, carb   # Contrast between marginal means (carb2 - carb1), or \"is the 1st marginal means equal to the 2nd?\" # see the vignette on \"Hypothesis Tests and Custom Contrasts\" on the `marginaleffects` website. lc <- c(-1, 1, 0, 0, 0, 0) marginalmeans(mod, variables = \"carb\", hypothesis = \"b2 = b1\") #>    term marginalmean std.error  conf.low conf.high   p.value  statistic #> 1 b2=b1   -0.5142619  1.477885 -3.410863   2.38234 0.7278616 -0.3479715  marginalmeans(mod, variables = \"carb\", hypothesis = lc) #>     term marginalmean std.error  conf.low conf.high   p.value  statistic #> 1 custom   -0.5142619  1.477885 -3.410863   2.38234 0.7278616 -0.3479715  # Multiple custom contrasts lc <- matrix(c(     -2, 1, 1, 0, -1, 1,     -1, 1, 0, 0, 0, 0     ),   ncol = 2,   dimnames = list(NULL, c(\"A\", \"B\"))) marginalmeans(mod, variables = \"carb\", hypothesis = lc) #>   term marginalmean std.error   conf.low conf.high   p.value  statistic #> 1    A    1.1989451  6.149643 -10.854133  13.25202 0.8454229  0.1949618 #> 2    B   -0.5142619  1.477885  -3.410863   2.38234 0.7278616 -0.3479715"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/mean_or_mode.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the mode or mean of x — mean_or_mode","title":"Compute the mode or mean of x — mean_or_mode","text":"Compute mode mean x","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/mean_or_mode.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the mode or mean of x — mean_or_mode","text":"","code":"mean_or_mode(x)  # S3 method for default mean_or_mode(x)  # S3 method for character mean_or_mode(x)  # S3 method for factor mean_or_mode(x)  # S3 method for logical mean_or_mode(x)  # S3 method for data.frame mean_or_mode(x)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/mean_or_mode.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the mode or mean of x — mean_or_mode","text":"x extract mean mode vector data.frame x depending type","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/mean_or_mode.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the mode or mean of x — mean_or_mode","text":"numeric vector","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/meffects.html","id":null,"dir":"Reference","previous_headings":"","what":"meffects() is a shortcut to marginaleffects() — meffects","title":"meffects() is a shortcut to marginaleffects() — meffects","text":"Partial derivative (slope) regression equation respect regressor interest. tidy() summary() functions can used aggregate summarize output marginaleffects(). learn , read marginal effects vignette, visit package website, scroll page full list vignettes: https://vincentarelbundock.github.io/marginaleffects/articles/marginaleffects.html https://vincentarelbundock.github.io/marginaleffects/","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/meffects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"meffects() is a shortcut to marginaleffects() — meffects","text":"","code":"meffects(   model,   newdata = NULL,   variables = NULL,   vcov = TRUE,   conf_level = 0.95,   type = NULL,   slope = \"dydx\",   by = NULL,   wts = NULL,   hypothesis = NULL,   eps = NULL,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/meffects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"meffects() is a shortcut to marginaleffects() — meffects","text":"model Model object newdata NULL, data frame, string, datagrid() call. Determines predictor values compute marginal effects. NULL (default): Unit-level marginal effects observed value original dataset. data frame: Unit-level marginal effects row newdata data frame. string: \"mean\": Marginal Effects Mean. Marginal effects predictor held mean mode. \"median\": Marginal Effects Median. Marginal effects predictor held median mode. \"marginalmeans\": Marginal Effects Marginal Means. See Details section . \"tukey\": Marginal Effects Tukey's 5 numbers. \"grid\": Marginal Effects grid representative numbers (Tukey's 5 numbers unique values categorical predictors). datagrid() call specify custom grid regressors. example: newdata = datagrid(cyl = c(4, 6)): cyl variable equal 4 6 regressors fixed means modes. See Examples section datagrid() documentation. variables NULL character vector. subset variables compute marginal effects. NULL: compute contrasts variables model object (can slow). Character vector: subset variables (usually faster). vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) conf_level numeric value 0 1. Confidence level use build confidence interval. type string indicates type (scale) predictions used compute marginal effects contrasts. can differ based model type, typically string : \"response\", \"link\", \"probs\", \"zero\". unsupported string entered, model-specific list acceptable values returned error message. type NULL, default value used. default first model-related row marginaleffects:::type_dictionary dataframe. slope string indicates type slope (semi-)elasticity compute: \"dydx\": dY/dX \"eyex\": dY/dX * Y / X \"eydx\": dY/dX * Y \"dyex\": dY/dX / X Character vector variable names compute group-wise estimates. wts string numeric: weights use computing average contrasts marginaleffects. weights affect averaging tidy() summary(), unit-level estimates . string: column name weights variable newdata. supplying column name wts, recommended supply original data (including weights variable) explicitly newdata. numeric: vector length equal number rows original data newdata (supplied). hypothesis specify hypothesis test custom contrast using vector, matrix, string, string formula. String: \"pairwise\": pairwise differences estimates row. \"reference\": differences estimates row estimate first row. \"sequential\": difference estimate estimate next row. \"revpairwise\", \"revreference\", \"revsequential\": inverse corresponding hypotheses, described . String formula specify linear non-linear hypothesis tests. term column uniquely identifies rows, terms can used formula. Otherwise, use b1, b2, etc. identify position parameter. Examples: hp = drat hp + drat = 12 b1 + b2 + b3 = 0 Numeric vector: Weights compute linear combination (custom contrast ) estimates. Length equal number rows generated function call, without hypothesis argument. Numeric matrix: column vector weights, describe , used compute distinct linear combination (contrast ) estimates. column names matrix used labels output. See Examples section vignette: https://vincentarelbundock.github.io/marginaleffects/articles/hypothesis.html eps NULL numeric value determines step size use calculating numerical derivatives: (f(x+eps)-f(x))/eps. eps NULL, step size 0.0001 multiplied difference maximum minimum values variable respect taking derivative. Changing eps may necessary avoid numerical problems certain models. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/meffects.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"meffects() is a shortcut to marginaleffects() — meffects","text":"data.frame one row per observation (per term/group) several columns: rowid: row number newdata data frame type: prediction type, defined type argument group: (optional) value grouped outcome (e.g., categorical outcome models) term: variable whose marginal effect computed dydx: marginal effect term outcome given combination regressor values std.error: standard errors computed via delta method.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/meffects.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"meffects() is a shortcut to marginaleffects() — meffects","text":"\"marginal effect\" partial derivative regression equation respect variable model. function uses automatic differentiation compute marginal effects vast array models, including non-linear models transformations (e.g., polynomials). Uncertainty estimates computed using delta method. newdata argument can used control kind marginal effects report: Average Marginal Effects (AME) Group-Average Marginal Effects (G-AME) Marginal Effects Mean (MEM) Marginal Effects User-Specified values (aka Marginal Effects Representative values, MER). See marginaleffects vignette worked-examples kind marginal effect. Numerical derivatives marginaleffects function calculated using simple epsilon difference approach: \\(\\partial Y / \\partial X = (f(X + \\varepsilon) - f(X)) / \\varepsilon\\), f predict() method associated model class, \\(\\varepsilon\\) determined eps argument. Warning: models particularly sensitive eps, good practice try different values argument. Standard errors marginal effects obtained using Delta method. See \"Standard Errors\" vignette package website details (link ).","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/meffects.html","id":"vignettes-and-documentation","dir":"Reference","previous_headings":"","what":"Vignettes and documentation","title":"meffects() is a shortcut to marginaleffects() — meffects","text":"Vignettes: Adjusted Predictions Contrasts Marginal Effects Marginal Means Hypothesis Tests Custom Contrasts using Delta Method Case studies: Bayesian Analyses brms Causal Inference g-Formula Elasticity Experiments Generalized Additive Models Mixed effects models Multinomial Logit Discrete Choice Models Multiple Imputation Plots: interactions, predictions, contrasts, slopes Python NumPyro models marginaleffects Unit-level contrasts logistic regressions Tips technical notes: 71 Supported Classes Models Index Functions Documentation Extending marginaleffects: add new models modify existing ones Standard Errors Confidence Intervals Tables Plots Performance Alternative Software Frequently Asked Questions","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/meffects.html","id":"model-specific-arguments","dir":"Reference","previous_headings":"","what":"Model-Specific Arguments","title":"meffects() is a shortcut to marginaleffects() — meffects","text":"model types allow model-specific arguments modify nature marginal effects, predictions, marginal means, contrasts.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/meffects.html","id":"bayesian-posterior-summaries","dir":"Reference","previous_headings":"","what":"Bayesian posterior summaries","title":"meffects() is a shortcut to marginaleffects() — meffects","text":"default, credible intervals bayesian models built equal-tailed intervals. can changed highest density interval setting global option: options(\"marginaleffects_posterior_interval\" = \"eti\") options(\"marginaleffects_posterior_interval\" = \"hdi\") default, center posterior distribution bayesian models identified median. Users can use different summary function setting global option: options(\"marginaleffects_posterior_center\" = mean) options(\"marginaleffects_posterior_center\" = median) estimates averaged using argument, tidy() function, summary() function, posterior distribution marginalized twice . First, take average across units within iteration MCMC chain, according user requested argument tidy()/summary() functions. , identify center resulting posterior using function supplied \"marginaleffects_posterior_center\" option (median default).","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/meffects.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"meffects() is a shortcut to marginaleffects() — meffects","text":"","code":"mod <- glm(am ~ hp * wt, data = mtcars, family = binomial) mfx <- marginaleffects(mod) head(mfx) #>   rowid     type term         dydx    std.error statistic   p.value #> 1     1 response   hp 0.0069832251 0.0058793768 1.1877492 0.2349322 #> 2     2 response   hp 0.0164041227 0.0133880594 1.2252801 0.2204697 #> 3     3 response   hp 0.0028284517 0.0037506567 0.7541217 0.4507761 #> 4     4 response   hp 0.0019348755 0.0024508961 0.7894564 0.4298453 #> 5     5 response   hp 0.0029928602 0.0033775105 0.8861142 0.3755560 #> 6     6 response   hp 0.0001476461 0.0003452784 0.4276146 0.6689317 #>        conf.low    conf.high   predicted predicted_hi predicted_lo am  hp    wt #> 1 -0.0045401417 0.0185065919 0.898311019   0.89850864  0.898311019  1 110 2.620 #> 2 -0.0098359916 0.0426442370 0.467644655   0.46810889  0.467644655  1 110 2.875 #> 3 -0.0045227004 0.0101796038 0.967103810   0.96718386  0.967103810  1  93 2.320 #> 4 -0.0028687925 0.0067385435 0.038895584   0.03895034  0.038895584  0 110 3.215 #> 5 -0.0036269388 0.0096126591 0.076483825   0.07656852  0.076483825  0 175 3.440 #> 6 -0.0005290872 0.0008243794 0.003566962   0.00357114  0.003566962  0 105 3.460 #>      eps #> 1 0.0283 #> 2 0.0283 #> 3 0.0283 #> 4 0.0283 #> 5 0.0283 #> 6 0.0283  # Average Marginal Effect (AME) summary(mfx) #>   Term    Effect Std. Error z value   Pr(>|z|)     2.5 %    97.5 % #> 1   hp  0.002653   0.001939   1.368    0.17121 -0.001147  0.006452 #> 2   wt -0.435783   0.102063  -4.270 1.9568e-05 -0.635822 -0.235744 #>  #> Model type:  glm  #> Prediction type:  response  tidy(mfx) #>       type term     estimate   std.error statistic      p.value     conf.low #> 1 response   hp  0.002652526 0.001938531  1.368318 1.712127e-01 -0.001146925 #> 2 response   wt -0.435783199 0.102062710 -4.269759 1.956841e-05 -0.635822435 #>      conf.high #> 1  0.006451977 #> 2 -0.235743963 plot(mfx)    # Marginal Effect at the Mean (MEM) marginaleffects(mod, newdata = datagrid()) #>   rowid     type term         dydx   std.error statistic   p.value     conf.low #> 1     1 response   hp  0.008526944 0.007849817  1.086260 0.2773639 -0.006858415 #> 2     1 response   wt -1.744526869 1.586306474 -1.099741 0.2714448 -4.853630428 #>   conf.high predicted predicted_hi predicted_lo      am       hp      wt #> 1 0.0239123  0.208598    0.2088393     0.208598 0.40625 146.6875 3.21725 #> 2 1.3645767  0.208598    0.2079157     0.208598 0.40625 146.6875 3.21725 #>         eps #> 1 0.0283000 #> 2 0.0003911  # Marginal Effect at User-Specified Values # Variables not explicitly included in `datagrid()` are held at their means marginaleffects(mod,                 newdata = datagrid(hp = c(100, 110))) #>   rowid     type term         dydx   std.error  statistic   p.value #> 1     1 response   hp  0.001166673 0.001754130  0.6651008 0.5059860 #> 2     2 response   hp  0.001895403 0.002416124  0.7844807 0.4327581 #> 3     1 response   wt -0.194677637 0.307227707 -0.6336591 0.5263033 #> 4     2 response   wt -0.331535828 0.436074375 -0.7602736 0.4470911 #>       conf.low   conf.high  predicted predicted_hi predicted_lo      am      wt #> 1 -0.002271359 0.004604705 0.02311544   0.02314846   0.02311544 0.40625 3.21725 #> 2 -0.002840114 0.006630920 0.03814134   0.03819498   0.03814134 0.40625 3.21725 #> 3 -0.796832879 0.407477604 0.02311544   0.02303930   0.02311544 0.40625 3.21725 #> 4 -1.186225897 0.523154240 0.03814134   0.03801168   0.03814134 0.40625 3.21725 #>    hp       eps #> 1 100 0.0283000 #> 2 110 0.0283000 #> 3 100 0.0003911 #> 4 110 0.0003911  # Group-Average Marginal Effects (G-AME) # Calculate marginal effects for each observation, and then take the average # marginal effect within each subset of observations with different observed # values for the `cyl` variable: mod2 <- lm(mpg ~ hp * cyl, data = mtcars) mfx2 <- marginaleffects(mod2, variables = \"hp\", by = \"cyl\") summary(mfx2) #>   Term    Contrast cyl   Effect Std. Error z value  Pr(>|z|)    2.5 %   97.5 % #> 1   hp mean(dY/dX)   6 -0.05226    0.02041 -2.5608 0.0104442 -0.09225 -0.01226 #> 2   hp mean(dY/dX)   4 -0.09173    0.03533 -2.5964 0.0094216 -0.16098 -0.02248 #> 3   hp mean(dY/dX)   8 -0.01278    0.01434 -0.8912 0.3727993 -0.04089  0.01533 #>  #> Model type:  lm  #> Prediction type:  response   # Marginal Effects at User-Specified Values (counterfactual) # Variables not explicitly included in `datagrid()` are held at their # original values, and the whole dataset is duplicated once for each # combination of the values in `datagrid()` mfx <- marginaleffects(mod,                        newdata = datagrid(hp = c(100, 110),                                           grid_type = \"counterfactual\")) head(mfx) #>   rowid     type term         dydx    std.error statistic   p.value #> 1     1 response   hp 0.0120345428 0.0099871557 1.2050020 0.2282025 #> 2     2 response   hp 0.0141605125 0.0108083854 1.3101413 0.1901480 #> 3     3 response   hp 0.0015641805 0.0022024745 0.7101923 0.4775849 #> 4     4 response   hp 0.0011906427 0.0017804554 0.6687293 0.5036682 #> 5     5 response   hp 0.0001454839 0.0003410785 0.4265408 0.6697138 #> 6     6 response   hp 0.0001201299 0.0002911014 0.4126737 0.6798457 #>        conf.low    conf.high rowidcf   predicted predicted_hi predicted_lo am #> 1 -0.0075399227 0.0316090083       1 0.804313722  0.804654300  0.804313722  1 #> 2 -0.0070235336 0.0353445586       2 0.312493620  0.312894363  0.312493620  1 #> 3 -0.0027525902 0.0058809511       3 0.982084695  0.982128961  0.982084695  1 #> 4 -0.0022989857 0.0046802710       4 0.023558258  0.023591954  0.023558258  0 #> 5 -0.0005230176 0.0008139854       5 0.003445112  0.003449229  0.003445112  0 #> 6 -0.0004504183 0.0006906781       6 0.002900259  0.002903658  0.002900259  0 #>      wt  hp    eps #> 1 2.620 100 0.0283 #> 2 2.875 100 0.0283 #> 3 2.320 100 0.0283 #> 4 3.215 100 0.0283 #> 5 3.440 100 0.0283 #> 6 3.460 100 0.0283  # Heteroskedasticity robust standard errors marginaleffects(mod, vcov = sandwich::vcovHC(mod)) #>    rowid     type term          dydx    std.error   statistic     p.value #> 1      1 response   hp  6.983225e-03 9.187144e-03  0.76010842 0.447189783 #> 2      2 response   hp  1.640412e-02 1.340247e-02  1.22396222 0.220966481 #> 3      3 response   hp  2.828452e-03 4.912949e-03  0.57571361 0.564808772 #> 4      4 response   hp  1.934876e-03 1.843501e-03  1.04956553 0.293917911 #> 5      5 response   hp  2.992860e-03 2.782662e-03  1.07553836 0.282133766 #> 6      6 response   hp  1.476461e-04 2.545412e-04  0.58004785 0.561882353 #> 7      7 response   hp  5.740668e-03 8.192346e-03  0.70073547 0.483468119 #> 8      8 response   hp  2.111702e-04 3.886726e-04  0.54331124 0.586915530 #> 9      9 response   hp  1.646976e-03 1.727929e-03  0.95314999 0.340514082 #> 10    10 response   hp  3.809918e-04 5.150443e-04  0.73972622 0.459466136 #> 11    11 response   hp  3.809918e-04 5.150443e-04  0.73972622 0.459466136 #> 12    12 response   hp  8.760463e-07 6.574577e-06  0.13324755 0.893997607 #> 13    13 response   hp  9.575809e-05 3.219972e-04  0.29738799 0.766170309 #> 14    14 response   hp  4.915362e-05 1.903900e-04  0.25817324 0.796273208 #> 15    15 response   hp -5.787254e-13 8.594637e-12 -0.06733565 0.946314499 #> 16    16 response   hp -4.902183e-14 8.735888e-13 -0.05611545 0.955249833 #> 17    17 response   hp -7.463248e-14 1.373213e-12 -0.05434881 0.956657263 #> 18    18 response   hp  1.107615e-02 1.420807e-02  0.77956725 0.435645637 #> 19    19 response   hp  1.403006e-03 4.013438e-03  0.34957719 0.726656031 #> 20    20 response   hp  1.346032e-03 2.931206e-03  0.45920764 0.646085064 #> 21    21 response   hp  5.795830e-03 7.807259e-03  0.74236419 0.457866710 #> 22    22 response   hp  4.644015e-04 6.992967e-04  0.66409789 0.506627662 #> 23    23 response   hp  1.215863e-03 1.227051e-03  0.99088198 0.321743214 #> 24    24 response   hp  1.153492e-04 6.936387e-04  0.16629576 0.867924202 #> 25    25 response   hp  1.800542e-05 8.054465e-05  0.22354577 0.823110765 #> 26    26 response   hp  2.339616e-03 4.551005e-03  0.51408786 0.607190567 #> 27    27 response   hp  8.695693e-04 1.975180e-03  0.44024813 0.659757401 #> 28    28 response   hp  4.267318e-07 2.730750e-06  0.15626907 0.875820938 #> 29    29 response   hp  2.271717e-04 1.130909e-03  0.20087535 0.840796046 #> 30    30 response   hp  3.179746e-04 1.377287e-03  0.23087027 0.817415585 #> 31    31 response   hp  4.210965e-03 7.657335e-03  0.54992568 0.582370347 #> 32    32 response   hp  1.568271e-02 7.580280e-03  2.06888256 0.038557109 #> 33     1 response   wt -8.280303e-01 1.279527e+00 -0.64713787 0.517542720 #> 34     2 response   wt -2.253205e+00 1.362419e+00 -1.65382633 0.098162804 #> 35     3 response   wt -2.658461e-01 5.257923e-01 -0.50561042 0.613130163 #> 36     4 response   wt -3.378277e-01 3.501323e-01 -0.96485732 0.334616280 #> 37     5 response   wt -8.290222e-01 6.811943e-01 -1.21701272 0.223599375 #> 38     6 response   wt -3.137785e-02 5.512417e-02 -0.56922132 0.569205956 #> 39     7 response   wt -2.276351e+00 2.471021e+00 -0.92121870 0.356936257 #> 40     8 response   wt -2.816330e-02 5.696766e-02 -0.49437345 0.621042459 #> 41     9 response   wt -2.543997e-01 2.857380e-01 -0.89032510 0.373291345 #> 42    10 response   wt -8.609526e-02 1.157515e-01 -0.74379421 0.457000986 #> 43    11 response   wt -8.609526e-02 1.157515e-01 -0.74379421 0.457000986 #> 44    12 response   wt -6.494143e-04 3.310778e-03 -0.19615159 0.844491515 #> 45    13 response   wt -3.775892e-02 9.172958e-02 -0.41163299 0.680608450 #> 46    14 response   wt -2.081495e-02 5.862543e-02 -0.35504993 0.722552188 #> 47    15 response   wt -2.272851e-10 3.859969e-09 -0.05888264 0.953045588 #> 48    16 response   wt -1.629596e-11 3.217589e-10 -0.05064649 0.959607218 #> 49    17 response   wt -2.826816e-11 5.795693e-10 -0.04877442 0.961099064 #> 50    18 response   wt -8.521936e-01 8.229549e-01 -1.03552892 0.300421966 #> 51    19 response   wt -7.886841e-02 1.842446e-01 -0.42806372 0.668604733 #> 52    20 response   wt -8.870757e-02 1.769120e-01 -0.50142206 0.616074120 #> 53    21 response   wt -5.959105e-01 9.379795e-01 -0.63531295 0.525224328 #> 54    22 response   wt -1.272450e-01 1.577696e-01 -0.80652389 0.419940837 #> 55    23 response   wt -3.054369e-01 2.813059e-01 -1.08578197 0.277575463 #> 56    24 response   wt -6.569718e-02 2.831304e-01 -0.23203857 0.816508055 #> 57    25 response   wt -8.288936e-03 2.714899e-02 -0.30531290 0.760127851 #> 58    26 response   wt -1.612155e-01 2.841263e-01 -0.56740790 0.570437083 #> 59    27 response   wt -7.464417e-02 1.884619e-01 -0.39607029 0.692053177 #> 60    28 response   wt -3.204617e-05 2.159959e-04 -0.14836470 0.882054955 #> 61    29 response   wt -6.580439e-02 3.321209e-01 -0.19813386 0.842940336 #> 62    30 response   wt -5.339272e-02 2.402385e-01 -0.22224887 0.824120154 #> 63    31 response   wt -2.107162e+00 4.582922e+00 -0.45978567 0.645670073 #> 64    32 response   wt -2.024827e+00 7.486883e-01 -2.70449963 0.006840735 #>         conf.low     conf.high    predicted predicted_hi predicted_lo am  hp #> 1  -1.102325e-02  2.498970e-02 8.983110e-01 8.985086e-01 8.983110e-01  1 110 #> 2  -9.864245e-03  4.267249e-02 4.676447e-01 4.681089e-01 4.676447e-01  1 110 #> 3  -6.800752e-03  1.245766e-02 9.671038e-01 9.671839e-01 9.671038e-01  1  93 #> 4  -1.678321e-03  5.548072e-03 3.889558e-02 3.895034e-02 3.889558e-02  0 110 #> 5  -2.461058e-03  8.446778e-03 7.648382e-02 7.656852e-02 7.648382e-02  0 175 #> 6  -3.512456e-04  6.465378e-04 3.566962e-03 3.571140e-03 3.566962e-03  0 105 #> 7  -1.031604e-02  2.179737e-02 1.923979e-01 1.925604e-01 1.923979e-01  0 245 #> 8  -5.506142e-04  9.729546e-04 4.015235e-03 4.021211e-03 4.015235e-03  0  62 #> 9  -1.739703e-03  5.033655e-03 3.120992e-02 3.125653e-02 3.120992e-02  0  95 #> 10 -6.284766e-04  1.390460e-03 9.073330e-03 9.084112e-03 9.073330e-03  0 123 #> 11 -6.284766e-04  1.390460e-03 9.073330e-03 9.084112e-03 9.073330e-03  0 123 #> 12 -1.200989e-05  1.376198e-05 5.439236e-05 5.441715e-05 5.439236e-05  0 180 #> 13 -5.353448e-04  7.268609e-04 3.172383e-03 3.175093e-03 3.172383e-03  0 180 #> 14 -3.240040e-04  4.223112e-04 1.746319e-03 1.747710e-03 1.746319e-03  0 180 #> 15 -1.742390e-11  1.626645e-11 1.751508e-11 1.749870e-11 1.751508e-11  0 205 #> 16 -1.761224e-12  1.663181e-12 1.216933e-12 1.215546e-12 1.216933e-12  0 215 #> 17 -2.766080e-12  2.616815e-12 2.017342e-12 2.015230e-12 2.017342e-12  0 230 #> 18 -1.677116e-02  3.892346e-02 8.634101e-01 8.637236e-01 8.634101e-01  1  66 #> 19 -6.463187e-03  9.269200e-03 9.879847e-01 9.880244e-01 9.879847e-01  1  52 #> 20 -4.399027e-03  7.091091e-03 9.875007e-01 9.875388e-01 9.875007e-01  1  65 #> 21 -9.506117e-03  2.109778e-02 9.243530e-01 9.245170e-01 9.243530e-01  0  97 #> 22 -9.061949e-04  1.834998e-03 1.204113e-02 1.205428e-02 1.204113e-02  0 150 #> 23 -1.189113e-03  3.620838e-03 2.941871e-02 2.945312e-02 2.941871e-02  0 150 #> 24 -1.244158e-03  1.474856e-03 4.509574e-03 4.512838e-03 4.509574e-03  0 245 #> 25 -1.398592e-04  1.758700e-04 7.069764e-04 7.074860e-04 7.069764e-04  0 175 #> 26 -6.580190e-03  1.125942e-02 9.771760e-01 9.772422e-01 9.771760e-01  1  66 #> 27 -3.001712e-03  4.740851e-03 9.908948e-01 9.909194e-01 9.908948e-01  1  91 #> 28 -4.925440e-06  5.778904e-06 9.999965e-01 9.999965e-01 9.999965e-01  1 113 #> 29 -1.989368e-03  2.443712e-03 9.957403e-01 9.957467e-01 9.957403e-01  1 264 #> 30 -2.381458e-03  3.017407e-03 9.954493e-01 9.954583e-01 9.954493e-01  1 175 #> 31 -1.079714e-02  1.921907e-02 8.687038e-01 8.688229e-01 8.687038e-01  1 335 #> 32  8.256332e-04  3.053978e-02 6.593657e-01 6.598095e-01 6.593657e-01  1 109 #> 33 -3.335857e+00  1.679796e+00 8.983110e-01 8.979872e-01 8.983110e-01  1 110 #> 34 -4.923497e+00  4.170878e-01 4.676447e-01 4.667634e-01 4.676447e-01  1 110 #> 35 -1.296380e+00  7.646879e-01 9.671038e-01 9.669998e-01 9.671038e-01  1  93 #> 36 -1.024074e+00  3.484190e-01 3.889558e-02 3.876346e-02 3.889558e-02  0 110 #> 37 -2.164139e+00  5.060942e-01 7.648382e-02 7.615959e-02 7.648382e-02  0 175 #> 38 -1.394192e-01  7.666354e-02 3.566962e-03 3.554690e-03 3.566962e-03  0 105 #> 39 -7.119463e+00  2.566761e+00 1.923979e-01 1.915076e-01 1.923979e-01  0 245 #> 40 -1.398179e-01  8.349126e-02 4.015235e-03 4.004220e-03 4.015235e-03  0  62 #> 41 -8.144358e-01  3.056364e-01 3.120992e-02 3.111043e-02 3.120992e-02  0  95 #> 42 -3.129639e-01  1.407734e-01 9.073330e-03 9.039658e-03 9.073330e-03  0 123 #> 43 -3.129639e-01  1.407734e-01 9.073330e-03 9.039658e-03 9.073330e-03  0 123 #> 44 -7.138419e-03  5.839590e-03 5.439236e-05 5.413837e-05 5.439236e-05  0 180 #> 45 -2.175456e-01  1.420277e-01 3.172383e-03 3.157615e-03 3.172383e-03  0 180 #> 46 -1.357187e-01  9.408877e-02 1.746319e-03 1.738178e-03 1.746319e-03  0 180 #> 47 -7.792685e-09  7.338115e-09 1.751508e-11 1.742619e-11 1.751508e-11  0 205 #> 48 -6.469318e-10  6.143399e-10 1.216933e-12 1.210560e-12 1.216933e-12  0 215 #> 49 -1.164203e-09  1.107667e-09 2.017342e-12 2.006286e-12 2.017342e-12  0 230 #> 50 -2.465156e+00  7.607684e-01 8.634101e-01 8.630768e-01 8.634101e-01  1  66 #> 51 -4.399811e-01  2.822443e-01 9.879847e-01 9.879538e-01 9.879847e-01  1  52 #> 52 -4.354487e-01  2.580335e-01 9.875007e-01 9.874660e-01 9.875007e-01  1  65 #> 53 -2.434317e+00  1.242495e+00 9.243530e-01 9.241200e-01 9.243530e-01  0  97 #> 54 -4.364678e-01  1.819778e-01 1.204113e-02 1.199137e-02 1.204113e-02  0 150 #> 55 -8.567864e-01  2.459126e-01 2.941871e-02 2.929926e-02 2.941871e-02  0 150 #> 56 -6.206226e-01  4.892282e-01 4.509574e-03 4.483880e-03 4.509574e-03  0 245 #> 57 -6.149997e-02  4.492210e-02 7.069764e-04 7.037346e-04 7.069764e-04  0 175 #> 58 -7.180927e-01  3.956618e-01 9.771760e-01 9.771130e-01 9.771760e-01  1  66 #> 59 -4.440228e-01  2.947344e-01 9.908948e-01 9.908656e-01 9.908948e-01  1  91 #> 60 -4.553905e-04  3.912981e-04 9.999965e-01 9.999965e-01 9.999965e-01  1 113 #> 61 -7.167493e-01  5.851405e-01 9.957403e-01 9.957145e-01 9.957403e-01  1 264 #> 62 -5.242514e-01  4.174660e-01 9.954493e-01 9.954285e-01 9.954493e-01  1 175 #> 63 -1.108952e+01  6.875201e+00 8.687038e-01 8.678796e-01 8.687038e-01  1 335 #> 64 -3.492230e+00 -5.574252e-01 6.593657e-01 6.585738e-01 6.593657e-01  1 109 #>       wt       eps #> 1  2.620 0.0283000 #> 2  2.875 0.0283000 #> 3  2.320 0.0283000 #> 4  3.215 0.0283000 #> 5  3.440 0.0283000 #> 6  3.460 0.0283000 #> 7  3.570 0.0283000 #> 8  3.190 0.0283000 #> 9  3.150 0.0283000 #> 10 3.440 0.0283000 #> 11 3.440 0.0283000 #> 12 4.070 0.0283000 #> 13 3.730 0.0283000 #> 14 3.780 0.0283000 #> 15 5.250 0.0283000 #> 16 5.424 0.0283000 #> 17 5.345 0.0283000 #> 18 2.200 0.0283000 #> 19 1.615 0.0283000 #> 20 1.835 0.0283000 #> 21 2.465 0.0283000 #> 22 3.520 0.0283000 #> 23 3.435 0.0283000 #> 24 3.840 0.0283000 #> 25 3.845 0.0283000 #> 26 1.935 0.0283000 #> 27 2.140 0.0283000 #> 28 1.513 0.0283000 #> 29 3.170 0.0283000 #> 30 2.770 0.0283000 #> 31 3.570 0.0283000 #> 32 2.780 0.0283000 #> 33 2.620 0.0003911 #> 34 2.875 0.0003911 #> 35 2.320 0.0003911 #> 36 3.215 0.0003911 #> 37 3.440 0.0003911 #> 38 3.460 0.0003911 #> 39 3.570 0.0003911 #> 40 3.190 0.0003911 #> 41 3.150 0.0003911 #> 42 3.440 0.0003911 #> 43 3.440 0.0003911 #> 44 4.070 0.0003911 #> 45 3.730 0.0003911 #> 46 3.780 0.0003911 #> 47 5.250 0.0003911 #> 48 5.424 0.0003911 #> 49 5.345 0.0003911 #> 50 2.200 0.0003911 #> 51 1.615 0.0003911 #> 52 1.835 0.0003911 #> 53 2.465 0.0003911 #> 54 3.520 0.0003911 #> 55 3.435 0.0003911 #> 56 3.840 0.0003911 #> 57 3.845 0.0003911 #> 58 1.935 0.0003911 #> 59 2.140 0.0003911 #> 60 1.513 0.0003911 #> 61 3.170 0.0003911 #> 62 2.770 0.0003911 #> 63 3.570 0.0003911 #> 64 2.780 0.0003911  # hypothesis test: is the `hp` marginal effect at the mean equal to the `drat` marginal effect mod <- lm(mpg ~ wt + drat, data = mtcars)  marginaleffects(     mod,     newdata = \"mean\",     hypothesis = \"wt = drat\") #>       type    term      dydx std.error statistic      p.value conf.low #> 1 response wt=drat -6.225381  1.051769 -5.918963 3.239775e-09 -8.28681 #>   conf.high #> 1 -4.163952  # same hypothesis test using row indices marginaleffects(     mod,     newdata = \"mean\",     hypothesis = \"b1 - b2 = 0\") #>       type    term      dydx std.error statistic      p.value conf.low #> 1 response b1-b2=0 -6.225381  1.051769 -5.918963 3.239775e-09 -8.28681 #>   conf.high #> 1 -4.163952  # same hypothesis test using numeric vector of weights marginaleffects(     mod,     newdata = \"mean\",     hypothesis = c(1, -1)) #>       type   term      dydx std.error statistic      p.value conf.low conf.high #> 1 response custom -6.225381  1.051769 -5.918963 3.239775e-09 -8.28681 -4.163952  # two custom contrasts using a matrix of weights lc <- matrix(c(     1, -1,     2, 3),     ncol = 2) colnames(lc) <- c(\"Contrast A\", \"Contrast B\") marginaleffects(     mod,     newdata = \"mean\",     hypothesis = lc) #>       type       term      dydx std.error  statistic      p.value  conf.low #> 1 response Contrast A -6.225381  1.051769 -5.9189632 3.239775e-09  -8.28681 #> 2 response Contrast B -5.238308  5.623757 -0.9314607 3.516153e-01 -16.26067 #>   conf.high #> 1 -4.163952 #> 2  5.784052"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/plot.marginaleffects.html","id":null,"dir":"Reference","previous_headings":"","what":"Point-range plot of average marginal effects — plot.marginaleffects","title":"Point-range plot of average marginal effects — plot.marginaleffects","text":"Uses ggplot2 package draw point-range plot average marginal effects computed tidy.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/plot.marginaleffects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Point-range plot of average marginal effects — plot.marginaleffects","text":"","code":"# S3 method for marginaleffects plot(x, conf_level = 0.95, ...)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/plot.marginaleffects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Point-range plot of average marginal effects — plot.marginaleffects","text":"x object produced marginaleffects function. conf_level numeric value 0 1. Confidence level use build confidence interval. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/plot.marginaleffects.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Point-range plot of average marginal effects — plot.marginaleffects","text":"ggplot2 object","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/plot.marginaleffects.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Point-range plot of average marginal effects — plot.marginaleffects","text":"tidy function calculates average marginal effects taking mean unit-level marginal effects computed marginaleffects function. standard error average marginal effects obtained taking mean column Jacobian. . , use \"Jacobian mean\" Delta method obtained standard errors.","code":""},{"path":[]},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/plot.marginaleffects.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Point-range plot of average marginal effects — plot.marginaleffects","text":"","code":"mod <- glm(am ~ hp + wt, data = mtcars) mfx <- marginaleffects(mod) plot(mfx)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/plot_cap.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Conditional Adjusted Predictions — plot_cap","title":"Plot Conditional Adjusted Predictions — plot_cap","text":"function plots adjusted predictions (y-axis) values one predictors (x-axis colors).","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/plot_cap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Conditional Adjusted Predictions — plot_cap","text":"","code":"plot_cap(   model,   condition = NULL,   type = \"response\",   vcov = NULL,   conf_level = 0.95,   transform_post = NULL,   draw = TRUE,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/plot_cap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Conditional Adjusted Predictions — plot_cap","text":"model Model object condition character vector named list length smaller 4. Character vectors must names predictor variables display. names list must first element displayed x-axis. second element determines colors. third element creates facets. variables held means modes. Lists can include types values: Numeric vector Function returns numeric vector set unique categorical values Shortcut strings common reference values: \"minmax\", \"quartile\", \"threenum\" type string indicates type (scale) predictions used compute marginal effects contrasts. can differ based model type, typically string : \"response\", \"link\", \"probs\", \"zero\". unsupported string entered, model-specific list acceptable values returned error message. type NULL, default value used. default first model-related row marginaleffects:::type_dictionary dataframe. vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) conf_level numeric value 0 1. Confidence level use build confidence interval. transform_post (experimental) function applied unit-level adjusted predictions confidence intervals just function returns results. bayesian models, function applied individual draws posterior distribution, computing summaries. draw TRUE returns ggplot2 plot. FALSE returns data.frame underlying data. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/plot_cap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Conditional Adjusted Predictions — plot_cap","text":"ggplot2 object","code":""},{"path":[]},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/plot_cap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Conditional Adjusted Predictions — plot_cap","text":"","code":"mod <- lm(mpg ~ hp + wt, data = mtcars) plot_cap(mod, condition = \"wt\")   mod <- lm(mpg ~ hp * wt * am, data = mtcars) plot_cap(mod, condition = c(\"hp\", \"wt\"))   plot_cap(mod, condition = list(\"hp\", wt = \"threenum\"))   plot_cap(mod, condition = list(\"hp\", wt = range))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/plot_cco.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Conditional Contrasts — plot_cco","title":"Plot Conditional Contrasts — plot_cco","text":"function plots contrasts (y-axis) values predictor(s) variable(s) (x-axis colors). especially useful models interactions, values contrasts depend values \"condition\" variables.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/plot_cco.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Conditional Contrasts — plot_cco","text":"","code":"plot_cco(   model,   effect = NULL,   condition = NULL,   type = \"response\",   vcov = NULL,   conf_level = 0.95,   transform_pre = \"difference\",   transform_post = NULL,   draw = TRUE,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/plot_cco.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Conditional Contrasts — plot_cco","text":"model Model object effect Name variable whose contrast want plot y-axis condition character vector named list length smaller 3. Character vectors must names predictor variables display. names list must first element displayed x-axis. second element determines colors. third element creates facets. Unspecified variables held means modes. Lists can include types values (see Examples section ): Numeric vector Function returns numeric vector set unique categorical values Shortcut strings common reference values: \"minmax\", \"quartile\", \"threenum\" type string indicates type (scale) predictions used compute marginal effects contrasts. can differ based model type, typically string : \"response\", \"link\", \"probs\", \"zero\". unsupported string entered, model-specific list acceptable values returned error message. type NULL, default value used. default first model-related row marginaleffects:::type_dictionary dataframe. vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) conf_level numeric value 0 1. Confidence level use build confidence interval. transform_pre string function. pairs adjusted predictions contrasted? string: shortcuts common contrast functions. Supported shortcuts strings: difference, differenceavg, differenceavgwts, dydx, eyex, eydx, dyex, dydxavg, eyexavg, eydxavg, dyexavg, dydxavgwts, eyexavgwts, eydxavgwts, dyexavgwts, ratio, ratioavg, ratioavgwts, lnratio, lnratioavg, lnratioavgwts, lnor, lnoravg, lnoravgwts, expdydx, expdydxavg, expdydxavgwts See Transformations section definitions transformation. function: accept two equal-length numeric vectors adjusted predictions (hi lo) returns vector contrasts length, unique numeric value. See Transformations section examples valid functions. transform_post string function. Transformation applied unit-level estimates confidence intervals just function returns results. Functions must accept vector return vector length. Support string shortcuts: \"exp\", \"ln\" draw TRUE returns ggplot2 plot. FALSE returns data.frame underlying data. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/plot_cco.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Conditional Contrasts — plot_cco","text":"ggplot2 object","code":""},{"path":[]},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/plot_cco.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Conditional Contrasts — plot_cco","text":"","code":"mod <- lm(mpg ~ hp * drat * factor(am), data = mtcars)  plot_cco(mod, effect = \"hp\", condition = \"drat\")   plot_cco(mod, effect = \"hp\", condition = c(\"drat\", \"am\"))   plot_cco(mod, effect = \"hp\", condition = list(\"am\", \"drat\" = 3:5))   plot_cco(mod, effect = \"am\", condition = list(\"hp\", \"drat\" = range))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/plot_cme.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Conditional Marginal Effects — plot_cme","title":"Plot Conditional Marginal Effects — plot_cme","text":"function plots marginal effects (y-axis) values predictor(s) variable(s) (x-axis colors). especially useful models interactions, values marginal effects depend values \"condition\" variables.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/plot_cme.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Conditional Marginal Effects — plot_cme","text":"","code":"plot_cme(   model,   effect = NULL,   condition = NULL,   type = \"response\",   vcov = NULL,   conf_level = 0.95,   draw = TRUE,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/plot_cme.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Conditional Marginal Effects — plot_cme","text":"model Model object effect Name variable whose marginal effect want plot y-axis condition character vector named list length smaller 3. Character vectors must names predictor variables display. names list must first element displayed x-axis. second element determines colors. third element creates facets. Unspecified variables held means modes. Lists can include types values (see Examples section ): Numeric vector Function returns numeric vector set unique categorical values Shortcut strings common reference values: \"minmax\", \"quartile\", \"threenum\" type string indicates type (scale) predictions used compute marginal effects contrasts. can differ based model type, typically string : \"response\", \"link\", \"probs\", \"zero\". unsupported string entered, model-specific list acceptable values returned error message. type NULL, default value used. default first model-related row marginaleffects:::type_dictionary dataframe. vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) conf_level numeric value 0 1. Confidence level use build confidence interval. draw TRUE returns ggplot2 plot. FALSE returns data.frame underlying data. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/plot_cme.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Conditional Marginal Effects — plot_cme","text":"ggplot2 object","code":""},{"path":[]},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/plot_cme.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Conditional Marginal Effects — plot_cme","text":"","code":"library(marginaleffects) mod <- lm(mpg ~ hp * drat * factor(am), data = mtcars)  plot_cme(mod, effect = \"hp\", condition = \"drat\")   plot_cme(mod, effect = \"hp\", condition = c(\"drat\", \"am\"))   plot_cme(mod, effect = \"hp\", condition = list(\"am\", \"drat\" = 3:5))   plot_cme(mod, effect = \"am\", condition = list(\"hp\", \"drat\" = range))   plot_cme(mod, effect = \"am\", condition = list(\"hp\", \"drat\" = \"threenum\"))"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/posteriordraws.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract posterior draws from a predictions, comparisons, or marginaleffects object derived from Bayesian models. — posteriordraws","title":"Extract posterior draws from a predictions, comparisons, or marginaleffects object derived from Bayesian models. — posteriordraws","text":"Extract posterior draws predictions, comparisons, marginaleffects object derived Bayesian models.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/posteriordraws.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract posterior draws from a predictions, comparisons, or marginaleffects object derived from Bayesian models. — posteriordraws","text":"","code":"posteriordraws(x, shape = \"long\")"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/posteriordraws.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract posterior draws from a predictions, comparisons, or marginaleffects object derived from Bayesian models. — posteriordraws","text":"x object produced marginaleffects, comparisons, predictions functions shape string indicating shape output format: \"long\": long format data frame \"DxP\": Matrix draws rows parameters columns \"PxD\": Matrix draws rows parameters columns \"rvar\": Random variable datatype (see posterior package documentation).","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/posteriordraws.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract posterior draws from a predictions, comparisons, or marginaleffects object derived from Bayesian models. — posteriordraws","text":"data.frame drawid draw columns.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/predictions.html","id":null,"dir":"Reference","previous_headings":"","what":"Adjusted Predictions — predictions","title":"Adjusted Predictions — predictions","text":"Outcome predicted fitted model specified scale given combination values predictor variables, observed values, means, factor levels (.k.. \"reference grid\"). tidy() summary() functions can used aggregate output predictions(). learn , read predictions vignette, visit package website, scroll page full list vignettes: https://vincentarelbundock.github.io/marginaleffects/articles/predictions.html https://vincentarelbundock.github.io/marginaleffects/","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/predictions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adjusted Predictions — predictions","text":"","code":"predictions(   model,   newdata = NULL,   variables = NULL,   vcov = TRUE,   conf_level = 0.95,   type = NULL,   by = NULL,   byfun = NULL,   wts = NULL,   transform_post = NULL,   hypothesis = NULL,   ... )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/predictions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adjusted Predictions — predictions","text":"model Model object newdata NULL, data frame, string, datagrid() call. Determines predictor values compute marginal effects. NULL (default): Unit-level marginal effects observed value original dataset. data frame: Unit-level marginal effects row newdata data frame. string: \"mean\": Marginal Effects Mean. Marginal effects predictor held mean mode. \"median\": Marginal Effects Median. Marginal effects predictor held median mode. \"marginalmeans\": Marginal Effects Marginal Means. See Details section . \"tukey\": Marginal Effects Tukey's 5 numbers. \"grid\": Marginal Effects grid representative numbers (Tukey's 5 numbers unique values categorical predictors). datagrid() call specify custom grid regressors. example: newdata = datagrid(cyl = c(4, 6)): cyl variable equal 4 6 regressors fixed means modes. See Examples section datagrid() documentation. variables NULL, character vector, named list. subset variables use creating counterfactual grid predictions. entire dataset replicated unique combination variables list. See Examples section . Warning: can use lot memory many variables values, dataset large. NULL: computes one prediction per row newdata Named list: names identify subset variables interest values. numeric variables, variables argument supports functions string shortcuts: function returns numeric value Numeric vector: Contrast 2nd element 1st element x vector. \"iqr\": Contrast across interquartile range regressor. \"sd\": Contrast across one standard deviation around regressor mean. \"2sd\": Contrast across two standard deviations around regressor mean. \"minmax\": Contrast maximum minimum values regressor. \"threenum\": mean 1 standard deviation sides \"fivenum\": Tukey's five numbers #' @param newdata NULL, data frame, string, datagrid() call. Determines grid predictors make predictions. NULL (default): Predictions observed value original dataset. data frame: Predictions row newdata data frame. string: \"mean\": Predictions Mean. Predictions predictor held mean mode. \"median\": Predictions Median. Predictions predictor held median mode. \"marginalmeans\": Predictions Marginal Means. See Details section . \"tukey\": Predictions Tukey's 5 numbers. \"grid\": Predictions grid representative numbers (Tukey's 5 numbers unique values categorical predictors). datagrid() call specify custom grid regressors. example: newdata = datagrid(cyl = c(4, 6)): cyl variable equal 4 6 regressors fixed means modes. See Examples section datagrid() documentation. vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) conf_level numeric value 0 1. Confidence level use build confidence interval. type string indicates type (scale) predictions used compute marginal effects contrasts. can differ based model type, typically string : \"response\", \"link\", \"probs\", \"zero\". unsupported string entered, model-specific list acceptable values returned error message. type NULL, default value used. default first model-related row marginaleffects:::type_dictionary dataframe. Character vector variable names compute group-wise estimates. byfun function mean() sum() used aggregate estimates within subgroups defined argument. NULL uses mean() function. Must accept numeric vector return single numeric value. sometimes used take sum mean predicted probabilities across outcome predictor levels. See examples section. wts string numeric: weights use computing average contrasts marginaleffects. weights affect averaging tidy() summary(), unit-level estimates . string: column name weights variable newdata. supplying column name wts, recommended supply original data (including weights variable) explicitly newdata. numeric: vector length equal number rows original data newdata (supplied). transform_post (experimental) function applied unit-level adjusted predictions confidence intervals just function returns results. bayesian models, function applied individual draws posterior distribution, computing summaries. hypothesis specify hypothesis test custom contrast using vector, matrix, string, string formula. String: \"pairwise\": pairwise differences estimates row. \"reference\": differences estimates row estimate first row. \"sequential\": difference estimate estimate next row. \"revpairwise\", \"revreference\", \"revsequential\": inverse corresponding hypotheses, described . String formula specify linear non-linear hypothesis tests. term column uniquely identifies rows, terms can used formula. Otherwise, use b1, b2, etc. identify position parameter. Examples: hp = drat hp + drat = 12 b1 + b2 + b3 = 0 Numeric vector: Weights compute linear combination (custom contrast ) estimates. Length equal number rows generated function call, without hypothesis argument. Numeric matrix: column vector weights, describe , used compute distinct linear combination (contrast ) estimates. column names matrix used labels output. See Examples section vignette: https://vincentarelbundock.github.io/marginaleffects/articles/hypothesis.html ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/predictions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adjusted Predictions — predictions","text":"data.frame one row per observation several columns: rowid: row number newdata data frame type: prediction type, defined type argument group: (optional) value grouped outcome (e.g., categorical outcome models) predicted: predicted outcome std.error: standard errors computed insight::get_predicted function , unavailable, via marginaleffects delta method functionality. conf.low: lower bound confidence interval (equal-tailed interval bayesian models) conf.high: upper bound confidence interval (equal-tailed interval bayesian models)","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/predictions.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Adjusted Predictions — predictions","text":"newdata argument, tidy() function, datagrid() function can used control kind predictions report: Average Predictions Predictions Mean Predictions User-Specified values (aka Predictions Representative values). possible, predictions() delegates computation confidence intervals insight::get_predicted() function, uses back transformation produce adequate confidence intervals scale specified type argument. possible, predictions() uses Delta Method compute standard errors around adjusted predictions, builds symmetric confidence intervals. naive symmetric intervals may always appropriate. instance, may stretch beyond bounds binary response variables.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/predictions.html","id":"vignettes-and-documentation","dir":"Reference","previous_headings":"","what":"Vignettes and documentation","title":"Adjusted Predictions — predictions","text":"Vignettes: Adjusted Predictions Contrasts Marginal Effects Marginal Means Hypothesis Tests Custom Contrasts using Delta Method Case studies: Bayesian Analyses brms Causal Inference g-Formula Elasticity Experiments Generalized Additive Models Mixed effects models Multinomial Logit Discrete Choice Models Multiple Imputation Plots: interactions, predictions, contrasts, slopes Python NumPyro models marginaleffects Unit-level contrasts logistic regressions Tips technical notes: 71 Supported Classes Models Index Functions Documentation Extending marginaleffects: add new models modify existing ones Standard Errors Confidence Intervals Tables Plots Performance Alternative Software Frequently Asked Questions","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/predictions.html","id":"model-specific-arguments","dir":"Reference","previous_headings":"","what":"Model-Specific Arguments","title":"Adjusted Predictions — predictions","text":"model types allow model-specific arguments modify nature marginal effects, predictions, marginal means, contrasts.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/predictions.html","id":"bayesian-posterior-summaries","dir":"Reference","previous_headings":"","what":"Bayesian posterior summaries","title":"Adjusted Predictions — predictions","text":"default, credible intervals bayesian models built equal-tailed intervals. can changed highest density interval setting global option: options(\"marginaleffects_posterior_interval\" = \"eti\") options(\"marginaleffects_posterior_interval\" = \"hdi\") default, center posterior distribution bayesian models identified median. Users can use different summary function setting global option: options(\"marginaleffects_posterior_center\" = mean) options(\"marginaleffects_posterior_center\" = median) estimates averaged using argument, tidy() function, summary() function, posterior distribution marginalized twice . First, take average across units within iteration MCMC chain, according user requested argument tidy()/summary() functions. , identify center resulting posterior using function supplied \"marginaleffects_posterior_center\" option (median default).","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/predictions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Adjusted Predictions — predictions","text":"","code":"# Adjusted Prediction for every row of the original dataset mod <- lm(mpg ~ hp + factor(cyl), data = mtcars) pred <- predictions(mod) head(pred) #>   rowid     type predicted std.error statistic       p.value conf.low conf.high #> 1     1 response  20.03819 1.2041405  16.64107  3.512623e-62 17.57162  22.50476 #> 2     2 response  20.03819 1.2041405  16.64107  3.512623e-62 17.57162  22.50476 #> 3     3 response  26.41451 0.9619738  27.45866 5.476301e-166 24.44399  28.38502 #> 4     4 response  20.03819 1.2041405  16.64107  3.512623e-62 17.57162  22.50476 #> 5     5 response  15.92247 0.9924560  16.04350  6.347069e-58 13.88952  17.95543 #> 6     6 response  20.15839 1.2186288  16.54186  1.832792e-61 17.66214  22.65463 #>    mpg  hp cyl #> 1 21.0 110   6 #> 2 21.0 110   6 #> 3 22.8  93   4 #> 4 21.4 110   6 #> 5 18.7 175   8 #> 6 18.1 105   6  # Adjusted Predictions at User-Specified Values of the Regressors predictions(mod, newdata = datagrid(hp = c(100, 120), cyl = 4)) #>   rowid     type predicted std.error statistic       p.value conf.low conf.high #> 1     1 response  26.24623 0.9856325  26.62883 3.148430e-156 24.22726  28.26521 #> 2     2 response  25.76546 1.1096486  23.21947 2.895018e-119 23.49245  28.03847 #>        mpg  hp cyl #> 1 20.09062 100   4 #> 2 20.09062 120   4  m <- lm(mpg ~ hp + drat + factor(cyl) + factor(am), data = mtcars) predictions(m, newdata = datagrid(FUN_factor = unique, FUN_numeric = median)) #>   rowid     type predicted std.error statistic      p.value conf.low conf.high #> 1     1 response  21.95333  1.288065  17.04365 3.896507e-65 19.30567  24.60099 #> 2     2 response  18.18910  1.270927  14.31168 1.849819e-46 15.57667  20.80153 #> 3     3 response  25.54890  1.322154  19.32369 3.395189e-83 22.83117  28.26663 #> 4     4 response  21.78467  1.541301  14.13395 2.346178e-45 18.61648  24.95286 #> 5     5 response  22.61705  2.140950  10.56403 4.374878e-26 18.21627  27.01784 #> 6     6 response  18.85282  1.734026  10.87228 1.562441e-27 15.28848  22.41716 #>    mpg  hp  drat cyl am #> 1 19.2 123 3.695   6  1 #> 2 19.2 123 3.695   6  0 #> 3 19.2 123 3.695   4  1 #> 4 19.2 123 3.695   4  0 #> 5 19.2 123 3.695   8  1 #> 6 19.2 123 3.695   8  0  # Average Adjusted Predictions (AAP) library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union mod <- lm(mpg ~ hp * am * vs, mtcars)  pred <- predictions(mod) summary(pred) #>   Predicted Std. Error z value   Pr(>|z|) CI low CI high #> 1     20.09     0.4844   41.47 < 2.22e-16  19.14   21.04 #>  #> Model type:  lm  #> Prediction type:  response   predictions(mod, by = \"am\") #>       type am predicted std.error statistic       p.value conf.low conf.high #> 1 response  1  24.39231 0.7600565  32.09275 5.564392e-226 22.90262  25.88199 #> 2 response  0  17.14737 0.6286961  27.27449 8.515145e-164 15.91515  18.37959  # Conditional Adjusted Predictions plot_cap(mod, condition = \"hp\")   # Counterfactual predictions with the `variables` argument # the `mtcars` dataset has 32 rows  mod <- lm(mpg ~ hp + am, data = mtcars) p <- predictions(mod) head(p) #>   rowid     type predicted std.error statistic       p.value conf.low conf.high #> 1     1 response  25.38434 0.8176495  31.04550 1.311940e-211 23.71206  27.05662 #> 2     2 response  25.38434 0.8176495  31.04550 1.311940e-211 23.71206  27.05662 #> 3     3 response  26.38543 0.8495566  31.05789 8.927432e-212 24.64790  28.12297 #> 4     4 response  20.10726 0.7754954  25.92827 3.197502e-148 18.52119  21.69332 #> 5     5 response  16.27955 0.6773841  24.03297 1.258166e-127 14.89414  17.66495 #> 6     6 response  20.40169 0.7962179  25.62325 8.401973e-145 18.77325  22.03014 #>    mpg  hp am #> 1 21.0 110  1 #> 2 21.0 110  1 #> 3 22.8  93  1 #> 4 21.4 110  0 #> 5 18.7 175  0 #> 6 18.1 105  0 nrow(p) #> [1] 32  # counterfactual predictions obtained by replicating the entire for different # values of the predictors p <- predictions(mod, variables = list(hp = c(90, 110))) nrow(p) #> [1] 64   # hypothesis test: is the prediction in the 1st row equal to the prediction in the 2nd row mod <- lm(mpg ~ wt + drat, data = mtcars)  predictions(     mod,     newdata = datagrid(wt = 2:3),     hypothesis = \"b1 = b2\") #>       type  term predicted std.error statistic      p.value conf.low conf.high #> 1 response b1=b2   4.78289 0.7970353  6.000851 1.962855e-09  3.22073  6.345051  # same hypothesis test using row indices predictions(     mod,     newdata = datagrid(wt = 2:3),     hypothesis = \"b1 - b2 = 0\") #>       type    term predicted std.error statistic      p.value conf.low #> 1 response b1-b2=0   4.78289 0.7970353  6.000851 1.962855e-09  3.22073 #>   conf.high #> 1  6.345051  # same hypothesis test using numeric vector of weights predictions(     mod,     newdata = datagrid(wt = 2:3),     hypothesis = c(1, -1)) #>       type   term predicted std.error statistic      p.value conf.low conf.high #> 1 response custom   4.78289 0.7970353  6.000851 1.962855e-09  3.22073  6.345051  # two custom contrasts using a matrix of weights lc <- matrix(c(     1, -1,     2, 3),     ncol = 2) predictions(     mod,     newdata = datagrid(wt = 2:3),     hypothesis = lc) #>   rowid     type   term predicted std.error statistic       p.value  conf.low #> 1     1 response custom   4.78289 0.7970353  6.000851  1.962855e-09   3.22073 #> 2     2 response custom 115.21432 3.6474827 31.587352 5.507900e-219 108.06539 #>    conf.high #> 1   6.345051 #> 2 122.363255   # `by` argument mod <- lm(mpg ~ hp * am * vs, data = mtcars) predictions(mod, by = c(\"am\", \"vs\"))  #>       type am vs predicted std.error statistic       p.value conf.low conf.high #> 1 response  1  0  19.75000 1.1187729  17.65327  9.603187e-70 17.55725  21.94275 #> 2 response  1  1  28.37143 1.0357825  27.39130 3.481693e-165 26.34133  30.40152 #> 3 response  0  1  20.74286 1.0357825  20.02627  3.251286e-89 18.71276  22.77295 #> 4 response  0  0  15.05000 0.7910919  19.02434  1.072330e-80 13.49949  16.60051  library(nnet) nom <- multinom(factor(gear) ~ mpg + am * vs, data = mtcars, trace = FALSE)  # first 5 raw predictions predictions(nom, type = \"probs\") |> head() #>   rowid  type group    predicted    std.error    statistic    p.value #> 1     1 probs     3 3.623918e-05 2.002490e-03   0.01809706 0.98556142 #> 2     2 probs     3 3.623918e-05 2.002490e-03   0.01809706 0.98556142 #> 3     3 probs     3 9.347603e-08 6.911938e-06   0.01352385 0.98920986 #> 4     4 probs     3 4.044657e-01 1.965452e-01   2.05787667 0.03960197 #> 5     5 probs     3 9.999714e-01 1.246217e-03 802.40562752 0.00000000 #> 6     6 probs     3 5.183336e-01 2.898025e-01   1.78857550 0.07368321 #>        conf.low    conf.high gear  mpg am vs #> 1 -3.888569e-03 3.961047e-03    4 21.0  1  0 #> 2 -3.888569e-03 3.961047e-03    4 21.0  1  0 #> 3 -1.345367e-05 1.364063e-05    4 22.8  1  1 #> 4  1.924426e-02 7.896871e-01    3 21.4  0  1 #> 5  9.975289e-01 1.002414e+00    3 18.7  0  0 #> 6 -4.966881e-02 1.086336e+00    3 18.1  0  1  # average predictions predictions(nom, type = \"probs\", by = \"group\") |> summary() #>   Group Predicted Std. Error z value   Pr(>|z|)  CI low CI high #> 1     3    0.4688    0.04043  11.595 < 2.22e-16 0.38952  0.5480 #> 2     4    0.3750    0.06142   6.106 1.0231e-09 0.25462  0.4954 #> 3     5    0.1562    0.04624   3.379  0.0007279 0.06561  0.2469 #>  #> Model type:  multinom  #> Prediction type:  probs   by <- data.frame(     group = c(\"3\", \"4\", \"5\"),     by = c(\"3,4\", \"3,4\", \"5\"))  predictions(nom, type = \"probs\", by = by) #>    type predicted  std.error statistic      p.value   conf.low conf.high  by #> 1 probs 0.4218766 0.02312133 18.246210 2.217708e-74 0.37655960 0.4671935 3,4 #> 2 probs 0.1562469 0.04624265  3.378848 7.279037e-04 0.06561294 0.2468808   5  # sum of predicted probabilities for combined response levels mod <- multinom(factor(cyl) ~ mpg + am, data = mtcars, trace = FALSE) by <- data.frame(     by = c(\"4,6\", \"4,6\", \"8\"),     group = as.character(c(4, 6, 8))) predictions(mod, newdata = \"mean\", byfun = sum, by = by) #> Warning: Some of the variable names are missing from the model data: group #>    type  predicted std.error statistic      p.value   conf.low conf.high  by #> 1 probs 0.91584335 0.1218077 7.5187647 5.529622e-14  0.6771047 1.1545820 4,6 #> 2 probs 0.08415665 0.1218077 0.6908977 4.896298e-01 -0.1545820 0.3228953   8"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. generics glance, tidy","code":""},{"path":[]},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/sanity_model_specific.html","id":null,"dir":"Reference","previous_headings":"","what":"Method to raise model-specific warnings and errors — sanity_model_specific.betareg","title":"Method to raise model-specific warnings and errors — sanity_model_specific.betareg","text":"Method raise model-specific warnings errors","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/sanity_model_specific.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Method to raise model-specific warnings and errors — sanity_model_specific.betareg","text":"","code":"# S3 method for betareg sanity_model_specific(model, ...)  sanity_model_specific(model, calling_function = \"marginaleffects\", ...)  # S3 method for default sanity_model_specific(   model,   vcov = NULL,   calling_function = \"marginaleffects\",   ... )  # S3 method for brmsfit sanity_model_specific(model, ...)  # S3 method for glmmTMB sanity_model_specific(   model,   vcov = NULL,   calling_function = \"marginaleffects\",   ... )  # S3 method for mblogit sanity_model_specific(model, calling_function = \"marginaleffects\", ...)  # S3 method for mlogit sanity_model_specific(model, newdata, ...)  # S3 method for clm sanity_model_specific(model, ...)  # S3 method for plm sanity_model_specific(model, ...)  # S3 method for plm sanity_model_specific(model, ...)  # S3 method for rqs sanity_model_specific(model, ...)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/sanity_model_specific.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Method to raise model-specific warnings and errors — sanity_model_specific.betareg","text":"model Model object ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments. vcov Type uncertainty estimates report (e.g., robust standard errors). Acceptable values: FALSE: compute standard errors. can speed computation considerably. TRUE: Unit-level standard errors using default vcov(model) variance-covariance matrix. String indicates kind uncertainty estimates return. Heteroskedasticity-consistent: \"HC\", \"HC0\", \"HC1\", \"HC2\", \"HC3\", \"HC4\", \"HC4m\", \"HC5\". See ?sandwich::vcovHC Heteroskedasticity autocorrelation consistent: \"HAC\" Mixed-Models degrees freedom: \"satterthwaite\", \"kenward-roger\" : \"NeweyWest\", \"KernHAC\", \"OPG\". See sandwich package documentation. One-sided formula indicates name cluster variables (e.g., ~unit_id). formula passed cluster argument sandwich::vcovCL function. Square covariance matrix Function returns covariance matrix (e.g., stats::vcov(model)) newdata NULL, data frame, string, datagrid() call. Determines predictor values compute marginal effects. NULL (default): Unit-level marginal effects observed value original dataset. data frame: Unit-level marginal effects row newdata data frame. string: \"mean\": Marginal Effects Mean. Marginal effects predictor held mean mode. \"median\": Marginal Effects Median. Marginal effects predictor held median mode. \"marginalmeans\": Marginal Effects Marginal Means. See Details section . \"tukey\": Marginal Effects Tukey's 5 numbers. \"grid\": Marginal Effects grid representative numbers (Tukey's 5 numbers unique values categorical predictors). datagrid() call specify custom grid regressors. example: newdata = datagrid(cyl = c(4, 6)): cyl variable equal 4 6 regressors fixed means modes. See Examples section datagrid() documentation.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/sanity_model_specific.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Method to raise model-specific warnings and errors — sanity_model_specific.betareg","text":"warning, error, nothing","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/set_coef.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal function to set coefficients — set_coef","title":"Internal function to set coefficients — set_coef","text":"Set coefficients model different values return modified object (internal function)","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/set_coef.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal function to set coefficients — set_coef","text":"","code":"set_coef(model, coefs, ...)  # S3 method for default set_coef(model, coefs, ...)  # S3 method for polr set_coef(model, coefs, ...)  # S3 method for glmmPQL set_coef(model, coefs, ...)  # S3 method for afex_aov set_coef(model, coefs, ...)  # S3 method for glimML set_coef(model, coefs, ...)  # S3 method for betareg set_coef(model, coefs, ...)  # S3 method for multinom set_coef(model, coefs, ...)  # S3 method for crch set_coef(model, coefs, ...)  # S3 method for hxlr set_coef(model, coefs, ...)  # S3 method for gamlss set_coef(model, coefs, ...)  # S3 method for glmmTMB set_coef(model, coefs, ...)  # S3 method for glmx set_coef(model, coefs, ...)  # S3 method for merMod set_coef(model, coefs, ...)  # S3 method for lmerModLmerTest set_coef(model, coefs, ...)  # S3 method for lmerMod set_coef(model, coefs, ...)  # S3 method for mlm set_coef(model, coefs, ...)  # S3 method for hurdle set_coef(model, coefs, ...)  # S3 method for zeroinfl set_coef(model, coefs, ...)  # S3 method for rlmerMod set_coef(model, coefs, ...)  # S3 method for selection set_coef(model, coefs, ...)  # S3 method for scam set_coef(model, coefs, ...)  # S3 method for glm set_coef(model, coefs, ...)  # S3 method for lm set_coef(model, coefs, ...)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/set_coef.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal function to set coefficients — set_coef","text":"model object modify coefs vector coefficients insert model object","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/set_coef.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal function to set coefficients — set_coef","text":"Model object class model argument, different stored coefficients.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/set_coef.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Internal function to set coefficients — set_coef","text":"compute variance marginal effects need take Jacobian ","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/summary.comparisons.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize a comparisons object — summary.comparisons","title":"Summarize a comparisons object — summary.comparisons","text":"Summarize comparisons object","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/summary.comparisons.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize a comparisons object — summary.comparisons","text":"","code":"# S3 method for comparisons summary(object, conf_level = NULL, transform_avg = NULL, ...)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/summary.comparisons.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize a comparisons object — summary.comparisons","text":"object object produced comparisons function conf_level numeric value 0 1. Confidence level use build confidence interval. transform_avg function applied estimates confidence intervals unit-level estimates averaged. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/summary.comparisons.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize a comparisons object — summary.comparisons","text":"Data frame summary statistics object produced comparisons function","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/summary.comparisons.html","id":"bayesian-posterior-summaries","dir":"Reference","previous_headings":"","what":"Bayesian posterior summaries","title":"Summarize a comparisons object — summary.comparisons","text":"default, credible intervals bayesian models built equal-tailed intervals. can changed highest density interval setting global option: options(\"marginaleffects_posterior_interval\" = \"eti\") options(\"marginaleffects_posterior_interval\" = \"hdi\") default, center posterior distribution bayesian models identified median. Users can use different summary function setting global option: options(\"marginaleffects_posterior_center\" = mean) options(\"marginaleffects_posterior_center\" = median) estimates averaged using argument, tidy() function, summary() function, posterior distribution marginalized twice . First, take average across units within iteration MCMC chain, according user requested argument tidy()/summary() functions. , identify center resulting posterior using function supplied \"marginaleffects_posterior_center\" option (median default).","code":""},{"path":[]},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/summary.comparisons.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize a comparisons object — summary.comparisons","text":"","code":"mod <- lm(mpg ~ hp * wt + factor(gear), data = mtcars) con <- comparisons(mod)  # average marginal effects summary(con) #>   Term Contrast   Effect Std. Error z value   Pr(>|z|)    2.5 %   97.5 % #> 1   hp       +1 -0.03533    0.01045 -3.3814 0.00072105 -0.05581 -0.01485 #> 2   wt       +1 -3.52593    0.73202 -4.8167 1.4593e-06 -4.96065 -2.09120 #> 3 gear    4 - 3  0.82900    1.11804  0.7415 0.45840435 -1.36232  3.02032 #> 4 gear    5 - 3  1.81650    1.54761  1.1737 0.24049622 -1.21675  4.84975 #>  #> Model type:  lm  #> Prediction type:  response"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/summary.marginaleffects.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize a marginaleffects object — summary.marginaleffects","title":"Summarize a marginaleffects object — summary.marginaleffects","text":"Summarize marginaleffects object","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/summary.marginaleffects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize a marginaleffects object — summary.marginaleffects","text":"","code":"# S3 method for marginaleffects summary(object, conf_level = NULL, ...)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/summary.marginaleffects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize a marginaleffects object — summary.marginaleffects","text":"object object produced marginaleffects function conf_level numeric value 0 1. Confidence level use build confidence interval. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/summary.marginaleffects.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize a marginaleffects object — summary.marginaleffects","text":"Data frame summary statistics object produced marginaleffects function","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/summary.marginaleffects.html","id":"bayesian-posterior-summaries","dir":"Reference","previous_headings":"","what":"Bayesian posterior summaries","title":"Summarize a marginaleffects object — summary.marginaleffects","text":"default, credible intervals bayesian models built equal-tailed intervals. can changed highest density interval setting global option: options(\"marginaleffects_posterior_interval\" = \"eti\") options(\"marginaleffects_posterior_interval\" = \"hdi\") default, center posterior distribution bayesian models identified median. Users can use different summary function setting global option: options(\"marginaleffects_posterior_center\" = mean) options(\"marginaleffects_posterior_center\" = median) estimates averaged using argument, tidy() function, summary() function, posterior distribution marginalized twice . First, take average across units within iteration MCMC chain, according user requested argument tidy()/summary() functions. , identify center resulting posterior using function supplied \"marginaleffects_posterior_center\" option (median default).","code":""},{"path":[]},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/summary.marginaleffects.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarize a marginaleffects object — summary.marginaleffects","text":"","code":"mod <- lm(mpg ~ hp * wt + factor(gear), data = mtcars) mfx <- marginaleffects(mod)  # average marginal effects summary(mfx) #>   Term Contrast   Effect Std. Error z value   Pr(>|z|)    2.5 %   97.5 % #> 1   hp    dY/dX -0.03533    0.01045 -3.3814 0.00072105 -0.05581 -0.01485 #> 2   wt    dY/dX -3.52593    0.73202 -4.8167 1.4593e-06 -4.96065 -2.09120 #> 3 gear    4 - 3  0.82900    1.11804  0.7415 0.45840435 -1.36232  3.02032 #> 4 gear    5 - 3  1.81650    1.54761  1.1737 0.24049622 -1.21675  4.84975 #>  #> Model type:  lm  #> Prediction type:  response"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/summary.marginalmeans.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize a marginalmeans object — summary.marginalmeans","title":"Summarize a marginalmeans object — summary.marginalmeans","text":"Summarize marginalmeans object","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/summary.marginalmeans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize a marginalmeans object — summary.marginalmeans","text":"","code":"# S3 method for marginalmeans summary(object, transform_avg = NULL, conf_level = 0.95, ...)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/summary.marginalmeans.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize a marginalmeans object — summary.marginalmeans","text":"object object produced marginalmeans function transform_avg function applied estimates confidence intervals unit-level estimates averaged. conf_level numeric value 0 1. Confidence level use build confidence interval. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/summary.marginalmeans.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize a marginalmeans object — summary.marginalmeans","text":"Data frame summary statistics object produced marginalmeans function","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/summary.marginalmeans.html","id":"bayesian-posterior-summaries","dir":"Reference","previous_headings":"","what":"Bayesian posterior summaries","title":"Summarize a marginalmeans object — summary.marginalmeans","text":"default, credible intervals bayesian models built equal-tailed intervals. can changed highest density interval setting global option: options(\"marginaleffects_posterior_interval\" = \"eti\") options(\"marginaleffects_posterior_interval\" = \"hdi\") default, center posterior distribution bayesian models identified median. Users can use different summary function setting global option: options(\"marginaleffects_posterior_center\" = mean) options(\"marginaleffects_posterior_center\" = median) estimates averaged using argument, tidy() function, summary() function, posterior distribution marginalized twice . First, take average across units within iteration MCMC chain, according user requested argument tidy()/summary() functions. , identify center resulting posterior using function supplied \"marginaleffects_posterior_center\" option (median default).","code":""},{"path":[]},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/summary.predictions.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize a predictions object — summary.predictions","title":"Summarize a predictions object — summary.predictions","text":"Summarize predictions object","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/summary.predictions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize a predictions object — summary.predictions","text":"","code":"# S3 method for predictions summary(object, conf_level = NULL, transform_avg = NULL, ...)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/summary.predictions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize a predictions object — summary.predictions","text":"object object produced predictions function conf_level numeric value 0 1. Confidence level use build confidence interval. transform_avg function applied estimates confidence intervals unit-level estimates averaged. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/summary.predictions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize a predictions object — summary.predictions","text":"Data frame summary statistics object produced predictions function","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/summary.predictions.html","id":"bayesian-posterior-summaries","dir":"Reference","previous_headings":"","what":"Bayesian posterior summaries","title":"Summarize a predictions object — summary.predictions","text":"default, credible intervals bayesian models built equal-tailed intervals. can changed highest density interval setting global option: options(\"marginaleffects_posterior_interval\" = \"eti\") options(\"marginaleffects_posterior_interval\" = \"hdi\") default, center posterior distribution bayesian models identified median. Users can use different summary function setting global option: options(\"marginaleffects_posterior_center\" = mean) options(\"marginaleffects_posterior_center\" = median) estimates averaged using argument, tidy() function, summary() function, posterior distribution marginalized twice . First, take average across units within iteration MCMC chain, according user requested argument tidy()/summary() functions. , identify center resulting posterior using function supplied \"marginaleffects_posterior_center\" option (median default).","code":""},{"path":[]},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/tidy.comparisons.html","id":null,"dir":"Reference","previous_headings":"","what":"Tidy a comparisons object — tidy.comparisons","title":"Tidy a comparisons object — tidy.comparisons","text":"Calculate average contrasts taking mean unit-level contrasts computed predictions function.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/tidy.comparisons.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tidy a comparisons object — tidy.comparisons","text":"","code":"# S3 method for comparisons tidy(x, conf_level = NULL, transform_avg = NULL, ...)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/tidy.comparisons.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tidy a comparisons object — tidy.comparisons","text":"x object produced comparisons function. conf_level numeric value 0 1. Confidence level use build confidence interval. default NULL uses conf_level value used original call comparisons(). transform_avg function applied estimates confidence intervals unit-level estimates averaged. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/tidy.comparisons.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tidy a comparisons object — tidy.comparisons","text":"\"tidy\" data.frame summary statistics conforms broom package specification.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/tidy.comparisons.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Tidy a comparisons object — tidy.comparisons","text":"compute standard errors around average marginaleffects, begin applying mean function column Jacobian. , use matrix Delta method obtained standard errors. Bayesian models (e.g., brms), compute Average Marginal Effects applying mean function twice. First, apply marginal effects posterior draw, thereby estimating one Average (Median) Marginal Effect per iteration MCMC chain. Second, calculate mean quantile function results Step 1 obtain Average Marginal Effect associated interval.","code":""},{"path":[]},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/tidy.comparisons.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tidy a comparisons object — tidy.comparisons","text":"","code":"mod <- lm(mpg ~ factor(gear), data = mtcars) contr <- comparisons(mod, variables = list(gear = \"sequential\")) tidy(contr) #>       type term contrast  estimate std.error statistic      p.value  conf.low #> 1 response gear    4 - 3  8.426667  1.823417  4.621361 3.812306e-06  4.852836 #> 2 response gear    5 - 4 -3.153333  2.506046 -1.258290 2.082869e-01 -8.065094 #>   conf.high #> 1 12.000498 #> 2  1.758428"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/tidy.deltamethod.html","id":null,"dir":"Reference","previous_headings":"","what":"Tidy a deltamethod object — tidy.deltamethod","title":"Tidy a deltamethod object — tidy.deltamethod","text":"Tidy deltamethod object","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/tidy.deltamethod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tidy a deltamethod object — tidy.deltamethod","text":"","code":"# S3 method for deltamethod tidy(x, ...)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/tidy.deltamethod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tidy a deltamethod object — tidy.deltamethod","text":"x object produced marginaleffects function. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":[]},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/tidy.marginaleffects.html","id":null,"dir":"Reference","previous_headings":"","what":"Tidy a marginaleffects object — tidy.marginaleffects","title":"Tidy a marginaleffects object — tidy.marginaleffects","text":"Tidy marginaleffects object","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/tidy.marginaleffects.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tidy a marginaleffects object — tidy.marginaleffects","text":"","code":"# S3 method for marginaleffects tidy(x, conf_level = NULL, ...)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/tidy.marginaleffects.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tidy a marginaleffects object — tidy.marginaleffects","text":"x object produced marginaleffects function. conf_level numeric value 0 1. Confidence level use build confidence interval. default NULL uses conf_level value used original call marginaleffects(). ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/tidy.marginaleffects.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tidy a marginaleffects object — tidy.marginaleffects","text":"\"tidy\" data.frame summary statistics conforms broom package specification.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/tidy.marginaleffects.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Tidy a marginaleffects object — tidy.marginaleffects","text":"tidy function calculates average marginal effects taking mean unit-level marginal effects computed marginaleffects function. standard error average marginal effects obtained taking mean column Jacobian. . , use \"Jacobian mean\" Delta method obtained standard errors.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/tidy.marginaleffects.html","id":"bayesian-posterior-summaries","dir":"Reference","previous_headings":"","what":"Bayesian posterior summaries","title":"Tidy a marginaleffects object — tidy.marginaleffects","text":"default, credible intervals bayesian models built equal-tailed intervals. can changed highest density interval setting global option: options(\"marginaleffects_posterior_interval\" = \"eti\") options(\"marginaleffects_posterior_interval\" = \"hdi\") default, center posterior distribution bayesian models identified median. Users can use different summary function setting global option: options(\"marginaleffects_posterior_center\" = mean) options(\"marginaleffects_posterior_center\" = median) estimates averaged using argument, tidy() function, summary() function, posterior distribution marginalized twice . First, take average across units within iteration MCMC chain, according user requested argument tidy()/summary() functions. , identify center resulting posterior using function supplied \"marginaleffects_posterior_center\" option (median default).","code":""},{"path":[]},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/tidy.marginaleffects.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tidy a marginaleffects object — tidy.marginaleffects","text":"","code":"mod <- lm(mpg ~ hp * wt + factor(gear), data = mtcars) mfx <- marginaleffects(mod)  # average marginal effects tidy(mfx) #>       type term contrast    estimate  std.error  statistic      p.value #> 1 response   hp    dY/dX -0.03533001 0.01044819 -3.3814471 7.210511e-04 #> 2 response   wt    dY/dX -3.52592595 0.73201586 -4.8167344 1.459267e-06 #> 3 response gear    4 - 3  0.82900152 1.11804097  0.7414769 4.584043e-01 #> 4 response gear    5 - 3  1.81649741 1.54760505  1.1737474 2.404962e-01 #>     conf.low   conf.high #> 1 -0.0558081 -0.01485193 #> 2 -4.9606507 -2.09120123 #> 3 -1.3623185  3.02032155 #> 4 -1.2167528  4.84974757"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/tidy.marginalmeans.html","id":null,"dir":"Reference","previous_headings":"","what":"Tidy a marginalmeans object — tidy.marginalmeans","title":"Tidy a marginalmeans object — tidy.marginalmeans","text":"Tidy marginalmeans object","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/tidy.marginalmeans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tidy a marginalmeans object — tidy.marginalmeans","text":"","code":"# S3 method for marginalmeans tidy(x, conf_level = 0.95, transform_avg = NULL, ...)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/tidy.marginalmeans.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tidy a marginalmeans object — tidy.marginalmeans","text":"x object produced marginalmeans function. conf_level numeric value 0 1. Confidence level use build confidence interval. default NULL uses conf_level value used original call marginaleffects(). transform_avg function applied estimates confidence intervals unit-level estimates averaged. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/tidy.marginalmeans.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tidy a marginalmeans object — tidy.marginalmeans","text":"\"tidy\" data.frame summary statistics conforms broom package specification.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/tidy.marginalmeans.html","id":"bayesian-posterior-summaries","dir":"Reference","previous_headings":"","what":"Bayesian posterior summaries","title":"Tidy a marginalmeans object — tidy.marginalmeans","text":"default, credible intervals bayesian models built equal-tailed intervals. can changed highest density interval setting global option: options(\"marginaleffects_posterior_interval\" = \"eti\") options(\"marginaleffects_posterior_interval\" = \"hdi\") default, center posterior distribution bayesian models identified median. Users can use different summary function setting global option: options(\"marginaleffects_posterior_center\" = mean) options(\"marginaleffects_posterior_center\" = median) estimates averaged using argument, tidy() function, summary() function, posterior distribution marginalized twice . First, take average across units within iteration MCMC chain, according user requested argument tidy()/summary() functions. , identify center resulting posterior using function supplied \"marginaleffects_posterior_center\" option (median default).","code":""},{"path":[]},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/tidy.predictions.html","id":null,"dir":"Reference","previous_headings":"","what":"Tidy a predictions object — tidy.predictions","title":"Tidy a predictions object — tidy.predictions","text":"Calculate average adjusted predictions taking mean unit-level adjusted predictions computed predictions function.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/tidy.predictions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tidy a predictions object — tidy.predictions","text":"","code":"# S3 method for predictions tidy(x, conf_level = NULL, transform_avg = NULL, ...)"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/tidy.predictions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tidy a predictions object — tidy.predictions","text":"x object produced predictions function. conf_level numeric value 0 1. Confidence level use build confidence interval. default NULL uses conf_level value used original call predictions(). transform_avg function applied estimates confidence intervals unit-level estimates averaged. ... Additional arguments passed predict() method supplied modeling package.arguments particularly useful mixed-effects bayesian models (see online vignettes marginaleffects website). Available arguments can vary model model, depending range supported arguments modeling package. See \"Model-Specific Arguments\" section ?marginaleffects documentation non-exhaustive list available arguments.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/tidy.predictions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tidy a predictions object — tidy.predictions","text":"\"tidy\" data.frame summary statistics conforms broom package specification.","code":""},{"path":[]},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/tidy.predictions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tidy a predictions object — tidy.predictions","text":"","code":"mod <- lm(mpg ~ hp * wt + factor(gear), data = mtcars) mfx <- predictions(mod) tidy(mfx) #>    estimate std.error statistic p.value conf.low conf.high #> 1: 20.09062 0.3837791  52.34945       0 19.33843  20.84282"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/typical.html","id":null,"dir":"Reference","previous_headings":"","what":"Superseded by datagrid(...) — typical","title":"Superseded by datagrid(...) — typical","text":"Superseded datagrid(...)","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/typical.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Superseded by datagrid(...) — typical","text":"","code":"typical(   ...,   model = NULL,   newdata = NULL,   FUN_character = Mode,   FUN_factor = Mode,   FUN_logical = Mode,   FUN_numeric = function(x) mean(x, na.rm = TRUE),   FUN_integer = function(x) round(mean(x, na.rm = TRUE)),   FUN_other = function(x) mean(x, na.rm = TRUE) )"},{"path":"https://vincentarelbundock.github.io/marginaleffects/reference/typical.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Superseded by datagrid(...) — typical","text":"... named arguments vectors values functions user-specified variables. Functions applied variable model dataset newdata, must return vector appropriate type. Character vectors automatically transformed factors necessary. +output include combinations variables (see Examples .) model Model object newdata data.frame (one one model newdata arguments FUN_character function applied character variables. FUN_factor function applied factor variables. FUN_logical function applied factor variables. FUN_numeric function applied numeric variables. FUN_integer function applied integer variables. FUN_other function applied variable types.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/news/index.html","id":"marginaleffects-0819000","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.8.1.9000","title":"marginaleffects 0.8.1.9000","text":"New features: options(\"marginaleffects_posterior_interval\" = \"eti\") options(\"marginaleffects_posterior_interval\" = \"hdi\") options(\"marginaleffects_posterior_center\" = median) options(\"marginaleffects_posterior_center\" = mean) Bug fixes: vcov argument accepts functions several models. Fix corner case slopes dataset includes infinite values. mlogit error factors.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/news/index.html","id":"marginaleffects-081","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.8.1","title":"marginaleffects 0.8.1","text":"CRAN release: 2022-11-23 deltamethod() can run hypothesis tests objects produced comparisons(), marginaleffects(), predictions(), marginalmeans() functions. feature relies match.call(), means may always work used programmatically, inside functions nested environments. generally safer efficient use hypothesis argument. plot_cme() plot_cco() accept lists user-specified values regressors, can display nice labels shortcut string-functions like “threenum” “quartile”. posteriordraws: new shape argument return MCMC draws various formats, including new rvar structure posterior package. transform_avg function gets printed summary() output. transform_post transform_avg support string shortcuts: “exp” “ln” Added support mlm models lm(). Thanks Noah Greifer. Bug fixes: hypothesis argument bayesian models tidy() used raise error. Missing values regressors comparisons() output brms models.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/news/index.html","id":"marginaleffects-080","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.8.0","title":"marginaleffects 0.8.0","text":"CRAN release: 2022-11-02 Breaking change: interaction argument deprecated replaced cross argument. reduce ambiguity respect interaction argument emmeans, something completely different, akin difference--differences illustrated Interactions vignette. 71 classes models supported, including new: rms::ols rms::lrm rms::orm New features: Plots: plot_cme(), plot_cap(), plot_cco() now much flexible specifying comparisons display. condition argument accepts lists, functions, shortcuts common reference values, “minmax”, “threenum”, etc. Accepts functions specify custom differences numeric variables (e.g., forward backward differencing). Can specify pairs factors compare variables argument comparisons function. Accepts shortcut strings, functions, vectors arbitrary length. Integrate random effects bayesian brms models (see Bayesian analysis vignette) New vignettes: Experiments Extending marginal effects Integrating random effects bayesian models Bug fixes minor improvements: default value conf_level summary() tidy() now NULL, inherits conf_level value original comparisons/marginaleffects/predictions calls. Fix typo function names missing “lnratioavgwts” Interactions fixest::() parsed properly categorical variables betareg objects, inference can now done coefficients using deltamethod(). previously location coefficients available. objects crch package, number bugs fixed; standard errors now correct deltamethod(), marginaleffects(), etc. Fixed bug tidy() function glmmTMB models without random effects, caused t statistics identical.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/news/index.html","id":"marginaleffects-071","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.7.1","title":"marginaleffects 0.7.1","text":"CRAN release: 2022-09-25 New supported model class: gamlss. Thanks Marcio Augusto Diniz. marginalmeans() accepts wts argument values: “equal”, “proportional”, “cells”. accepts data frames complex groupings. marginalmeans accepts data frames. accepts “group” group response level. works bayesian models. byfun argument predictions() function aggregate using different functions. matrix column names used labels hypothesis tests. Better labels “sequential”, “reference”, “pairwise”. new shortcuts “revpairwise”, “revsequential”, “revreference” wts argument respected argument *avg shortcuts transform_pre argument. tidy.predictions() tidy.marginalmeans() get new transform_avg argument. Unit-level contrasts logistic regressions. Thanks @arthur-albuquerque. Python Numpy models marginaleffects. Thanks @timpipeseek. Bootstrap example standard errors vignette.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/news/index.html","id":"marginaleffects-070","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.7.0","title":"marginaleffects 0.7.0","text":"CRAN release: 2022-08-06 Breaking changes: deprecated summary() tidy(). Use argument main functions instead: comparisons(), marginaleffects(), predictions() Character vectors longer supported variables argument predictions() function. Use newdata=\"fivenum\" “grid”, “mean”, “median” instead. Critical bug fix: Contrasts interactions incorrect version 0.6.0. error obvious analysts cases (weird-looking alignment). Thanks @vmikk. New supported packages models: survival::clogit biglm: main quantities can computed, delta method standard errors. See https://github.com/vincentarelbundock/marginaleffects/issues/387 New vignette: Elasticity Frequently Asked Questions New features: Elasticity semi-elasticity using new slope argument marginaleffects(): eyex, dyex, eydx datagrid() accepts functions: datagrid(newdata = mtcars, hp = range, mpg = fivenum, wt = sd) New datagridcf() function create counterfactual datasets. shortcut datagrid() function default grid_type = \"counterfactual\" New arguments predictions(), comparisons(), marginaleffects() New newdata shortcuts: “tukey”, “grid” New string shortcuts transform_pre comparisons() marginalmeans() now back transforms confidence intervals possible. vcov argument string shortcuts now case-insensitive default contrast comparisons() binary predictors now difference 1 0, rather +1 relative baseline. documentation improvements","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/news/index.html","id":"marginaleffects-060","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.6.0","title":"marginaleffects 0.6.0","text":"CRAN release: 2022-06-20 New supported packages models: tidymodels objects class tidy_model supported fit engine supported marginaleffects. New function: deltamethod(): Hypothesis tests functions parameters plot_cco(): Plot conditional contrasts New arguments: hypothesis hypothesis tests custom contrasts transform_post predictions() wts argument predictions() affects average predictions tidy() summary(). New improved vignettes: Hypothesis Tests Custom Contrasts using Delta Method: https://vincentarelbundock.github.io/marginaleffects/articles/hypothesis.html Multiple Imputation: https://vincentarelbundock.github.io/marginaleffects/articles/multiple_imputation.html Causal Inference g-Formula: https://vincentarelbundock.github.io/marginaleffects/articles/gformula.html (Thanks Rohan Kapre idea) Deprecated renamed arguments: contrast_factor contrast_numeric arguments deprecated comparisons(). Use named list variables argument instead. Backward compatibility maintained. transform_post argument tidy() summary() renamed transform_avg disambiguate argument name comparisons(). Backward compatibility preserved. Misc: tidy.predictions() computes standard errors using delta method average predictions Support gam models matrix columns. eps marginaleffects() now “adaptive” default: equals 0.0001 multiplied range predictor variable comparisons() now supports “log marginal odds ratio” transform_pre argument. Thanks Noah Greifer. New transform_pre shortcuts: dydx, expdydx tidy.predictions() computes standard errors confidence intervals linear models GLM link scale.","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/news/index.html","id":"marginaleffects-050","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.5.0","title":"marginaleffects 0.5.0","text":"CRAN release: 2022-05-17 Breaking changes: type longer accepts character vector. Must single string. conf.int argument deprecated. Use vcov = FALSE instead. New supported packages models: mlogit mhurdle tobit1 glmmTMB New features: interaction argument comparisons() compute interactions contrasts (cross-contrasts). argument tidy() summary() computes group-average marginal effects comparisons. transform_pre argument can define custom contrasts adjusted predictions (e.g., log adjusted risk ratios). Available comparisons(). transform_post argument allows back transformation returning final results. Available comparisons(), marginalmeans(), summary(), tidy(). variables argument comparisons() function accepts named list specify variable-specific contrast types. sandwich package shortcuts: vcov = \"HC3\", \"HC2\", \"NeweyWest\", . Mixed effects models: vcov = \"satterthwaite\" \"kenward-roger\" One-sided formula clusters: vcov = ~cluster_variable Variance-covariance matrix Function returns named squared matrix marginalmeans() allows interactions Bayesian Model Averaging brms models using type = \"average\". See vignette marginaleffects website. eps argument step size numerical derivative marginaleffects comparisons now report confidence intervals default. New dependency data.table package yields substantial performance improvements. informative error messages warnings Bug fixes performance improvements New pages marginaleffects website: https://vincentarelbundock.github.io/marginaleffects/ Alternative software packages Robust standard errors () Performance tips Tables plots Multinomial Logit Discrete Choice Models Generalized Additive Models Mixed effects models (Bayesian Frequentist) Transformations Custom Contrasts: Adjusted Risk Ratio Example Argument name changes (backward compatibility preserved: conf.level -> conf_level FUN.factor -> FUN_factor (related arguments) grid.type -> grid_type","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/news/index.html","id":"marginaleffects-041","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.4.1","title":"marginaleffects 0.4.1","text":"CRAN release: 2022-03-27 New supported packages models: stats::loess sampleSelection::selection sampleSelection::heckit Misc: mgcv::bam models allow exclude argument. Gam models allow include_smooth argument. New tests Bug fixes","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/news/index.html","id":"marginaleffects-040","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.4.0","title":"marginaleffects 0.4.0","text":"CRAN release: 2022-03-13 New function: comparisons() computes contrasts Misc: Speed optimizations predictions() plot_cap() include confidence intervals linear models robust handling -formula functions: factor(), strata(), mo() overwrite user’s ggplot2::theme_set() call","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/news/index.html","id":"marginaleffects-034","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.3.4","title":"marginaleffects 0.3.4","text":"CRAN release: 2022-03-03 Bug fixes","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/news/index.html","id":"marginaleffects-033","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.3.3","title":"marginaleffects 0.3.3","text":"CRAN release: 2022-01-26 New supported models: mclogit::mclogit robust::lmRob robustlmm::rlmer fixest confidence intervals predictions Misc: Support modelbased::visualisation_matrix newdata without specify x explicitly. tidy.predictions() summary.predictions() methods. Documentation improvements. CRAN test fixes","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/news/index.html","id":"marginaleffects-032","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.3.2","title":"marginaleffects 0.3.2","text":"CRAN release: 2022-01-18 Support new models packages: brglm2::bracl mclogit::mblogit scam::scam lmerTest::lmer Misc: Drop numDeriv dependency, make available via global option: options(“marginaleffects_numDeriv” = list(method = “Richardson”, method.args = list(eps = 1e-5, d = 0.0001))) Bugfixes Documentation improvements CRAN tests","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/news/index.html","id":"marginaleffects-031","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.3.1","title":"marginaleffects 0.3.1","text":"CRAN release: 2022-01-09 documentation bugfix","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/news/index.html","id":"marginaleffects-030","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.3.0","title":"marginaleffects 0.3.0","text":"CRAN release: 2022-01-08 Breaking changes: predictions returns predictions every observation original dataset instead newdata=datagrid(). marginalmeans objects new column names, corresponding tidy summary outputs. New supported packages models: brms::brm rstanarm::stanglm brglm2::brmultinom MASS::glmmPQL aod::betabin Misc: datagrid function supersedes typical counterfactual grid.type argument. typical counterfactual functions remain available exported, use encouraged. posteriordraws function can applied predictions marginaleffects object extract draws posterior distribution. marginalmeans standard errors now computed using delta method. predictions standard errors now computed using delta method available insight::get_predicted. New vignette Bayesian models brms New vignette Mixed effects models lme4 data.table package installed, marginaleffects automatically use speed things . Contrast definition reported separate column marginaleffects output. Safer handling type argument. Comprehensive list supported tests models website. Many bug fixes Many new tests, including several emmeans","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/news/index.html","id":"marginaleffects-020","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.2.0","title":"marginaleffects 0.2.0","text":"CRAN release: 2021-10-18 Breaking change: data argument becomes newdata functions. New supported packages models: lme4:glmer.nb mgcv::gam ordinal::clm mgcv marginalmeans: New variables_grid argument predictions: Support mgcv plot_cap New type argument Misc: New validity checks tests","code":""},{"path":"https://vincentarelbundock.github.io/marginaleffects/news/index.html","id":"marginaleffects-010","dir":"Changelog","previous_headings":"","what":"marginaleffects 0.1.0","title":"marginaleffects 0.1.0","text":"CRAN release: 2021-09-29 First release. Bravo! Thanks Marco Avina Mendoza, Resul Umit, offered comments suggestions.","code":""}]
